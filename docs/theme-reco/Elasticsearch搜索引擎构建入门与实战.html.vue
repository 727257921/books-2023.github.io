<template><div><h1 id="elasticsearch搜索引擎构建入门与实战" tabindex="-1"><a class="header-anchor" href="#elasticsearch搜索引擎构建入门与实战" aria-hidden="true">#</a> Elasticsearch搜索引擎构建入门与实战</h1>
<p>高印会编著</p>
<h2 id="◆-前言" tabindex="-1"><a class="header-anchor" href="#◆-前言" aria-hidden="true">#</a> ◆ 前言</h2>
<blockquote>
<blockquote>
<p>搜索引擎的底层技术是非常专业的，需要技术人员系统地学习索引、压缩和存储等方面的知识，学习路线非常“陡峭”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>而在工程实践中，技术人员往往需要一款无须熟知底层技术便可使用的搜索引擎框架，以便在较短时间内实现业务搜索的需求。作为搜索引擎框架中的佼佼者，Elasticsearch（简称ES）提供了完备的解决方案。从索引创建到搜索查询，再到搜索排序等各个方面，ES都提供了对应的服务支持，用户可以通过发送REST请求完成上述工作。如今，ES已经不是单一的搜索引擎框架，它已经演变成一个生态系统。ES与ELK的完美搭配，使系统的数据收集、数据检索和数据呈现可以无缝连接，因此越来越多的企业都采用该方案来搭建数据系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本书涉及的所有源代码需要读者自行下载。请在华章公司的网站（www.hzbook.com）上搜索到本书，然后单击“资料下载”按钮，即可在本书页面上找到下载链接进行下载。此外，读者还可以在百度网盘https://pan.baidu.com/s/1XQaHieTBIGOg5JeQbSDkyA（提取码0trh）上下载这些资源。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-1-1-elasticsearch简介" tabindex="-1"><a class="header-anchor" href="#◆-1-1-1-elasticsearch简介" aria-hidden="true">#</a> ◆ 1.1.1 Elasticsearch简介</h3>
<blockquote>
<blockquote>
<p>很多应用都有搜索功能。Lucene作为“老牌”的搜索技术支持库，它提供的很多功能都能用于处理文本类型的数据。但是使用Lucene架设搜索引擎需要使用者熟悉搜索引擎的很多知识，对使用者的要求非常高，并且Lucene仅仅提供了基础的搜索引擎支持，而对搜索的分布式、容错性和实时性并不支持。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES是建立在Lucene基础之上的分布式准实时搜索引擎，它所提供的诸多功能中有一大优点，即实时性好。那么什么是实时性好呢？在一般的业务需求中，新增加的数据至少要1min才能被搜索到，而在ES中，数秒甚至1s内即可搜索到新增的数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES是分布式的架构设计，当单台或者少量的计算机不能很好地支持搜索任务时，完全可以扩展到足够多的计算机上进行搜索；以往在使用Lucene时，需要用户有Java语言基础，而ES提供了REST风格的API接口，使用户可以借助任何语言使用HTTP对ES执行请求来完成搜索任务；ES本身还提供了聚合功能，用户可以使用该功能对索引中的数据进行统计分析；在数据安全方面，ES提供了X-Pack进行用户验证。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES不仅是一个搜索引擎框架，而且其官方还提供了ELK“全家桶”，为构建搜索引擎提供了很好的解决方案。其中，E代表Elasticsearch，主要提供数据搜索和分析功能；L代表Logstash，借助它可以将数据库和日志等结构化或非结构化数据轻松地导入ES中；K代表Kibana，它可以将分析结果进行图形化展示，此外还可以使用它提供的开发工具对ES进行请求的交互。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-1-2-elasticsearch的基本概念" tabindex="-1"><a class="header-anchor" href="#◆-1-1-2-elasticsearch的基本概念" aria-hidden="true">#</a> ◆ 1.1.2 Elasticsearch的基本概念</h3>
<blockquote>
<blockquote>
<p>Elasticsearch的基本概念</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.索引</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在使用传统的关系型数据库时，如果对数据有存取和更新操作，需要建立一个数据库。相应地，在ES中则需要建立索引。用户的数据新增、搜索和更新等操作的对象全部对应索引。但是，ES中的索引和Lucene中的索引不是一一对应的。ES中的一个索引对应一个或多个Lucene索引，这是由其分布式的设计方案决定的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.文档</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在使用传统的关系型数据库时，需要把数据封装成数据库中的一条记录，而在ES中对应的则是文档。ES的文档中可以有一个或多个字段，每个字段可以是各种类型。用户对数据操作的最细粒度对象就是文档。ES文档操作使用了版本的概念，即文档的初始版本为1，每次的写操作会把文档的版本加1，每次使用文档时，ES返回给用户的是最新版本的文档。另外，为了减轻集群负载和提升效率，ES提供了文档的批量索引、更新和删除功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.字段</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个文档可以包含一个或多个字段，每个字段都有一个类型与其对应。除了常用的数据类型（如字符串型、文本型和数值型）外，ES还提供了多种数据类型，如数组类型、经纬度类型和IP地址类型等。ES对不同类型的字段可以支持不同的搜索功能。例如，当使用文本类型的数据时，可以按照某种分词方式对数据进行搜索，并且可以设定搜索后的打分因子来影响最终的排序。再如，使用经纬度的数据时，ES可以搜索某个地点附近的文档，也可以查询地理围栏内的文档。在排序函数的使用上，ES也可以基于某个地点按照衰减函数进行排序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>索引、文档和字段的逻辑关系如图1.1所示，从图中可以看出它们之间的包含关系。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.映射</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>建立索引时需要定义文档的数据结构，这种结构叫作映射。在映射中，文档的字段类型一旦设定后就不能更改。因为字段类型在定义后，ES已经针对定义的类型建立了特定的索引结构，这种结构不能更改。借助映射可以给文档新增字段。另外，ES还提供了自动映射功能，即在添加数据时，如果该字段没有定义类型，ES会根据用户提供的该字段的真实数据来猜测可能的类型，从而自动进行字段类型的定义。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.集群和节点</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式系统中，为了完成海量数据的存储、计算并提升系统的高可用性，需要多台计算机集成在一起协作，这种形式被称为集群，如图1.2所示。这些集群中的每台计算机叫作节点。ES集群的节点个数不受限制，用户可以根据需求增加计算机对搜索服务进行扩展。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.分片</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式系统中，为了能存储和计算海量的数据，会先对数据进行切分，然后再将它们存储到多台计算机中。这样不仅能分担集群的存储和计算压力，而且在该架构基础上进一步优化，还可以提升系统中数据的高可用性。在ES中，一个分片对应的就是一个Lucene索引，每个分片可以设置多个副分片，这样当主分片所在的计算机因为发生故障而离线时，副分片会充当主分片继续服务。索引的分片个数只能设置一次，之后不能更改。在默认情况下，ES的每个索引设置为5个分片。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>7.副分片</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了提升系统索引数据的高可用性并减轻集群搜索的负载，可以启用分片的副本，该副本叫作副分片，而原有分片叫作主分片。在一个索引中，主分片的副分片个数是没有限制的，用户可以按需设定。在默认情况下，ES不会为索引的分片开启副分片，用户需要手动设置。副分片的个数设定后，也可以进行更改。一个分片的主分片和副分片分别存储在不同的计算机上，</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如图1.3所示为一个3个节点的集群，某个索引设置了3个主分片，每个主分片分配两个副分片。图1.3中深色方框中的P表示该分片为主分片，R表示该分片为副分片，P和R后面的数字表示其编号。在极端情况下，当只有一个节点时，如果索引的副分片个数设置大于1，则系统只分配主分片，而不会分配副分片。[插图]图1.3　ES集群中的主分片和副分片</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>8.DSL</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES使用DSL（Domain Specific Language，领域特定语言），来定义查询。与编程语言不同，DSL是在特定领域解决特定任务的语言，它可以有多种表达形式，如我们常见的HTML、CSS、SQL等都属于DSL。ES中的DSL采用JSON进行表达，相应地，ES也将响应客户端请求的返回数据封装成了JSON形式。这样不仅可以简单明了地表达请求/响应内容，而且还屏蔽了各种编程语言之间数据通信的差异。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-1-3-elasticsearch和关系型数据库的对比" tabindex="-1"><a class="header-anchor" href="#◆-1-1-3-elasticsearch和关系型数据库的对比" aria-hidden="true">#</a> ◆ 1.1.3 Elasticsearch和关系型数据库的对比</h3>
<blockquote>
<blockquote>
<p>ES属于非关系型数据库。在判断该使用ES还是关系型数据库之前，要先比较一下这两种不同类别的产品。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.索引方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>关系型数据库的索引大多是B-Tree结构，而ES使用的是倒排索引，两种不同的数据索引方式决定了这两种产品在某些场景中性能和速度的差异。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例如，对一个包含几亿条数据的关系型数据表执行最简单的count查询时，关系型数据库可能需要秒级的响应时间，如果数据表的设计不合理，甚至有可能把整个关系型数据库拖垮，影响其他的数据服务；而ES可以在毫秒级别进行返回，该查询对整个集群的影响微乎其微。再例如，一个需求是进行分词匹配，关系型数据库需要依靠其他的组件才能完成这种查询，查询的结果只能是满足匹配，但是不能按照匹配程度进行打分排序；ES建立在Lucene基础之上，与生俱来就能完成分词匹配，并且支持多种打分排序算法，还支持用户自定义排序脚本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.事务支持</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>事务是关系型数据库的核心组成模块，而ES是不支持事务的。ES更新文档时，先读取文档再进行修改，然后再为文档重新建立索引。如果同一个文档同时有多个并发请求，则极有可能会丢失某个更新操作。为了解决这个问题，ES使用了乐观锁，即假定冲突是不会发生的，不阻塞当前数据的更新操作，每次更新会增加当前文档的版本号，最新的数据由文档的最新版本来决定，这种机制就决定了ES没有事务管理。因此，如果你的需求是类似商品库存的精准查询或者金融系统的核心并发业务的支持，那么关系型数据是不错的选择。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.SQL和DSL</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>SQL和DSL都有自己的语法结构，都是各自和用户之间进行交互的一种语言表达方式。SQL是关系型数据库使用的语言，主要是因为SQL查询的逻辑比较简单和直接，一般是大小、相等之类的比较运算，以及逻辑与、或、非的关系运算。ES不仅包含上述运算，而且支持文本搜索、地理位置搜索等复杂数据的搜索，因此ES使用DSL查询进行请求通信。虽然ES的高版本也开始支持SQL查询，但若需要完成比较复杂的数据搜索需求，使用DSL查询会更加方便快捷。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.扩展方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>关系型数据库的扩展，需要借助第三方组件完成分库分表的支持。分库分表即按照某个ID取模将数据打散后分散到不同的数据节点中，借此来分摊集群的压力。但是分库分表有多种策略，需要使用人员对业务数据特别精通才能进行正确的选择。另外，分库分表会对一些业务造成延迟，如查询结果的合并及多表Join操作。ES本身就是支持分片的，只要初期对分片的个数进行了合理的设置，后期是不需要对扩展过分担心的，即使现有集群负载较高，也可以通过后期增加节点和副分片的方式来解决。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.数据的查询速度在少量字段和记录的情况下，传统的关系型数据库的查询速度非常快。如果单表有上百个字段和几十亿条记录，则查询速度是比较慢的。虽然可以通过索引进行缓解，但是随着数据量的增长，查询速度还是会越来越慢。ES是基于Lucene库的搜索引擎，可以支持全字段建立索引。在ES中，单个索引存储上百个字段或几十亿条记录都是没有问题的，并且查询速度也不会变慢。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.数据的实时性关系型数据库存储和查询数据基本上是实时的，即单条数据写入之后可以立即查询。为了提高数据写入的性能，ES在内存和磁盘之间增加了一层系统缓存。ES响应写入数据的请求后，会先将数据存储在内存中，此时该数据还不能被搜索到。内存中的数据每隔一段时间（默认为1s）被刷新到系统缓存内，此时数据才能被搜索到。因此，ES的数据写入不是实时的，而是准实时的。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-1-节点职责" tabindex="-1"><a class="header-anchor" href="#◆-1-2-1-节点职责" aria-hidden="true">#</a> ◆ 1.2.1 节点职责</h3>
<blockquote>
<blockquote>
<p>节点按照职责可以分为master节点、数据节点和协调节点，每个节点类型可以进行单独配置。默认情况下，集群不会对节点角色进行划分，所有节点都是平等的，可以担任所有的职责。但是在生产环境中需要对这些节点的角色进行最优划分，否则在高并发请求的情况下，集群容易出现服务阻塞超时甚至服务崩溃的隐患。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>master节点负责维护整个集群的相关工作，管理集群的变更，如创建/删除索引、节点健康状态监测、节点上/下线等。master节点是由集群节点通过选举算法选举出来的，一个集群中只有一个节点可以成为master节点，但是可以有一个或多个节点参与master节点的选举。在默认情况下，任意节点都可以作为master的候选节点，可以通过配置项node.master对当前节点是否作为master的候选节点进行控制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据节点主要负责索引数据的保存工作</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>文档的删除、修改和查询操作。数据节点的很多工作是调用Lucene库进行Lucene索引操作，因此这种节点对于内存和I/O的消耗比较大</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>客户端可以向ES集群的节点发起请求，这个节点叫作协调节点。在默认情况下，协调节点可以是集群中的任意节点，此时它的生命周期是和一个单独的请求相关的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当客户端向集群中的某个节点发起请求时，此时该节点被称为当前请求的协调节点；当它将响应结果返回给客户端后，该协调节点的生命周期就结束了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了降低集群的负载，可以设置某些节点作为单独的协调节点。在节点的配置文件中设置node.master和node.data配置项为false，此时，这个节点就不会被选中为master节点并且不再担任数据节点，而客户端就可以把这类节点作为协调节点来使用，把所有的请求都分发到这些节点上</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.5　在集群中单独部署协调节点</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-2-主分片和副分片" tabindex="-1"><a class="header-anchor" href="#◆-1-2-2-主分片和副分片" aria-hidden="true">#</a> ◆ 1.2.2 主分片和副分片</h3>
<blockquote>
<blockquote>
<p>ES为了支持分布式搜索，会把数据按照分片进行切分。一个索引由一个或者多个分片构成，并且每个分片有0个甚至多个副分片。多个分片分布在不同的节点中，通过这种分布式结构提升了分片数据的高可用性和服务的高并发支持。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES是如何提升分片数据的高可用性的呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群中的索引主分片和副分片在不同的计算机上，如果某个主分片所在的节点宕机，则原有的某个副分片会提升为主分片继续对外进行服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES又是如何提升服务的高并发性能的呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当客户端对某个索引的请求被分发到ES的协调节点时，协调节点会将请求进行转发，转发的对象是包含这个索引的所有分片的部分节点。协调节点中有一份分片-节点路由表，该表主要存放分片和节点的对应关系。协调节点采用轮询算法，选取该索引的主/副分片所在的节点进行请求转发。一个索引的主分片设定后就不能再修改，如果想继续提升索引的并发性能，则可以增加索引的副分片个数，此时协调节点会将这些副分片加入轮询算法中。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-3-路由计算" tabindex="-1"><a class="header-anchor" href="#◆-1-2-3-路由计算" aria-hidden="true">#</a> ◆ 1.2.3 路由计算</h3>
<blockquote>
<blockquote>
<p>当客户端向一个ES协调节点发送一条数据的写入请求时，协调节点如何确认当前数据应该存储在哪个节点的哪个分片上呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>协调节点根据数据获取分片ID的计算公式如下：shard=hash（routing）%number_of_primary_shards</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>式中，routing代表每条文档提交时的参数，该值是可变的，用户可以自定义，在默认情况下使用的是文档的_id值；number_of_primary_shards是索引中主分片的个数。计算routing的哈希值后，除以索引的主分片数再取余，就是当前文档实际应该存储的分片ID。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>获取到分片ID后，根据分片-节点路由表获取该分片的主/副分片节点列表，然后再转发请求进行分片内的数据写入。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>主分片个数作为取余的分母不能进行更改，否则分片ID计算就会发生错误，进而导致找不到存储节点，这也是ES索引的主分片个数不能更改的原因。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-4-文档读写过程" tabindex="-1"><a class="header-anchor" href="#◆-1-2-4-文档读写过程" aria-hidden="true">#</a> ◆ 1.2.4 文档读写过程</h3>
<blockquote>
<blockquote>
<p>S集群响应客户端的写入和读取请求的过程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当ES协调节点接收到来自客户端对某个索引的写入文档请求时，该节点会根据一定的路由算法将该文档映射到某个主分片上，然后将请求转发到该分片所在的节点。完成数据的存储后，该节点会将请求转发给该分片的其他副分片所在的节点，直到所有副分片节点全部完成写入，ES协调节点向客户端报告写入成功。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个包含3个节点的ES集群，假设索引中只有3个主分片和6个副分片，客户端向节点1发起向索引写入一条文档的请求，在本次请求中，节点1被称为协调节点。节点1判断数据应该映射到哪个分片上。假设将数据映射到分片1上，因为分片1的主分片在节点2上，因此节点1把请求转发到节点2上。节点2接收客户端的数据并进行存储，然后把请求转发到副分片1所在的节点1和节点3上，当所有副分片所在的节点全部完成存储后，协调节点也就是节点1向客户端返回成功标志。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.8　ES写文档的过程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当ES协调节点接收到来自客户端的获取某个索引的某文档的请求时，协调节点会找到该文档所在的所有分片，然后根据轮询算法在主/副分片中选择一个分片并将请求转发给该分片所在的节点，该节点会将目标数据发送给协调节点，协调节点再将数据返回给客户端。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个包含3个节点的ES集群，假设索引中只有3个主分片和6个副分片，客户端向节点1发起向索引获取文档的请求，在本次请求中，节点1被称为协调节点。节点1判断数据应该映射到哪个分片上。假设将数据映射到分片1上，分片1有主/副两种分片，分别在节点2、节点1和节点3上。假设此时协调节点的轮询算法选择的是节点3，那么它会将请求转发到节点3上，然后节点3会把数据传输给协调节点，也就是节点1，最后由节点1向客户端返回文档数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.9　ES读文档的过程</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-1-搜索引擎" tabindex="-1"><a class="header-anchor" href="#◆-1-3-1-搜索引擎" aria-hidden="true">#</a> ◆ 1.3.1 搜索引擎</h3>
<blockquote>
<blockquote>
<p>ES最擅长的是充当搜索引擎，在这类场景中较典型的应用领域是垂直搜索，如电商搜索、地图搜索、新闻搜索等各类站内搜索。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>创建索引时，业务系统模块把数据存储到数据库中，第三方数据同步模块（如Canal）负责将数据库中的数据按照业务需求同步到ES中。搜索时，前端应用先向搜索模块发起搜索请求，然后搜索模块组织搜索DSL向ES发起请求，ES响应搜索模块的请求开始搜索，并将搜索到的商品信息（如名称、价格、地理位置等）进行封装，然后把数据传送给搜索模块，进而数据再由搜索模块传递到前端进行展现</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.10　ES搜索引擎架构</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-2-推荐系统" tabindex="-1"><a class="header-anchor" href="#◆-1-3-2-推荐系统" aria-hidden="true">#</a> ◆ 1.3.2 推荐系统</h3>
<blockquote>
<blockquote>
<p>ES在高版本（7.0及以上版本）中引入了高维向量的数据类型。可以把推荐模型算法计算的商品和用户向量存储到ES索引中，当实时请求时，加载用户向量并使用ES的Script Score进行查询，使每个文档最终的排序分值等于当前用户向量与当前文档向量的相似度。为同时满足实时向量计算和实时数据过滤的需求，可以在Script Score查询中添加filter（即过滤条件，如库存、上下架状态等）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.11　ES推荐系统架构</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-3-二级索引" tabindex="-1"><a class="header-anchor" href="#◆-1-3-3-二级索引" aria-hidden="true">#</a> ◆ 1.3.3 二级索引</h3>
<blockquote>
<blockquote>
<p>在有些场景中，部分数据是强事务性的，或者说这些数据需要关联多张表才可以获取到，这种数据不适合在ES中作为最终数据进行呈现，最好将它们存储在RDBMS中。如果还需要使用任意组合字段进行查询，或者按照某些文本字段进行搜索且这些字段是弱事务性的，那么可以考虑使用ES作为二级索引</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据存储在RDBMS中，建立ES索引时其中仅包含查询字段，RDBMS中的主键在ES中仅存储不用建立索引。这些主键存在于RDBMS的索引中，叫作一级索引；ES中的查询字段构成的索引叫作二级索引。查询时客户端可以把查询请求分发到ES中，ES从索引中查询并返回符合条件的记录主键，客户端再根据返回的记录主键请求RDBMS得到实时数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.12　ES二级索引服务</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-4-日志分析" tabindex="-1"><a class="header-anchor" href="#◆-1-3-4-日志分析" aria-hidden="true">#</a> ◆ 1.3.4 日志分析</h3>
<blockquote>
<blockquote>
<p>支持任意字段的各种组合查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>又具有很强大的数据统计和分析能力</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>也可以当作数据分析引擎</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ELK（Elasticsearch+Logstash+Kibana）全家桶可以完成日志采集、索引创建再到可视化的数据分析等工作，使用户可以0代码完成搭建工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>生产中的用户行为日志、Web容器日志、接口调用日志及数据库日志等都可以通过ELK进行分析。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES官网提供的ELK-Stack架构层级，其中的Beats是新加入的成员，定位为轻量型的单一功能数据采集器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.13　ELK-Stack架构层级</p>
</blockquote>
</blockquote>
<h3 id="◆-1-4-1-单机模式安装" tabindex="-1"><a class="header-anchor" href="#◆-1-4-1-单机模式安装" aria-hidden="true">#</a> ◆ 1.4.1 单机模式安装</h3>
<blockquote>
<blockquote>
<p>ES的最新版本下载地址为https://www.elastic.co/cn/downloads/elasticsearch，本书使用的版本为ES7.10.2。ES的安装文件是压缩文件，把文件解压缩后，各目录的作用如表1.1所示。表1.1　ES的目录及其作用[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>出于安全性考虑，ES不允许用root账户启动，应创建其他账户启动ES。对基本的入门使用而言，ES的默认配置已经是最佳配置，用户不需要更改配置文件即可启动。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>默认情况下，配置文件中ES进程占用的内存为1GB。如果计算机的内存较小，需要更改config/jvm.options配置文件，修改其中的-Xms和-Xmx参数值到合适的值即可。通过执行bin/elasticsearch命令可以启动ES，如果需要在后台运行，则执行bin/elasticsearch-d命令即可。观察logs/elasticsearch.log文件的内容，可以查看ES启动输出的日志有无报错信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当ES启动后，在其安装目录下会增加一个data目录，该目录主要用于存储索引数据文件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以通过curl命令访问ES的9200端口来实际验证一下安装是否成功。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行命令curl http://127.0.0.1:9200，ES返回的信息如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>name为当前ES的实例名称，默认取值是当前服务器的主机名。cluster_name为集群的名称，该项在配置文件中的默认值即为elasticsearch。当在同一个网络中部署多个ES集群时，将依靠cluster_name的值作为集群的唯一标识，各节点只有和集群下的其他节点的cluster_name值一致才能加入该集群中。在这种情况下，不同的集群节点需要将cluster_name的值定义为不同的名称。version内为当前集群版本及使用的Lucene组件等版本信息。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-4-2-集群模式安装" tabindex="-1"><a class="header-anchor" href="#◆-1-4-2-集群模式安装" aria-hidden="true">#</a> ◆ 1.4.2 集群模式安装</h3>
<blockquote>
<blockquote>
<p>如果需要增强ES集群的服务性能或提升其高可用性，则需要使用ES的集群模式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本节仅使用3台计算机，并且使用默认的节点职责设置。假设这3台计算机的IP地址分别为192.168.0.1、192.168.0.2和192.168.0.3，名称分别为es1、es2和es3，需要在这3台计算机上创建除root外的用户进行集群的搭建。修改3台计算机的config/elasticsearch.yml文件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在es1上需要修改的文件内容如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]在es2上需要修改的文件内容如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在es3上需要修改的文件内容如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>更改各节点配置后，可以按照任意顺序在3台计算机上运行bin/elasticsearch命令，观察各计算机上logs/elasticsearch.log文件的内容，查看ES启动输出的日志有无报错信息。通过访问ES的_cat API可以实际验证一下安装是否成功，执行curl http://192.168.0.1:9200/_cat/nodes?v命令，ES返回的信息如图1.14所示。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>返回的信息中主要描述了当前集群中各个节点的IP地址及CPU的内存负载情况，另外还包括节点角色信息，其中，es1目前是集群中的master节点。ES集群中的master节点是由集群自动选举完成指派的，不需要额外指定。当然，如果用户对某些节点的角色有特殊的要求，可以更改config/elasticsearch.yml文件中的node.master或者node.data选项来完成配置。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-5-1-创建索引" tabindex="-1"><a class="header-anchor" href="#◆-1-5-1-创建索引" aria-hidden="true">#</a> ◆ 1.5.1 创建索引</h3>
<blockquote>
<blockquote>
<p>1.5.1　创建索引</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>完成搜索的第一步是建立搜索数据集的对象，即建立索引。在定义酒店的搜索需求时，应该包括的字段有酒店标题、所属城市和房价等。对于酒店标题来说，需要按照用户输入的关键词进行模糊搜索，因此应该定义成文本（text）型；对于所属城市来说，只需进行相等与否的判断，定义成普通的关键词类型（keyword）即可；对于房价来说，只需进行大小比较的判断，因此定义成数值中的双精度浮点型。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设使用默认的分片数和副本数，整体的索引创建语句如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Content-Type:application/json描述的是本次请求向目标URL传递JSON形式的参数，-XPUT是告诉服务方本次的请求类型为PUT，URL最后面的hotel就是将要创建的索引名称。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-5-2-写入文档" tabindex="-1"><a class="header-anchor" href="#◆-1-5-2-写入文档" aria-hidden="true">#</a> ◆ 1.5.2 写入文档</h3>
<blockquote>
<blockquote>
<p>hotel索引创建后，需要在索引中填充一些数据。例如，在目标索引中写入下面的数据：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行上述命令后，在索引中创建了一条ID为001的文档。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-5-3-根据-id搜索文档" tabindex="-1"><a class="header-anchor" href="#◆-1-5-3-根据-id搜索文档" aria-hidden="true">#</a> ◆ 1.5.3 根据_id搜索文档</h3>
<blockquote>
<blockquote>
<p>1.5.3　根据_id搜索文档</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有的时候需要根据文档的ID直接定位某个文档，例如，把1.5.2节写入的文档检索出来：[插图][插图][插图]检索结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在_source中展示了命中的文档的原始数据</p>
</blockquote>
</blockquote>
<h3 id="◆-1-5-4-根据一般字段搜索文档" tabindex="-1"><a class="header-anchor" href="#◆-1-5-4-根据一般字段搜索文档" aria-hidden="true">#</a> ◆ 1.5.4 根据一般字段搜索文档</h3>
<blockquote>
<blockquote>
<p>1.5.4　根据一般字段搜索文档</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在ES中进行搜索时需要用到query子句，其请求形式如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>query子句可以按照需求填充查询项。假设按照城市进行搜索，把酒店文档搜索出来。因为只需要进行文本是否相等的判断，所以需要用到term搜索</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES不仅返回了搜索的文档结果，而且对结果进行了打分计算</p>
</blockquote>
</blockquote>
<h3 id="◆-1-5-5-根据文本字段搜索文档" tabindex="-1"><a class="header-anchor" href="#◆-1-5-5-根据文本字段搜索文档" aria-hidden="true">#</a> ◆ 1.5.5 根据文本字段搜索文档</h3>
<blockquote>
<blockquote>
<p>对文本进行模糊匹配并给出匹配分数这一功能是搜索引擎所独有的。此处使用match搜索对某个字段进行模糊匹配，按照标题进行模糊搜索，示例如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES对结果进行了打分计算，此处使用了对文本打分计算的算法。</p>
</blockquote>
</blockquote>
<h2 id="◆-第2章-elasticsearch客户端实战" tabindex="-1"><a class="header-anchor" href="#◆-第2章-elasticsearch客户端实战" aria-hidden="true">#</a> ◆ 第2章 Elasticsearch客户端实战</h2>
<blockquote>
<blockquote>
<p>在使用ES构建搜索应用时，需要使用客户端与ES进行会话。在开发和调试环节，使用最广泛的客户端要数Kibana，其提供的强大功能足以满足构建索引、验证结果和调试DSL等各种需求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于Java，可选的客户端有RestHighLevelClient、Spring Data Elasticsearch和Jest</p>
</blockquote>
</blockquote>
<h3 id="◆-2-1-kibana客户端简介" tabindex="-1"><a class="header-anchor" href="#◆-2-1-kibana客户端简介" aria-hidden="true">#</a> ◆ 2.1 Kibana客户端简介</h3>
<blockquote>
<blockquote>
<p>Kibana是ELK家族中一个开源、免费的可视化数据搜索和分析平台。借助Kibana，用户不需要编码就可以将ES中分析的结果进行可视化呈现，如以常用的饼图、柱状图和时序图等方式呈现。除了可视化数据分析功能，Kibana还提供了Dev Tools，它是一款可以与ES进行交互式请求的工具，可以借助它进行DSL调试。</p>
</blockquote>
</blockquote>
<h3 id="◆-2-1-1-kibana的安装" tabindex="-1"><a class="header-anchor" href="#◆-2-1-1-kibana的安装" aria-hidden="true">#</a> ◆ 2.1.1 Kibana的安装</h3>
<blockquote>
<blockquote>
<p>Kibana的下载地址为https://www.elastic.co/cn/downloads/kibana，这里选择7.10.2版本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>解压缩下载后的Kibana安装文件，修改config/kibana.yml配置文件，将elasticsearch.hosts的值修改为ES的HTTP服务地址，此处为[&quot;http://localhost:9200&quot;]。如果希望外网计算机也能访问Kibana的界面服务，则需要将server.host的值修改为&quot;0.0.0.0&quot;。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Kibana的简单配置已经完成了，运行bin/kibana即可开启Kibana的Web界面服务。在浏览器的地址栏中输入http://ip:5601/，运行界面如图2.1所示。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>图2.1　Kibana Web界面首页</p>
</blockquote>
</blockquote>
<h3 id="◆-2-1-2-在kibana中搜索文档" tabindex="-1"><a class="header-anchor" href="#◆-2-1-2-在kibana中搜索文档" aria-hidden="true">#</a> ◆ 2.1.2 在Kibana中搜索文档</h3>
<blockquote>
<blockquote>
<p>在Kibana首页中单击Dev Tools链接，即进入Kibana开发工具集的界面。目前的工具集中包含Console、Search Profiler、Grok Debugger和Painless Lab4个工具，它们各自的功能如表2.1所示。表2.1　Dev Tools中的各种工具及其功能[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-2-2-java客户端简介" tabindex="-1"><a class="header-anchor" href="#◆-2-2-java客户端简介" aria-hidden="true">#</a> ◆ 2.2 Java客户端简介</h3>
<blockquote>
<blockquote>
<p>ES和客户端的通信通过HTTP进行，用户可以使用任意语言完成搜索。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-1-创建索引" tabindex="-1"><a class="header-anchor" href="#◆-3-1-1-创建索引" aria-hidden="true">#</a> ◆ 3.1.1 创建索引</h3>
<blockquote>
<blockquote>
<p>3.1.1　创建索引</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用ES构建搜索引擎的第一步是创建索引。在创建索引时，可以按照实际需求对索引进行主分片和副分片设置。ES创建索引的请求类型为PUT，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>变量index_name就是创建的目标索引名称；可以在settings子句内部填写索引相关的设置项，如主分片个数和副分片个数等；可以在mappings子句内部填写数据组织结构，即数据映射。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在第1章中曾介绍过创建索引hotel的语句，但是当时的主分片个数使用的是系统默认值（默认值为5），并且没有使用副分片个数（默认值为0）。假设设置主分片个数为15，副分片个数为2，则相应的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-2-删除索引" tabindex="-1"><a class="header-anchor" href="#◆-3-1-2-删除索引" aria-hidden="true">#</a> ◆ 3.1.2 删除索引</h3>
<blockquote>
<blockquote>
<p>ES中删除索引的请求类型是DELETE，其请求形式如下：[插图][插图][插图]其中，${index_name}就是将要被删除的索引的名称，例如执行下面的删除命令：[插图][插图][插图]系统返回信息如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-3-关闭索引" tabindex="-1"><a class="header-anchor" href="#◆-3-1-3-关闭索引" aria-hidden="true">#</a> ◆ 3.1.3 关闭索引</h3>
<blockquote>
<blockquote>
<p>3.1.3　关闭索引</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在有些场景下，某个索引暂时不使用，但是后期可能又会使用，这里的使用是指数据写入和数据搜索。这个索引在某一时间段内属于冷数据或者归档数据，这时可以使用索引的关闭功能。索引关闭时，只能通过ES的API或者监控工具看到索引的元数据信息，但是此时该索引不能写入和搜索数据，待该索引被打开后，才能写入和搜索数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>先把索引hotel关闭，请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>此时可以尝试进行数据写入：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES返回信息如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>索引关闭时写入数据将会报错。下面可以尝试进行数据搜索：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-4-打开索引" tabindex="-1"><a class="header-anchor" href="#◆-3-1-4-打开索引" aria-hidden="true">#</a> ◆ 3.1.4 打开索引</h3>
<blockquote>
<blockquote>
<p>索引关闭后，需要开启读写服务时可以将其设置为打开状态。下面的示例是把处于关闭状态的hotel索引设置为打开状态。[插图][插图][插图]索引被打开后，就可以对其进行读写操作了</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-5-索引别名" tabindex="-1"><a class="header-anchor" href="#◆-3-1-5-索引别名" aria-hidden="true">#</a> ◆ 3.1.5 索引别名</h3>
<blockquote>
<blockquote>
<p>别名是指给一个或者多个索引定义另外一个名称，使索引别名和索引之间可以建立某种逻辑关系。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以用别名表示别名和索引之间的包含关系。例如，我们建立了1月、2月、3月的用户入住酒店的日志索引，假设当前日期是4月1日，需要搜索过去的3个月的日志索引，如果分别去3个索引中进行搜索，这种编码方案比较低效。此时可以创建一个别名last_three_month，设置前面的3个索引的别名为last_three_month，然后在last_three_month中进行搜索即可。如图3.1所示，last_three_month包含january_log、february_log和march_log3个索引，用户请求在last_three_month中进行搜索时，ES会在上述3个索引中进行搜索。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先依次建立january_log、february_log和march_log3个索引。创建索引january_log的DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这3个索引除了索引名称不一样，其他的参数都是一样的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面分别在3个索引中写入同一用户在不同月份的入住记录。在索引january_log中写入记录的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在索引february_log中写入记录的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在索引march_log中写入记录的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在建立别名last_three_month，设置上面3个索引的别名为last_three_month，请求的DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>请求在索引last_three_month中搜索uid为001的用户的入住记录，搜索的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索结果返回的数据如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当请求搜索last_three_month的数据时，ES将请求转发到了january_log、february_log和march_log3个索引中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在默认情况下，当一个别名只指向一个索引时，写入数据的请求可以指向这个别名，如果这个别名指向多个索引（就像上面的例子），则写入数据的请求是不可以指向这个别名的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在默认情况下，ES不能确定向last_three_month写入数据时的转发对象。这种情况需要在别名设置时，将目标索引的is_write_index属性值设置为true来指定该索引可用于执行数据写入操作。例如设置january_log为数据写入转发对象，对应的DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>此时可以再向last_three_month中写入上面的数据</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设一个酒店的搜索别名设置为hotel，初期创建索引hotel_1时，主分片个数设置为5，然后设置hotel_1的别名为hotel。此时客户端使用索引别名hotel进行搜索请求，该请求会转发到索引hotel_1中。假设此时酒店索引中的新增数据急剧增长，索引分片需要扩展，需要将其扩展成为10个分片的索引。但是一个索引在创建后，主分片个数已经不能更改，因此只能考虑使用索引替换来完成索引的扩展。这时可以创建一个索引hotel_2，除了将其主分片个数设置为10外，其他设置与hotel_1相同。当hotel_2的索引数据准备好后，删除hotel_1的别名hotel，同时，置hotel_2的别名为hotel。此时客户端不用进行任何改动，继续使用hotel进行搜索请求时，该请求会转发给索引hotel_2。如果服务稳定，最后将hotel_1删除即可。此时借助别名就完成了一次索引替换工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3.2　借助别名进行索引替代</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先建立索引hotel_1，设置其主分片个数为5，其他信息与创建索引时保持一致。[插图][插图][插图]在数据写入端向hotel_1写入搜索数据，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>建立别名hotel，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在搜索请求端使用hotel进行搜索，假设在title字段中搜索“再来”，搜索的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES返回的数据如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>因为只有索引hotel_1的别名为hotel，所以向索引别名hotel发起搜索请求时ES会将搜索请求全部转发给索引hotel_1。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-映射操作" tabindex="-1"><a class="header-anchor" href="#◆-3-2-映射操作" aria-hidden="true">#</a> ◆ 3.2 映射操作</h3>
<blockquote>
<blockquote>
<p>3.2　映射操作</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在使用数据之前，需要构建数据的组织结构。这种组织结构在关系型数据库中叫作表结构，在ES中叫作映射。作为无模式搜索引擎，ES可以在数据写入时猜测数据类型，从而自动创建映射。但有时ES创建的映射中的数据类型和目标类型可能不一致。当需要严格控制数据类型时，还是需要用户手动创建映射。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-1-查看映射" tabindex="-1"><a class="header-anchor" href="#◆-3-2-1-查看映射" aria-hidden="true">#</a> ◆ 3.2.1 查看映射</h3>
<blockquote>
<blockquote>
<p>查看索引hotel的mappings，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES的返回结果如下：[插图][插图][插图]通过返回信息可见，查看索引hotel的mappings时，返回的信息和建立该索引时的信息是一致的。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-2-扩展映射" tabindex="-1"><a class="header-anchor" href="#◆-3-2-2-扩展映射" aria-hidden="true">#</a> ◆ 3.2.2 扩展映射</h3>
<blockquote>
<blockquote>
<p>映射中的字段类型是不可以修改的，但是字段可以扩展。最常见的扩展方式是增加字段和为object（对象）类型的数据新增属性。下面的DSL示例为扩展hotel索引，并增加tag字段。[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-3-基本的数据类型" tabindex="-1"><a class="header-anchor" href="#◆-3-2-3-基本的数据类型" aria-hidden="true">#</a> ◆ 3.2.3 基本的数据类型</h3>
<blockquote>
<blockquote>
<p>3.2.3　基本的数据类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.keyword类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>keyword类型是不进行切分的字符串类型。这里的“不进行切分”指的是：在索引时，对keyword类型的数据不进行切分，直接构建倒排索引；在搜索时，对该类型的查询字符串不进行切分后的部分匹配。keyword类型数据一般用于对文档的过滤、排序和聚合。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>keyword经常用于描述姓名、产品类型、用户ID、URL和状态码等。keyword类型数据一般用于比较字符串是否相等，不对数据进行部分匹配，因此一般查询这种类型的数据时使用term查询。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例如，建立一个人名索引，可以设定姓名字段为keyword字段：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在写入一条数据，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面查询刚刚写入的数据，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>返回的结果信息如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用term进行全字符串匹配“张三”可以搜索到命中文档。下面的DSL使用match搜索姓名中带有“张”的记录：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>返回结果如下：[插图][插图][插图]由搜索结果可见，对keyword类型使用match搜索进行匹配是不会命中文档的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.text类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>text类型是可进行切分的字符串类型。这里的“可切分”指的是：在索引时，可按照相应的切词算法对文本内容进行切分，然后构建倒排索引；在搜索时，对该类型的查询字符串按照用户的切词算法进行切分，然后对切分后的部分匹配打分。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例如，一个酒店搜索项目，我们希望可以根据酒店名称即title字段进行模糊匹配，因此可以设定title字段为text字段，建立酒店索引的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在写入一条数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面先按照普通的term进行搜索，观察能否搜索到刚刚写入的文档，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>返回结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>根据返回结果可知，上面的请求并没有搜索到文档。term搜索用于搜索值和文档对应的字段是否完全相等，而对于text类型的数据，在建立索引时ES已经进行了切分并建立了倒排索引，因此使用term没有搜索到数据。一般情况下，搜索text类型的数据时应使用match搜索。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]返回结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.数值类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES支持的数值类型有long、integer、short、byte、double、float、half_float、scaled_float和unsigned_long等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为节约存储空间并提升搜索和索引的效率，在实际应用中，在满足需求的情况下应尽可能选择范围小的数据类型。比如，年龄字段的取值最大值不会超过200，因此选择byte类型即可。数值类型的数据也可用于对文档进行过滤、排序和聚合。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以酒店搜索为例，酒店的索引除了包含酒店名称和城市之外，还需要定义价格、星级和评论数等，创建索引的DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于数值型数据，一般使用term搜索或者范围搜索。例如，搜索价格为350～400（包含350和400）元的酒店，搜索的DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.布尔类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>布尔类型使用boolean定义，用于业务中的二值表示，如商品是否售罄，房屋是否已租，酒店房间是否满房等。写入或者查询该类型的数据时，其值可以使用true和false，或者使用字符串形式的&quot;true&quot;和&quot;false&quot;。下面的DSL定义索引中“是否满房”的字段为布尔类型：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面的DSL将查询满房的酒店：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.日期类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在ES中，日期类型的名称为date。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面定义索引hotel，该索引有一个create_time字段，现在把它定义成date类型。定义date类型请求的DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般使用如下形式表示日期类型数据：·格式化的日期字符串。·毫秒级的长整型，表示从1970年1月1日0点到现在的毫秒数。·秒级别的整型，表示从1970年1月1日0点到现在的秒数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>日期类型的默认格式为strict_date_optional_time||epoch_millis。其中，strict_date_optional_time的含义是严格的时间类型，支持yyyy-MM-dd、yyyyMMdd、yyyyMMddHHmmss、yyyy-MM-ddTHH:mm:ss、yyyy-MM-ddTHH:mm:ss.SSS和yyyy-MM-ddTHH:mm:ss.SSSZ等格式，epoch_millis的含义是从1970年1月1日0点到现在的毫秒数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面写入索引的文档中有一个create_time字段是日期格式的字符串，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索日期型数据时，一般使用ranges查询。例如，搜索创建日期为2015年的酒店，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>日期类型默认不支持yyyy-MM-dd HH:mm:ss格式，如果经常使用这种格式，可以在索引的mapping中设置日期字段的format属性为自定义格式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-4-复杂的数据类型" tabindex="-1"><a class="header-anchor" href="#◆-3-2-4-复杂的数据类型" aria-hidden="true">#</a> ◆ 3.2.4 复杂的数据类型</h3>
<blockquote>
<blockquote>
<p>3.2.4　复杂的数据类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.数组类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果事先已经定义了字段类型，在写数据时以数组形式写入，ES也会将该类型转为数组。例如，为hotel索引增加一个标签字段，名称为tag，请求的DSL如下：[插图][插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>查看一下索引hotel的mapping：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过返回的mapping信息来看，新增的tag字段与普通的keyword类型字段没什么区别，现在写入一条数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>查看一下写入的数据，ES返回的信息如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>写入的数据的tag字段已经是数组类型了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数组类型的字段适用于元素类型的搜索方式，也就是说，数组元素适用于什么搜索，数组字段就适用于什么搜索。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的示例中，数组元素类型是keyword，该类型可以适用于term搜索，则tag字段也可以适用于term搜索，搜索的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.对象类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实际业务中，一个文档需要包含其他内部对象。例如，在酒店搜索需求中，用户希望酒店信息中包含评论数据。评论数据分为好评数量和差评数量。为了支持这种业务，在ES中可以使用对象类型。和数组类型一样，对象类型也不用事先定义，在写入文档的时候ES会自动识别并转换为对象类型。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面将在hotel索引中添加一条记录，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行以上DSL后，索引hotel增加了一个字段comment_info，它有两个属性，分别是favourable_comment和negative_comment，二者的类型都是long。下面查看mapping进行验证：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>根据对象类型中的属性进行搜索，可以直接用“。”操作符进行指向。例如，搜索hotel索引中好评数大于200的文档，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对象内部还可以包含对象。例如，评论信息字段comment_info可以增加前3条好评数据，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.地理类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户需要根据某个地理位置来搜索酒店，此时可以把酒店的经纬度数据设置为地理数据类型。该类型的定义需要在mapping中指定目标字段的数据类型为geo_point类型，示例如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>location字段定义为地理类型，现在向索引中写入一条酒店文档，DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-5-动态映射" tabindex="-1"><a class="header-anchor" href="#◆-3-2-5-动态映射" aria-hidden="true">#</a> ◆ 3.2.5 动态映射</h3>
<blockquote>
<blockquote>
<p>3.2.5　动态映射</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当字段没有定义时，ES可以根据写入的数据自动定义该字段的类型，这种机制叫作动态映射。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表3.1　JSON类型和索引类型对应表[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在一般情况下，如果使用基本类型数据，最好先把数据类型定义好，因为ES的动态映射生成的字段类型可能会与用户的预期有差别。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-6-多字段" tabindex="-1"><a class="header-anchor" href="#◆-3-2-6-多字段" aria-hidden="true">#</a> ◆ 3.2.6 多字段</h3>
<blockquote>
<blockquote>
<p>3.2.6　多字段</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>针对同一个字段，有时需要不同的数据类型，这通常表现在为了不同的目的以不同的方式索引相同的字段。例如，在订单搜索系统中，既希望能够按照用户姓名进行搜索，又希望按照姓氏进行排列，可以在mapping定义中将姓名字段先后定义为text类型和keyword类型，其中，keyword类型的字段叫作子字段，这样ES在建立索引时会将姓名字段建立两份索引，即text类型的索引和keyword类型的索引。订单搜索索引的定义如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以在普通搜索中使用user_name字段，DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-文档操作" tabindex="-1"><a class="header-anchor" href="#◆-3-3-文档操作" aria-hidden="true">#</a> ◆ 3.3 文档操作</h3>
<blockquote>
<blockquote>
<p>使用ES构建搜索引擎时需要经常对文档进行操作。除了简单的单条文档操作，有时还需要进行批量操作。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-1-单条写入文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-1-单条写入文档" aria-hidden="true">#</a> ◆ 3.3.1 单条写入文档</h3>
<blockquote>
<blockquote>
<p>在ES中写入文档请求的类型是POST，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上面的_id就是ES中的文档_id，这种请求方式是用户直接定义_id值，不使用ES生成的_id。请求的数据体即为写入的文档数据，格式是JSON形式。例如，在目标索引中写入下面数据：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES返回的结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由以上结果可知，向hotel索引中写入文档成功。另外，ES在返回结果中还会显示文档的版本，这里因为文档刚刚建立，所以当前值为1。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户也可以不指定文档_id，该_id值将由ES自动生成，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>写入上面的文档时不指定文档_id，请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-2-批量写入文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-2-批量写入文档" aria-hidden="true">#</a> ◆ 3.3.2 批量写入文档</h3>
<blockquote>
<blockquote>
<p>在ES中批量写入文档请求的类型是POST，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>请求体的第一行表示写入的第一条文档对应的元数据，其中，index_name表示写入的目标索引，第2行表示数据体，第3行表示写入的第二条文档对应的元数据，第4行表示数据体。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>向hotel索引中批量写入两条酒店数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上面的DSL写入索引中的文档_id是ES自动生成的。如果需要指定_id，则应该在元数据中添加_id。例如，下面的DSL将向酒店索引中添加文档_id为001和002两条文档：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实际使用过程中需要批量写入的文档比较多，有时甚至上千条或者上万条，这时如果使用Kibana的请求页面就很不方便了。一般使用Linux系统中的curl命令进行数据的批量写入。curl命令支持上传文件，用户可以将批量写入的JSON数据保存到文件中，然后使用curl命令进行提交。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行curl命令将上述两个文档批量写入hotel索引中：[插图][插图][插图]其中，bulk_doc.json是文件名称，文件内容如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-3-更新单条文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-3-更新单条文档" aria-hidden="true">#</a> ◆ 3.3.3 更新单条文档</h3>
<blockquote>
<blockquote>
<p>3.3.3　更新单条文档</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在ES中更新索引的请求类型是POST，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上面的_id就是将要修改的ES文档中的_id，修改后的字段和值将会填写到大括号中，其格式是JSON形式。例如把_id为001的文档修改成下面的数据：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行上述命令后，ES返回的结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了普通的update功能，ES还提供了upsert。upsert即是update和insert的合体字，表示更新/插入数据。如果目标文档存在，则执行更新逻辑；否则执行插入逻辑。以下DSL演示了upsert的应用：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-4-批量更新文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-4-批量更新文档" aria-hidden="true">#</a> ◆ 3.3.4 批量更新文档</h3>
<blockquote>
<blockquote>
<p>与批量写入文档相似，批量更新文档的请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>与批量写入文档不同的是，批量更新文档必须在元数据中填写需要更新的文档_id。下面的DSL将批量更新_id为001和002的文档：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-5-根据条件更新文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-5-根据条件更新文档" aria-hidden="true">#</a> ◆ 3.3.5 根据条件更新文档</h3>
<blockquote>
<blockquote>
<p>在索引数据的更新操作中，有些场景需要根据某些条件同时更新多条数据，类似于在RDBMS中使用update table table_name set…where…更新一批数据。为了满足这样的需求，ES为用户提供了_update_by_query功能，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上面的query用于指定更新数据的匹配条件，相当于SQL中的where语句；script用于指定具体的更新操作，相当于SQL的set内容。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果更新所有文档中的某个字段应该如何操作呢？其实，_update_by_query中的query子句可以不定义，这种情况下ES会选中所有的文档执行script中的内容。以下为修改所有酒店中城市为“上海”的DSL：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-6-删除单条文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-6-删除单条文档" aria-hidden="true">#</a> ◆ 3.3.6 删除单条文档</h3>
<blockquote>
<blockquote>
<p>在ES中删除文档的请求的类型是DELETE，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上面的_id就是将要删除的ES文档的_id。执行下面的删除命令：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-7-批量删除文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-7-批量删除文档" aria-hidden="true">#</a> ◆ 3.3.7 批量删除文档</h3>
<blockquote>
<blockquote>
<p>与批量写入和更新文档不同的是，批量删除文档不需要提供JSON数据，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例如，下面的DSL将批量删除_id为001和002的文档：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-8-根据条件删除文档" tabindex="-1"><a class="header-anchor" href="#◆-3-3-8-根据条件删除文档" aria-hidden="true">#</a> ◆ 3.3.8 根据条件删除文档</h3>
<blockquote>
<blockquote>
<p>和条件更新操作类似，有些场景需要根据某些条件同时删除多条数据，类似于在RDBMS中使用deletetable_name where…删除一批数据。为了满足这样的需求，ES为用户提供了_delete_by_query功能，其请求形式如下：[插图][插图][插图]query子句用于指定删除数据的匹配条件，相当于SQL中的where语句。下面的DSL将把city为北京的文档删除：[插图][插图]</p>
</blockquote>
</blockquote>
<h2 id="◆-第4章-丰富的搜索功能" tabindex="-1"><a class="header-anchor" href="#◆-第4章-丰富的搜索功能" aria-hidden="true">#</a> ◆ 第4章 丰富的搜索功能</h2>
<blockquote>
<blockquote>
<p>ES为用户提供了丰富的搜索功能：既有基本的搜索功能，又有搜索建议功能；既有常用的普通类型的匹配功能，又有基于地理位置的搜索功能；既提供了分页搜索功能，又提供了搜索的调试分析功能。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-搜索辅助功能" tabindex="-1"><a class="header-anchor" href="#◆-4-1-搜索辅助功能" aria-hidden="true">#</a> ◆ 4.1 搜索辅助功能</h3>
<blockquote>
<blockquote>
<p>ES提供的各种搜索辅助功能。例如，为优化搜索性能，需要指定搜索结果返回一部分字段内容。为了更好地呈现结果，需要用到结果计数和分页功能；当遇到性能瓶颈时，需要剖析搜索各个环节的耗时；面对不符合预期的搜索结果时，需要分析各个文档的评分细节。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-1-指定返回的字段" tabindex="-1"><a class="header-anchor" href="#◆-4-1-1-指定返回的字段" aria-hidden="true">#</a> ◆ 4.1.1 指定返回的字段</h3>
<blockquote>
<blockquote>
<p>考虑到性能问题，需要对搜索结果进行“瘦身”——指定返回的字段。在ES中，通过_source子句可以设定返回结果的字段。_source指向一个JSON数组，数组中的元素是希望返回的字段名称。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>定义酒店索引的结构如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为方便演示，向酒店索引中新增如下数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面的DSL指定搜索结果只返回title和city字段：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行上述DSL后，搜索结果如下：[插图][插图][插图]在上述搜索结果中，每个命中文档的_source结构体中只包含指定的city和title两个字段的数据。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-2-结果计数" tabindex="-1"><a class="header-anchor" href="#◆-4-1-2-结果计数" aria-hidden="true">#</a> ◆ 4.1.2 结果计数</h3>
<blockquote>
<blockquote>
<p>为提升搜索体验，需要给前端传递搜索匹配结果的文档条数，即需要对搜索结果进行计数。针对这个要求，ES提供了_count API功能，在该API中，用户提供query子句用于结果匹配，ES会返回匹配的文档条数。下面的DSL将返回城市为“北京”的酒店个数：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行上述DSL后，返回信息如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES不仅返回了匹配的文档数量（值为3），并且还返回了和分片相关的元数据，如总共扫描的分片个数，以及成功、失败、跳过的分片个数等。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-3-结果分页" tabindex="-1"><a class="header-anchor" href="#◆-4-1-3-结果分页" aria-hidden="true">#</a> ◆ 4.1.3 结果分页</h3>
<blockquote>
<blockquote>
<p>在实际的搜索应用中，分页是必不可少的功能。在默认情况下，ES返回前10个搜索匹配的文档。用户可以通过设置from和size来定义搜索位置和每页显示的文档数量，from表示查询结果的起始下标，默认值为0，size表示从起始下标开始返回的文档个数，默认值为10。下面的DSL将返回下标从0开始的20个结果。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在默认情况下，用户最多可以取得10 000个文档，即from为0时，size参数最大为10 000，如果请求超过该值，ES返回如下报错信息：[插图][插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于普通的搜索应用来说，size设为10 000已经足够用了。如果确实需要返回多于10 000条的数据，可以适当修改max_result_window的值。以下示例将hotel索引的最大窗口值修改为了20 000。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作为一个分布式搜索引擎，一个ES索引的数据分布在多个分片中，而这些分片又分配在不同的节点上。一个带有分页的搜索请求往往会跨越多个分片，每个分片必须在内存中构建一个长度为from+size的、按照得分排序的有序队列，用以存储命中的文档。然后这些分片对应的队列数据都会传递给协调节点，协调节点将各个队列的数据进行汇总，需要提供一个长度为number_of_shards*（from+size）的队列用以进行全局排序，然后再按照用户的请求从from位置开始查找，找到size个文档后进行返回。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于上述原理，ES不适合深翻页。什么是深翻页呢？简而言之就是请求的from值很大。假设在一个3个分片的索引中进行搜索请求，参数from和size的值分别为1000和10</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4.1　深翻页响应</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当深翻页的请求过多时会增加各个分片所在节点的内存和CPU消耗。尤其是协调节点，随着页码的增加和并发请求的增多，该节点需要对这些请求涉及的分片数据进行汇总和排序，过多的数据会导致协调节点资源耗尽而停止服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作为搜索引擎，ES更适合的场景是对数据进行搜索，而不是进行大规模的数据遍历。一般情况下，只需要返回前1000条数据即可，没有必要取到10 000条数据。如果确实有大规模数据遍历的需求，可以参考使用scroll模式或者考虑使用其他的存储引擎。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-4-性能分析" tabindex="-1"><a class="header-anchor" href="#◆-4-1-4-性能分析" aria-hidden="true">#</a> ◆ 4.1.4 性能分析</h3>
<blockquote>
<blockquote>
<p>在使用ES的过程中，有的搜索请求的响应可能比较慢，其中大部分的原因是DSL的执行逻辑有问题。ES提供了profile功能，该功能详细地列出了搜索时每一个步骤的耗时，可以帮助用户对DSL的性能进行剖析。开启profile功能只需要在一个正常的搜索请求的DSL中添加&quot;profile&quot;:&quot;true&quot;即可。以下查询将开启profile功能：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>执行以上DSL后ES返回了一段比较冗长的信息</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在带有profile的返回信息中，除了包含搜索结果外，还包含profile子句，在该子句中展示了搜索过程中各个环节的名称及耗时情况。需要注意的是，使用profile功能是有资源损耗的，建议用户只在前期调试的时候使用该功能，在生产中不要开启profile功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>因为一个搜索可能会跨越多个分片，所以使用shards数组放在profile子句中。每个shard子句中包含3个元素，分别是id、searches和aggregations。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·id表示分片的唯一标识，它的组成形式为[nodeID][indexName][shardID]。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·searches以数组的形式存在，因为有的搜索请求会跨多个索引进行搜索。每一个search子元素即为在同一个索引中的子查询，此处不仅返回了该search子元素耗时为322 496ns的信息，而且还返回了搜索“金都”的详细策略，即被拆分成“title:金”和“title:都”两个子查询。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·aggregations只有在进行聚合运算时才有内容</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>profile返回的信息将特别冗长。在这种情况下，用户进行性能剖析的效率将非常低。为此，Kibana提供了可视化的profile功能，该功能建立在ES的profile功能基础上。在Kibana的Dev Tools界面中单击Search Profiler链接，就可以使用可视化的profile了</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-5-评分分析" tabindex="-1"><a class="header-anchor" href="#◆-4-1-5-评分分析" aria-hidden="true">#</a> ◆ 4.1.5 评分分析</h3>
<blockquote>
<blockquote>
<p>如果用户不指定按照某个字段进行升序或者降序排列，那么ES会使用自己的打分算法对文档进行排序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES提供了explain功能来帮助使用者查看搜索时的匹配详情。explain的使用形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例为按照标题进行搜索的explain查询请求：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果一个文档和查询不匹配，explain也会直接返回信息告知用户，具体如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-丰富的搜索匹配功能" tabindex="-1"><a class="header-anchor" href="#◆-4-2-丰富的搜索匹配功能" aria-hidden="true">#</a> ◆ 4.2 丰富的搜索匹配功能</h3>
<blockquote>
<blockquote>
<p>ES提供了很多搜索匹配功能：既有进行完全匹配的term搜索，也有按照范围匹配的range搜索；既有进行分词匹配的match搜索，也有按照前缀匹配的suggest搜索。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-1-查询所有文档" tabindex="-1"><a class="header-anchor" href="#◆-4-2-1-查询所有文档" aria-hidden="true">#</a> ◆ 4.2.1 查询所有文档</h3>
<blockquote>
<blockquote>
<p>在关系型数据库中，当需要查询所有文档的数据时，对应的SQL语句为select*form table_name。在ES中是否有类似的功能呢？答案是“有”，使用ES的match_all查询可以完成类似的功能。使用match_all查询文档时，ES不对文档进行打分计算，默认情况下给每个文档赋予1.0的得分。用户可以通过boost参数设定该分值。以下示例使用match_all查询所有文档，并设定所有文档的分值为2.0：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-2-term级别查询" tabindex="-1"><a class="header-anchor" href="#◆-4-2-2-term级别查询" aria-hidden="true">#</a> ◆ 4.2.2 term级别查询</h3>
<blockquote>
<blockquote>
<p>1.term查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>term查询是结构化精准查询的主要查询方式，用于查询待查字段和查询值是否完全匹配</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>FIELD和VALUE分别代表字段名称和查询值，FIELD的数据类型可以是数值型、布尔型、日期型、数组型及关键字等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例是搜索住宿价格为500元的酒店，price字段为数值型数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例是搜索城市为北京的酒店，city字段为关键字类型数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例是搜索没有满房的酒店，full_room（满房状态）字段为布尔型数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于日期型的字段查询，需要按照该字段在mappings中定义的格式进行查询。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES的默认格式中不包含yyyy-MM-ddHH:mm:ss格式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.terms查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>terms查询是term查询的扩展形式，用于查询一个或多个值与待查字段是否完全匹配，其请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>FIELD代表待查字段名，VALUE1和VALUE2代表多个查询值，FIELD的数据类型可以是数值型、布尔型、日期型、数组型及关键字等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下是搜索城市为“北京”或者“天津”的酒店示例：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.range查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>range查询用于范围查询，一般是对数值型和日期型数据的查询。使用range进行范围查询时，用户可以按照需求中是否包含边界数值进行选项设置，可供组合的选项如下：·gt：大于；·lt：小于；·gte：大于或等于；·lte：小于或等于。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下是数值类型的查询示例，查询住宿价格在300～500（包含边界值）元的酒店：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用range查询时，查询值必须符合该字段在mappings中设置的规范。例如，在酒店索引中，price字段是double类型，则range应该使用数值型或者数值类型的字符串形式，不能使用其他形式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>和term查询类似，查询日期型的字段时，需要遵循该字段在mappings中定义的格式进行查询。例如，create_time使用的是默认格式，并且统一采用的是“yyyyMMddHHmmss”格式，则range查询应该使用如下方式：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.exists查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在某些场景下，我们希望找到某个字段不为空的文档，则可以用exists搜索。字段不为空的条件有：·值存在且不是null；·值不是空数组；·值是数组，但不是[null]。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-3-布尔查询" tabindex="-1"><a class="header-anchor" href="#◆-4-2-3-布尔查询" aria-hidden="true">#</a> ◆ 4.2.3 布尔查询</h3>
<blockquote>
<blockquote>
<p>复合搜索，顾名思义是一种在一个搜索语句中包含一种或多种搜索子句的搜索。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>布尔查询是常用的复合查询，它把多个子查询组合成一个布尔表达式，这些子查询之间的逻辑关系是“与”，即所有子查询的结果都为true时布尔查询的结果才为真。布尔查询还可以按照各个子查询的具体匹配程度对文档进行打分计算。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>布尔查询支持的子查询有四种，各子查询的名称和功能如表4.1所示。表4.1　布尔查询中各子查询的功能[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.must查询当查询中包含must查询时，相当于逻辑查询中的“与”查询。命中的文档必须匹配该子查询的结果，并且ES会将该子查询与文档的匹配程度值加入总得分里。must搜索包含一个数组，可以把其他的term级别的查询及布尔查询放入其中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例使用must查询城市为北京并且价格在350～400元的酒店：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.should查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当查询中包含should查询时，表示当前查询为“或”查询。命中的文档可以匹配该查询中的一个或多个子查询的结果，并且ES会将该查询与文档的匹配程度加入总得分里。should查询包含一个数组，可以把其他的term级别的查询及布尔查询放入其中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例使用should查询城市为北京或者天津的酒店。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.must not查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当查询中包含must not查询时，表示当前查询为“非”查询。命中的文档不能匹配该查询中的一个或多个子查询的结果，ES会将该查询与文档的匹配程度加入总得分里。must not查询包含一个数组，可以把其他term级别的查询及布尔查询放入其中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例中使用must not查询城市不是北京也不是天津的酒店：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.filter查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>filter查询即过滤查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其他布尔查询关注的是查询条件和文档的匹配程度，并按照匹配程度进行打分；而filter查询关注的是查询条件和文档是否匹配，不进行相关的打分计算，但是会对部分匹配结果进行缓存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下为使用filter的简单的例子：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以上是请求城市为北京并且未满房的酒店的查询结果。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-4-filter查询原理" tabindex="-1"><a class="header-anchor" href="#◆-4-2-4-filter查询原理" aria-hidden="true">#</a> ◆ 4.2.4 filter查询原理</h3>
<blockquote>
<blockquote>
<p>4.2.4　filter查询原理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设当前有5个文档，ES对于city字段的倒排索引结构如图4.6所示。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES对于满房字段倒排的索引结构如图4.7所示。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当ES执行过滤条件时，会查询缓存中是否有city字段值为“北京”对应的bitset数据。bitset，中文为位图，它可以用非常紧凑的格式来表示给定范围内的连续数据。如果查询缓存中有对应的bitset数据，则取出备用；如果缓存中没有bitset数据，则ES在查询数据后会对查询条件进行bitset的构建并将其放入缓存中。同时，ES也会考察满房字段为false是否有对应的bitset数据。如果有，则取出备用；如果缓存中没有，ES也会进行bitset的构建。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设city字段值为“北京”，缓存中没有对应的bitset数据，则bitset构建的过程如下：首先，ES在倒排索引中查找字段city值为“北京”字符串的文档，这里为doc1和doc5。然后为所有文档构建bitset数组，数组中每个元素的值用来表示对应位置的文档是否和查询条件匹配，0表示未匹配，1表示匹配。在本例中，doc1和doc5匹配“北京”，对应位置的值为1；doc2、doc3、doc4不匹配，对应位置的值为0。最终，本例的bitset数组为[1,0,0,0,1]。之所以用bitset表示文档和query的匹配结果，是因为该结构不仅节省空间而且后续进行操作时也能节省时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果满房字段缓存中没有对应的bitset数据，ES构建满房字段为false对应bitset的过程也是类似的。如图4.8所示为ES构建的字段city值为“北京”和满房字段值为false时对应的bitset结构。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>接下来ES会遍历查询条件的bitset数组，按照文档命中与否进行文档过滤。当一个请求中有多个filter查询条件时，ES会构建多个bitset数组。为提升效率，ES会从最稀疏的数组开始遍历，因为遍历稀疏的数组可以过滤掉更多的文档。此时，城市为“北京”对应的bitset比满房为false的bitset更加稀疏，因此先遍历城市为“北京”的bitset，再遍历满房为false的bitset。遍历的过程中也进行了位运算，每次运算的结果都逐渐接近符合条件的结果。遍历计算完这两个bitset后，得到匹配所有过滤条件的文档，即doc1和doc5。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果查询内包含filter，那么ES首先就从缓存中搜索这个filter条件是否有执行记录，是否有对应的bitset缓存可查询。如果有，则从缓存中查询；如果没有，则为filter中的每个查询项新建bitset，并且缓存该bitset，以供后续其他带有filter的查询可以先在缓存中查询。也就是说，ES对于bitset是可重用的，这种重用的机制叫作filter cache（过滤器缓存）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>filter cache会跟踪每一个filter查询，ES筛选一部分filter查询的bitset进行缓存。首先，这些过滤条件要在最近256个查询中出现过；其次，这些过滤条件的次数必须超过某个阈值。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>filter cache是有自动更新机制的，即如果有新增文档或者文档被修改过，那么filter cache对应的过滤条件中的bitset将被更新。例如城市为“北京”过滤条件对应的bitset为[1,0,0,0,1]，如果文档4的城市被修改为“北京”，则“北京”过滤条件对应的bitset会被自动更新为[1,0,0,1,1]。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用filter查询的子句是不计算分数的，这可以减少不小的时间开销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果某些匹配条件不需要打分操作的话，那么应该把这些查询全部改成filter形式，让查询更高效。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-5-constant-score查询" tabindex="-1"><a class="header-anchor" href="#◆-4-2-5-constant-score查询" aria-hidden="true">#</a> ◆ 4.2.5 Constant Score查询</h3>
<blockquote>
<blockquote>
<p>如果不想让检索词频率TF（Term Frequency）对搜索结果排序有影响，只想过滤某个文本字段是否包含某个词，可以使用Constant Score将查询语句包装起来。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设需要查询amenities字段包含关键词“停车场”的酒店，则请求的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>查询结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用Constant Score搜索时，命中的酒店文档对应的amenities字段都包含有“停车场”一词。但是不论该词在文档中出现多少次，这些文档的得分都是一样的，值为1.0。在Constant Score搜索中，参数boost可以控制命中文档的得分，默认值为1.0。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-6-function-score查询" tabindex="-1"><a class="header-anchor" href="#◆-4-2-6-function-score查询" aria-hidden="true">#</a> ◆ 4.2.6 Function Score查询</h3>
<blockquote>
<blockquote>
<p>当使用ES进行搜索时，命中的文档默认按照相关度进行排序。有些场景下用户需要干预该“相关度”，此时就可以使用Function Score查询。使用时，用户必须定义一个查询以及一个或多个函数，这些函数为每个文档计算一个新分数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面使用一个随机函数对查询结果进行排序：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本例使用了简单的term查询，functions子句负责输出对文档的排序分值，此处使用了random_score随机函数，使得每个文档的分数都是随机生成的。每次执行上述查询时生成的文档分数都不同。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-7-全文搜索" tabindex="-1"><a class="header-anchor" href="#◆-4-2-7-全文搜索" aria-hidden="true">#</a> ◆ 4.2.7 全文搜索</h3>
<blockquote>
<blockquote>
<p>不同于结构化查询，全文搜索首先对查询词进行分析，然后根据查询词的分词结果构建查询。这里所说的全文指的是文本类型数据（text类型），默认的数据形式是人类的自然语言，如对话内容、图书名称、商品介绍和酒店名称等。结构化搜索关注的是数据是否匹配，全文搜索关注的是匹配的程度；结构化搜索一般用于精确匹配，而全文搜索用于部分匹配。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.match查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>match查询是全文搜索的主要代表。对于最基本的math搜索来说，只要分词中的一个或者多个在文档中存在即可。例如搜索“金都酒店”，查询词先被分词器切分为“金”“都”“酒”“店”，因此，只要文档中包含这4个字中的任何一个字，都会被搜索到。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为什么“金都酒店”被切分成4个字而不是“金都”“酒店”两个词呢？这是因为在默认情况下，match查询使用的是标准分词器。该分词器比较适用于英文，如果是中文则按照字进行切分，因此默认的分词器不适合做中文搜索，</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例为按照标题搜索“金都酒店”：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>或者按照如下方式搜索：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]从结果中可以看到，匹配度最高的文档是004，该酒店的名称和查询词相同，得分为1.4177237；次之的文档是003，因为该酒店名称中包含“金”“都”“酒”“店”，并且标题相对较短，所以部分匹配，得分为1.2164695；再次之的文档是002，虽然该酒店名称中包含“金”“都”“酒”“店”，但是相对于文档003其标题相对较长，因此位居其后。文档001和文档005只有“酒”“店”两个字和查询词部分匹配，因此排在后面，又因为文档005比文档001较长，所以位居最后。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>match搜索可以设置operator参数，该参数决定文档按照分词后的词集合进行“与”还是“或”匹配。在默认情况下，该参数的值为“与”关系，即operator的值为or，这也解释了搜索结果中包含部分匹配的文档。如果希望各个词之间的匹配结果是“与”关系，则可以设置operator参数的值为and。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面的请求示例设置查询词之间的匹配结果为“与”关系：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有时搜索多个关键字，关键词和文档在某一个比例上匹配即可，如果使用“与”操作过于严苛，如果使用“或”操作又过于宽松。这时可以采用minimum_should_match参数，该参数叫作最小匹配参数，其值为一个数值，意义为可以匹配上的词的个数。在一般情况下将其设置为一个百分数，因为在真实场景中并不能精确控制具体的匹配数量。以下示例设置最小匹配为80%的文档：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.multi_match查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有时用户需要在多个字段中查询关键词，除了使用布尔查询封装多个match查询之外，可替代的方案是使用multi_match。可以在multi_match的query子句中组织数据匹配规则，并在fields子句中指定需要搜索的字段列表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面的示例在title和amenities两个字段中同时搜索“假日”关键词：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>命中的文档要么在title中包含“假日”关键词，要么在amenities字段中包含“假日”关键词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.match_phrase查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>match_phrase用于匹配短语，与match查询不同的是，match_phrase用于搜索确切的短语或邻近的词语。假设在酒店标题中搜索“文雅酒店”，希望酒店标题中的“文雅”与“酒店”紧邻并且“文雅”在“酒店”前面，则使用match_phrase查询的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>根据上述结果可知，使用match_phrase查询后，只有文档001命中，而文档005（酒店标题为“文雅精选酒店”）没有命中，这是为什么呢？ES在构建索引时，文档001的title字段被切分为“文雅”“酒店”，文档005的title字段被切分为“文雅”“精选”“酒店”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用match_phrase进行查询时，ES将查询文本“精选酒店”切分为“精选”“酒店”，“文雅”匹配时命中了文档001和文档005，但是“酒店”匹配时要求“酒店”必须在“文雅”之后并且索引位置和“文雅”之差为1，而文档001符合匹配要求但是文档005不符合要求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果需要文档005也命中上述查询，则可以设置match_phrase查询的slop参数，它用来调节匹配词之间的距离阈值。下面的DSL将slop设置为2：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-8-基于地理位置查询" tabindex="-1"><a class="header-anchor" href="#◆-4-2-8-基于地理位置查询" aria-hidden="true">#</a> ◆ 4.2.8 基于地理位置查询</h3>
<blockquote>
<blockquote>
<p>基于地理位置的搜索功能，大大提升了人们的生活和工作效率。例如，外出旅行时，只需要用手机打开订酒店的应用软件，查找附近心仪的酒店下单即可；又或者打车行业，人们不用在寒冷的户外去拦截出租车，只需要在室内打开手机里的打车App定位到当前位置，然后确定目的地，系统就可以为附近的车辆派发订单。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES为用户提供了基于地理位置的搜索功能。它主要支持两种类型的地理查询：一种是地理点（geo_point），即经纬度查询，另一种是地理形状查询（geo_shape），即支持点、线、圆形和多边形查询等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对应于geo_point字段类型的查询方式有3种，分别为geo_distance查询、geo_bounding_box查询和geo_polygon。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>geo_distance查询方式需要用户指定一个坐标点，在指定距离该点的范围后，ES即可查询到相应的文档。假设北京天安门的经纬度为[116.4039,39.915143]，以下为使用geo_distance查询所找到的天安门5km范围内的酒店：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>geo_shape查询提供的是矩形内的搜索，需要用户给出左上角的顶点地理坐标和右下角的顶点地理坐标。假设定义国贸商圈为一个矩形，其左上角顶点的经纬度为[116.457044,39.922821]，右下角顶点的经纬度为[116.479466,39.907104]，则在国贸商圈内搜索酒店的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>geo_polygon比geo_shape提供的地理范围功能更加灵活，它支持多边形内的文档搜索，使用该查询需要提供多边形所有顶点的地理坐标。假设北京地坛公园商圈的地形为三角形，该三角形的三个顶点的经纬度分别为[116.417088,39.959829]、[116.432035,39.960272]和[116.421399,39.965802]，则在地坛公园商圈内搜索酒店的DSL语句如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-9-搜索建议" tabindex="-1"><a class="header-anchor" href="#◆-4-2-9-搜索建议" aria-hidden="true">#</a> ◆ 4.2.9 搜索建议</h3>
<blockquote>
<blockquote>
<p>搜索建议，顾名思义，即在用户输入搜索关键词的过程中系统进行自动补全，用户可以根据自己的需求单击搜索建议的内容直接进行搜索。在搜索时，用户每输入一个字符，前端就需要向后端发送一次查询请求对匹配项进行查询，因此这种场景对后端响应速度的要求比较高。通过协助用户进行搜索，可以避免用户输入错误的关键词，引导用户使用更合适的关键词，提升用户的搜索体验和搜索效率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索建议目前是各大搜索引擎和电商的标配服务，如图4.9所示为在京东商城中输入elastic时的搜索建议示例。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES的搜索建议查询。对于以上应用来说，ES中的Completion Suggester是比较合适的。为了使用Completion Suggester，其对应的字段类型需要定义为completion类型。在以下示例中定义了一个酒店搜索建议的索引：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为方便演示，现在向索引中写入一些候选数据：[插图][插图][插图]假设用户输入“如家”关键词，需要ES给出前缀为该词的酒店查询词，DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>hotel_zh_sug定义的是搜索建议的名称，prefix定义的是用户输入的关键词，completion.field定义的是搜索建议的候选集对应的字段名称。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>和普通搜索不同的是，搜索建议的结果不是封装在hits中，而是单独封装在suggest中。在suggest.hotel_zh_sug.options中可以看到每一个候选集的文档信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES提供的Completion Suggester功能使用的索引结构不是倒排索引，而是在内存中构建FST（Finite StateTransducers）。构建该数据结构是有比较大的内存存储成本的，因此在生产环境中向索引中添加数据时一定要关注ES节点的内存消耗，避免数据量过大造成ES节点内存耗尽从而影响集群服务。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-3-按字段值排序" tabindex="-1"><a class="header-anchor" href="#◆-4-3-按字段值排序" aria-hidden="true">#</a> ◆ 4.3 按字段值排序</h3>
<blockquote>
<blockquote>
<p>在默认情况下，ES对搜索结果是按照相关性降序排序的。有时需要按照某些字段的值进行升序或者降序排序。例如在酒店搜索应用软件中，除了可以按照综合排序外，还可以按照价格、销量、评论数、距离进行升/降序排序。之所以提供这样的功能，是因为存在多种不同的心态促使用户并不只想按照关键词匹配对结果进行浏览。用户单击价格进行升序或降序排列，很可能说明该用户对酒店价格比较敏感；用户按照销量或评论数进行升序或降序排列，很可能说明用户有一些从众心理，希望通过销量或评论数来评估大众对该酒店是否看好，从而筛选心仪的酒店；用户按照距离进行排序，很可能是该用户需要找到距离匹配的酒店。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES提供了sort子句可以对数据进行排序。使用sort子句一般是按照字段信息进行排序，不受相关性影响，而且打分步骤需要耗费一定的硬件资源和时间，因此默认情况下，不对文档进行打分。使用sort排序分为两种类别，一种是按照字段值的大小进行排序，另一种是按照给定地理坐标的距离远近进行排序。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-3-1-按普通字段值排序" tabindex="-1"><a class="header-anchor" href="#◆-4-3-1-按普通字段值排序" aria-hidden="true">#</a> ◆ 4.3.1 按普通字段值排序</h3>
<blockquote>
<blockquote>
<p>使用sort子句对字段值进行排序时需要指定排序的字段。ES默认是按照字段值进行升序排序，可以设置order参数为asc或desc，指定按照字段值进行升序或者降序排序。以下示例为搜索名称包含“金都”的酒店，并对酒店按照价格进行降序排列。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>默认情况下ES查询时使用sort对结果排序是不计算分数的。也可以使用sort对搜索结果按照多个字段进行排序。例如，用户可以按照价格进行降序排列，然后再按照口碑值进行降序排列，对应的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-4-3-2-按地理距离排序" tabindex="-1"><a class="header-anchor" href="#◆-4-3-2-按地理距离排序" aria-hidden="true">#</a> ◆ 4.3.2 按地理距离排序</h3>
<blockquote>
<blockquote>
<p>ES提供的基于地理位置的查询功能，使用geo_distance查询，配合sort可以指定另一种排序规则，即按照文档坐标与指定坐标的距离对结果进行排序。使用时，需要在sort内部指定排序名称为geo_distanc，并指定目的地坐标。除了可以指定升序或者降序排列外，还可以指定排序结果中sort子句中的距离的计量单位，默认值为km即千米。在进行距离计算时，系统默认使用的算法为arc，该算法的特点是计算精准但是耗费时间较长，用户可以使用distance_type参数选择另一种计算速度快但经度略差的算法，名称为plane。如下示例使用geo_distance查询天安门5km范围内的酒店，并按照距离由近及远进行排序：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h2 id="◆-第5章-文本搜索" tabindex="-1"><a class="header-anchor" href="#◆-第5章-文本搜索" aria-hidden="true">#</a> ◆ 第5章 文本搜索</h2>
<blockquote>
<blockquote>
<p>与其他需要精确匹配的数据不同，文本数据在前期的索引构建和搜索环节都需要进行额外的处理，并且在匹配环节还要进行相关性分数计算。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-1-文本搜索简介" tabindex="-1"><a class="header-anchor" href="#◆-5-1-文本搜索简介" aria-hidden="true">#</a> ◆ 5.1 文本搜索简介</h3>
<blockquote>
<blockquote>
<p>ES在文本索引的建立和搜索过程中依赖两大组件，即Lucene和分析器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Lucene负责进行倒排索引的物理构建，分析器负责在建立倒排索引前和搜索前对文本进行分词和语法处理。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-1-1-文本的索引建立过程" tabindex="-1"><a class="header-anchor" href="#◆-5-1-1-文本的索引建立过程" aria-hidden="true">#</a> ◆ 5.1.1 文本的索引建立过程</h3>
<blockquote>
<blockquote>
<p>为了完成对文本的快速搜索，ES使用了一种称为“倒排索引”的数据结构。倒排索引中的所有词语存储在词典中，每个词语又指向包含它的文档信息列表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设需要对下面两个酒店的信息进行倒排索引的创建：·文档ID为001，酒店名称为“金都嘉怡假日酒店”；·文档ID为002，酒店名称为“金都欣欣酒店”。首先，ES将文档交给分析器进行处理，处理的过程包括字符过滤、分词和分词过滤，最终的处理结果是文档内容被表示为一系列关键词信息的集合。这里的关键词信息指的是关键词本身以及它在文档中出现的位置信息和词性信息</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过上面的文档-词语矩阵可知，ES从文档001中提取出4个词语，从文档002中提取出3个词语。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>文档-词语矩阵建立完成之后，接着需要建立基于词语的倒排索引。ES会遍历文档词语矩阵中的每一个词语，然后将包含该词语的文档信息与该词语建立一种映射关系。映射关系中的词语集合叫作TermDictionary，即“词典”。映射中的文档集合信息不仅包含文档ID，还包含词语在文档中的位置和词频信息，包含这些文档信息的结构叫作Posting List。对于一个规模很大的文档集合来说，可能包含几十万甚至上百万的词语集合，能否快速定位某个词语，直接影响搜索时的响应速度。因此需要一种高效的数据结构对映射关系中的词语集合进行索引，这种结构叫作Term Index。上述3种结构结合在一起就构成了ES的倒排索引结构，倒排索引与三者之间的逻辑关系如图5.3所示。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5.3　倒排索引的包含关系</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5.4　倒排索引结构</p>
</blockquote>
</blockquote>
<h3 id="◆-5-1-2-文本的搜索过程" tabindex="-1"><a class="header-anchor" href="#◆-5-1-2-文本的搜索过程" aria-hidden="true">#</a> ◆ 5.1.2 文本的搜索过程</h3>
<blockquote>
<blockquote>
<p>在ES中，一般使用match查询对文本字段进行搜索。match查询过程一般分为如下几步：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）ES将查询的字符串传入对应的分析器中，分析器的主要作用是对查询文本进行分词，并把分词后的每个词语变换为对应的底层lucene term查询。（2）ES用term查询在倒排索引中查找每个term，然后获取一组包含该term的文档集合。（3）ES根据文本相关度对每个文档进行打分计算，打分完毕后，ES把文档按照相关性进行倒序排序。（4）ES根据得分高低返回匹配的文档。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如图5.5所示为对酒店索引中搜索“金都嘉怡”的查询流程。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES分析器先将查询词切分为“金都”和“嘉怡”，然后分别到倒排索引里查找两个词对应的文档列表并获得了文档001和002，然后根据相关性算法计算文档得分并进行排序，最后将文档集合返回给客户端。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-分析器简介" tabindex="-1"><a class="header-anchor" href="#◆-5-2-分析器简介" aria-hidden="true">#</a> ◆ 5.2 分析器简介</h3>
<blockquote>
<blockquote>
<p>ES在文本字段的索引建立和搜索阶段都会用到分析器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分析器的主要作用是什么？它是由哪几部分构成的？各部分的作用又是什么呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分析器一般用在下面两个场景中：·创建或更新文档时（合称索引时），对相应的文本字段进行分词处理；·查询文本字段时，对查询语句进行分词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES中的分析器有很多种，但是所有分析器的结构都遵循三段式原则，即字符过滤器、分词器和词语过滤器。其中，字符过滤器可以有0个或多个，分词器必须只有一个，词语过滤器可以有0个或多个。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>三个部分的数据流方向为字符过滤器→分词器→分词过滤器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5.6　分析器构成示例</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>文本先以字符流的形式流经字符过滤器，在本例中，由两个子字符过滤器组成一个字符过滤器组合。字符过滤器处理完字符后将结果传递给分词器，分词器对文本进行分词处理后将结果又传递给分词过滤器。在本例中，由两个子分词过滤器组成一个分词过滤器组合。最终，分析器输出分词后每个词的信息，至此，一个分析器的处理流程结束。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果在数据写入时指定了某个分析器，那么在匹配查询时也需要设定相同的分析器对查询语句进行分析。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-1-字符过滤器" tabindex="-1"><a class="header-anchor" href="#◆-5-2-1-字符过滤器" aria-hidden="true">#</a> ◆ 5.2.1 字符过滤器</h3>
<blockquote>
<blockquote>
<p>字符过滤器是分析器处理文本数据的第一道工序，它接收原始的字符流，对原始字符流中的字符进行添加、删除或者转换操作，进而改变原始的字符流。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>原始数据中可能包含来自爬虫的结果，字符过滤器可以去除文本中的HTML标签，也可以将原始文本中的一些特殊字符进行转义，如把“＆”转换为and。总而言之，字符过滤器就是对原始文本做一些粗加工的工作，为后续的分词做准备。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表5.1　ES内置的字符过滤器[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-2-分词器" tabindex="-1"><a class="header-anchor" href="#◆-5-2-2-分词器" aria-hidden="true">#</a> ◆ 5.2.2 分词器</h3>
<blockquote>
<blockquote>
<p>对于英文来说，简单的分词器通常是根据空格及标点符号进行切分。然而对于中文分词来说，字符之间往往没有空格，因此采用英文的切分规则是不可取的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分词器对文本进行切分后，需要保留词语与原始文本之间的对应关系，因此分词器还负责记录每个Token的位置，以及开始和结束的字符偏移量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表5.2　ES内置的分词器[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-3-分词过滤器" tabindex="-1"><a class="header-anchor" href="#◆-5-2-3-分词过滤器" aria-hidden="true">#</a> ◆ 5.2.3 分词过滤器</h3>
<blockquote>
<blockquote>
<p>分词过滤器接收分词器的处理结果，并可以将切分好的词语进行加工和修改，进而对分词结果进行规范化、统一化和优化处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>它可以将文本中的字母全部转换为小写形式，还可以删除停用词（如的、这、那等），还可以为某个分词增加同义词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表5.3　ES内置的分词过滤器[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-分析器的使用" tabindex="-1"><a class="header-anchor" href="#◆-5-3-分析器的使用" aria-hidden="true">#</a> ◆ 5.3 分析器的使用</h3>
<blockquote>
<blockquote>
<p>ES提供了分析器的调用API，使用户可以方便地对比不同分析器的分析结果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES提供了一些开箱即用的内置分析器，这些分析器其实就是字符过滤器、分词器和分词过滤器的组合体，可以在索引建立时和搜索时指定使用这些分析器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户还可以自定义分析器。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-1-测试分析api" tabindex="-1"><a class="header-anchor" href="#◆-5-3-1-测试分析api" aria-hidden="true">#</a> ◆ 5.3.1 测试分析API</h3>
<blockquote>
<blockquote>
<p>在DSL中可以直接使用参数analyzer来指定分析器的名称进行测试，分析API的请求形式如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下示例使用standard分析器分析一段英文：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上述文本的分析结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>standard分析器对文本进行分析时，按照空格把上面的句子进行了分词。分析API返回信息的参数说明如下：·token：文本被切分为词语后的某个词语；·start_offset：该词在文本中的起始偏移位置；·end_offset：该词在文本中的结束偏移位置；·type：词性，各个分词器的值不一样；·position：分词位置，指明该词语在原文本中是第几个出现的。start_offset和end_offset组合起来就是该词在原文本中占据的起始位置和结束位置。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面使用standard分析器分析一段中文文本。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分析结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用standard分析器对中文进行分析时，由于中文没有空格，无法根据空格进行切分，因此只能按单字进行切分，并给出了每个单字的词性。在中文里，两个单字的词性和每个单字的词性是不同的，因此使用standard分析器分析中文时给出的词性不具备参考价值。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES内置的其他分析器也不适合分析中文</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户还可以指定某个索引的字段，使用这个字段对应的分析器对目标文本进行分析。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户还可以在API中自定义分析器对文本进行分析。在下面的示例中自定义了一个分析器，该分析器的分词器使用standard，分词过滤器使用Lower Case，其将分词后的结果转换为小写形式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-2-内置分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-3-2-内置分析器" aria-hidden="true">#</a> ◆ 5.3.2 内置分析器</h3>
<blockquote>
<blockquote>
<p>在默认情况下，一个索引的字段类型为text时，该字段在索引建立时和查询时的分析器是standard。standard分析器是由standard分词器、Lower Case分词过滤器和Stop Token分词过滤器构成的。注意，standard分析器没有字符过滤器。除了standard分析器之外，ES还提供了simple分析器、language分析器、whitespace分析器及pattern分析器等，这些分析器的功能如表5.4所示。</p>
<p><img src="@source/docs/theme-reco/D:/BaiduNetdiskDownload/计算机书籍笔记/img/Elasticsearch搜索引擎构建入门与实战/image-20220210203242062.png" alt="image-20220210203242062"></p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表5.4　ES内置的分析器[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-3-索引时使用分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-3-3-索引时使用分析器" aria-hidden="true">#</a> ◆ 5.3.3 索引时使用分析器</h3>
<blockquote>
<blockquote>
<p>文本字段在索引时需要使用分析器进行分析，ES默认使用的是standard分析器。如果需要指定分析器，一种方式是在索引的settings参数中设置当前索引的所有文本字段的分析器，另一种方式是在索引的mappings参数中设置当前字段的分析器。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-4-搜索时使用分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-3-4-搜索时使用分析器" aria-hidden="true">#</a> ◆ 5.3.4 搜索时使用分析器</h3>
<blockquote>
<blockquote>
<p>为了搜索时更加协调，在默认情况下，ES对文本进行搜索时使用的分析器和索引时使用的分析器保持一致。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>也可以在mappings参数中指定字段在搜索时使用的分析器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在大多数情况下是没有必要指定的，因为在默认情况下二者就是一致的。如果指定的搜索分析器和索引时的分析器不一致，则ES在搜索时可能出现有不符合预期的匹配情况，因此该设置在使用时需要慎重选择。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-5-自定义分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-3-5-自定义分析器" aria-hidden="true">#</a> ◆ 5.3.5 自定义分析器</h3>
<blockquote>
<blockquote>
<p>当系统内置的分析器不满足需求时，用户可以使用自定义分析器。在有些场景中，某个文本字段不是自然语言而是在某种规则下的编码。例如，在酒店索引中有个sup_env字段，其值为“APP,H5,WX”，表示当前酒店可以在App、Web端和微信小程序端上显示。假设当前搜索用户使用的是H5或App客户端，则需要过滤掉不支持在这两个客户端上显示的酒店。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>需要在索引创建的DSL中定义分析器comma_analyzer，该分析器中只有一个分词组件，该分词组件使用逗号进行词语切分；然后在mappings中使用analyzer参数指定字段sup_env的分析器为定义好的comma_analyzer分析器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面向酒店索引中插入几条数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当前用户的客户端为H5或App，当搜索“金都”关键词时应该构建的DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>运行上面的DSL后，ES返回的结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由上面的结果可以看到，索引中有3个文档，只有文档001和文档002对应的酒店标题中包含“金都”且可以在H5或App客户端显示。使用自定义的分词器可以将以逗号分隔的字段进行分词后建立索引，从而在搜索时也使用逗号分隔符进行匹配搜索。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-中文分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-4-中文分析器" aria-hidden="true">#</a> ◆ 5.4 中文分析器</h3>
<blockquote>
<blockquote>
<p>中文相对于英文等西方语言有独有的一些特点，ES内置的分析器一般很难适用于中文搜索，因此针对中文的ES分词器插件应运而生。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-1-中文分词介绍" tabindex="-1"><a class="header-anchor" href="#◆-5-4-1-中文分词介绍" aria-hidden="true">#</a> ◆ 5.4.1 中文分词介绍</h3>
<blockquote>
<blockquote>
<p>对于英文来说，一个文档很容易被切分成关键词的集合，因为除了标点符号外都是由空格把各个英文单词进行分隔的。例如I have a red car，用空格进行切分的结果为I/have/a/red/car。对于中文来说，一般由一个或多个字组合在一起形成一个词语，并且句子中没有词的界限。根据不同的使用场景，对于词语切分颗粒度的需求也是不一样的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例句：我来到北京清华大学。分词结果1：我/来到/北京/清华/华大/大学/清华大学分词结果2：我/来到/北京/清华大学</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>中文分词根据实现原理和特点，分词的切分算法主要有两种，即基于词典的分词算法和基于统计的机器学习算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.基于词典的分词算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于词典的分词算法是按照某种策略将提前准备好的词典和待匹配的字符串进行匹配，当匹配到词典中的某个词时，说明该词分词成功。该算法是匹配算法中最简单、速度最快的算法，其分词算法分为3种，即正向最大化匹配法、逆向最大化匹配法和双向最大化匹配法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.基于统计的机器学习算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于统计的机器学习算法的主要思想是事先构建一个语料库，该语料库中是标记好的分词形式的语料，然后统计每个词出现的频率或者词与词之间共现的频率等，基于统计结果给出某种语境下应该切分出某个词的先验概率。后续进行分词时，使用先验概率给出文本应该切分的结果。这类算法中代表的算法有HMM、CRF、深度学习等，比如结巴分词基于HMM算法、HanLP分词工具基于CRF算法等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>中文分词的难点主要有以下三方面：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·分词标准：不同的分词器使用的分词标准不同，分词的结果也不同。例如，在分词的颗粒度方面，对“中华人民共和国”进行切分时，粗粒度的分词就是“中华人民共和国”，细粒度的分词可能是“中华”“人民”“共和国”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·分词歧义：使用分词器对文本进行切分，切分后的结果和原来的字面意义不同。例如，在“郑州天和服装厂”中，“天和”是厂名，是一个专有词，“和服”也是一个词，它们共用了“和”字。如果分词器不够精准，则很容易切分成“郑州、和服、服装、服装厂”，但是原文中并没有与“和服”有关的含义，因此这里就产生了歧义。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·新词识别：新词也称未登录词，即该词没有在词典或者训练语料中出现过。在这种情况下，分词器很难识别出该词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES通过安装插件的方式来支持第三方分析器。比较常用的第三方中文分析器是HanLP和IK分析器</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-2-ik分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-4-2-ik分析器" aria-hidden="true">#</a> ◆ 5.4.2 IK分析器</h3>
<blockquote>
<blockquote>
<p>IK分析器是一个开源的、基于Java语言开发的轻量级的中文分词工具包，它提供了多种语言的调用库。在ES中，IK分析器通过第三方插件的方式来使用，其代码托管到了GitHub上，项目地址为https://github.com/medcl/elasticsearch-analysis-ik。IK分析器实现了词典的冷更新和热更新，用户可以选择适合自己的方式进行词典的更新。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面介绍ES中IK分析器的安装过程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下例使用ik_max_word分析器对待测试文本进行分析。[插图][插图][插图]分析结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下例使用ik_smart分析器对待测试文本进行分析。[插图][插图][插图]分析结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ik_max_word和ik_smart分析器的主要区别在于切分词语的粒度上，ik_smart的切分粒度比较粗，而ik_max_word将文本进行了最细粒度的拆分，甚至穷尽了各种可能的组合。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另外可以看到“嘉怡”这个词被切分成了“嘉”和“怡”，这个词没有在IK分析器的词典里，因此被切分成了两个单字，这需要为IK分析器添加词典来解决该问题。在IK分析器的安装目录下的config子目录中创建文件my.dict，在其中添加“嘉怡”即可。如果有更多的词语需要添加，则每个词语单独一行，添加示例如图5.9所示。[插图]图5.9　在IK分析器中添加字典</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>添加完成后修改IK分析器的配置文件，路径为config/IKAnalyzer.cfg.xml，将新建的字典文件加入ext_dict选项中，如图5.10所示。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>配置完成后重启ES，然后使用分析器分析上面的文本，此时“嘉怡”就可以被切分出来。下面是使用ik_smart分析器切分文本的过程。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>安装完毕后，也可以将IK分析器应用到索引的字段中。下面将ik_max_word分析器设置为酒店索引中title字段的默认分析器。[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-3-hanlp分析器" tabindex="-1"><a class="header-anchor" href="#◆-5-4-3-hanlp分析器" aria-hidden="true">#</a> ◆ 5.4.3 HanLP分析器</h3>
<blockquote>
<blockquote>
<p>HanLP是由一系列模型与算法组成的Java工具包，它从中文分词开始，覆盖词性标注、命名实体识别、句法分析、文本分类等常用的NLP任务，提供了丰富的API，被广泛用于Lucene、Solr和ES等搜索平台。就分词算法来说，它支持最短路分词、N-最短路分词和CRF分词等分词算法。用户可以在ES中安装HanLP分析器插件进行使用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HanLP分析器插件的安装比较简单，在ES的安装目录下执行bin/elasticsearch-plugin install${URL}命令即可，其中的URL是HanLP的安装文件链接。本书使用的ES版本为7.10.2，需要HanLP分析器也使用相同的版本，对应的链接地址为https://github.com/Kenn Falcon/elasticsearch-analysis-hanlp/releases/download/v7.10.2/elasticsearch-analysis-hanlp-7.10.2.zip，安装时可根据当前的版本进行选择。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HanLP分析器提供了众多的子分析器，如hanlp、hanlp_standard、hanlp_crf和hanlp_n_short等。下例使用hanlp_standard分析器对待测试文本进行分析。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-5-使用同义词" tabindex="-1"><a class="header-anchor" href="#◆-5-5-使用同义词" aria-hidden="true">#</a> ◆ 5.5 使用同义词</h3>
<blockquote>
<blockquote>
<p>在搜索场景中，同义词用来处理不同的查询词，有可能是表达相同搜索目标的场景。例如，当用户的查询词为“带浴缸的酒店”和“带浴池的酒店”时，其实是想搜索有单独泡澡设施的酒店。再例如，在电商搜索中，同义词更是应用广泛，如品牌同义词Adidas和“阿迪达斯”，产品同义词“投影仪”和“投影机”，修饰同义词“大码”和“大号”等。用户在使用这些与同义词相关的关键词进行搜索时，搜索引擎返回的搜索结果应该是一致的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户还可以通过ES中的分析器来使用同义词，使用方式分为两种，一种是在建立索引时指定同义词并构建同义词的倒排索引，另一种是在搜索时指定字段的search_analyzer查询分析器使用同义词。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-5-1-建立索引时使用同义词" tabindex="-1"><a class="header-anchor" href="#◆-5-5-1-建立索引时使用同义词" aria-hidden="true">#</a> ◆ 5.5.1 建立索引时使用同义词</h3>
<blockquote>
<blockquote>
<p>在ES内置的分词过滤器中，有一种分词过滤器叫作synonyms，它是一种支持用户自定义同义词的分词过滤器。以下是使用IK分析器和synonyms分词过滤器一起定义索引的DSL：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为方便测试，下面向酒店索引中写入几条数据：[插图][插图][插图]搜索关键词“首都度假酒店”，DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-5-2-查询时使用同义词" tabindex="-1"><a class="header-anchor" href="#◆-5-5-2-查询时使用同义词" aria-hidden="true">#</a> ◆ 5.5.2 查询时使用同义词</h3>
<blockquote>
<blockquote>
<p>在ES内置的分词过滤器中还有个分词过滤器叫作synonym_graph，它是一种支持查询时用户自定义同义词的分词过滤器。以下是使用IK分析器和synonym_graph分词过滤器一起定义索引的DSL：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-使用停用词" tabindex="-1"><a class="header-anchor" href="#◆-5-6-使用停用词" aria-hidden="true">#</a> ◆ 5.6 使用停用词</h3>
<blockquote>
<blockquote>
<p>停用词也叫停止词，是指文本在被分词之后的词语中包含的无搜索意义的词。什么叫作“无搜索意义”呢？假设文本为“这里的世界丰富多彩”，那么分词结果中的“这里”和“的”对于匹配这个文档来说意义不大，因为这两个词的使用频率非常高，并且没有太多独特的意义。在构建搜索引擎索引时，常常忽略这样的词，这样可以大大提升搜索效率。经常使用的中文和英文停用词可以在网站www.ranks.nl上提取，中文停用词地址为https://www.ranks.nl/stopwords/chinese-stopwords，英文停用词地址为https://www.ranks.nl/stopwords。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-1-使用停用词过滤器" tabindex="-1"><a class="header-anchor" href="#◆-5-6-1-使用停用词过滤器" aria-hidden="true">#</a> ◆ 5.6.1 使用停用词过滤器</h3>
<blockquote>
<blockquote>
<p>可以通过创建自定义分析器的方式使用停用词，方法是在分析器中指定停用词过滤器，在过滤器中可以指定若干个停用词。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-2-在内置分析器中使用停用词" tabindex="-1"><a class="header-anchor" href="#◆-5-6-2-在内置分析器中使用停用词" aria-hidden="true">#</a> ◆ 5.6.2 在内置分析器中使用停用词</h3>
<blockquote>
<blockquote>
<p>像standard这种常用的分析器都自带有停用词过滤器，只需要对其参数进行相应设置即可。以下示例中使用standard分析器并通过设置其stopwords属性进行停用词的设定：</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-3-在ik分析器中使用停用词" tabindex="-1"><a class="header-anchor" href="#◆-5-6-3-在ik分析器中使用停用词" aria-hidden="true">#</a> ◆ 5.6.3 在IK分析器中使用停用词</h3>
<blockquote>
<blockquote>
<p>在默认情况下，IK分析器的分词器只有英文停用词，没有中文停用词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果用户想要添加中文停用词，需要通过自定义停用词文件的形式进行添加。在${ES_HOME}/plugins/ik-analysis/config目录下创建my_stopword.dict文件，并在其中添加中文停用词即可，如图5.16所示。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>添加完停用词后保存文件并退出，然后修改${ES_HOME}/plugins/ik-analysis/config/IKAnalyzer.cfg.xml文件，设置配置项ext_stopwords的值为停用词词典的文件名称，如图5.17所示。[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-4-在hanlp分析器中使用停用词" tabindex="-1"><a class="header-anchor" href="#◆-5-6-4-在hanlp分析器中使用停用词" aria-hidden="true">#</a> ◆ 5.6.4 在HanLP分析器中使用停用词</h3>
<blockquote>
<blockquote>
<p>在默认情况下，HanLP分析器的停用词是不启用的，需要配置自定义分析器并设置其启用停用词</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的示例中，自定义分析器中的my_tokenizer分词器的enable_stop_dictionary属性被设置为true，表示当前分词器启用停用词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由上述结果可知，文本中的“最”这个停用词已经被过滤。如果希望把词语“一个”也过滤掉应该如何操作呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户可以在HanLP分析器的停用词词典文件中添加停用词，文件位置为${ES_HOME}/plugins/analysis-hanlp/data/dictionary/stopwords.txt，在该文件中已经有一些HanLP分析器内置的停用词，在该文件末尾追加停用词“一个”即可</p>
</blockquote>
</blockquote>
<h3 id="◆-5-7-拼音搜索" tabindex="-1"><a class="header-anchor" href="#◆-5-7-拼音搜索" aria-hidden="true">#</a> ◆ 5.7 拼音搜索</h3>
<blockquote>
<blockquote>
<p>拼音搜索在中文搜索环境中是经常使用的一种功能，用户只需要输入关键词的拼音全拼或者拼音首字母，搜索引擎就可以搜索出相关结果。在国内，中文输入法基本上都是基于汉语拼音的，这种在符合用户输入习惯的条件下缩短用户输入时间的功能是非常受欢迎的，如图5.19所示为分别在艺龙App和携程App上输入wfj后的搜索结果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5.19　在艺龙App和携程App上搜索wfj</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在ES中可以使用拼音分析器插件进行拼音搜索，插件的项目地址为https://github.com/medcl/elasticsearch-analysis-pinyin，该插件对较新的ES版本并不支持，需要用户自行进行编译安装。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-7-1-拼音分析器插件的安装" tabindex="-1"><a class="header-anchor" href="#◆-5-7-1-拼音分析器插件的安装" aria-hidden="true">#</a> ◆ 5.7.1 拼音分析器插件的安装</h3>
<blockquote>
<blockquote>
<p>如果要安装拼音分析器插件，则需要安装Git和Maven这两个工具。首先使用Git命令从互联网中复制该项目，命令如下：[插图][插图][插图]然后进入该项目，修改目录中的pom.xml文件，将elasticsearch.version选项的值修改成当前ES版本的值</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>修改完成后保存文件并退出，使用mvn命令进行编译：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>安装完成后会在${PROJECT_PATH}/target/releases/目录下生成目标文件elasticsearch analysis-pinyin-7.10.2.zip。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-7-2-拼音分析器插件的使用" tabindex="-1"><a class="header-anchor" href="#◆-5-7-2-拼音分析器插件的使用" aria-hidden="true">#</a> ◆ 5.7.2 拼音分析器插件的使用</h3>
<blockquote>
<blockquote>
<p>拼音分析器提供的分析器为pinyin，另外还提供了与其同名的分词器和分词过滤器。安装完成后，可以使用pinyin分析器或分词器进行验证。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面使用pinyin分析器对待测试文本进行分析，DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的代码中，“王府井”被切分成拼音wang、fu、jing及首字母wfj。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>也可以将拼音分析器应用到索引的字段中。以下示例中将自定义的ik_pinyin_analyzer分析器设置为酒店索引中title字段的默认分析器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用带有拼音词语过滤器的分析器后，就可以匹配查询词中的拼音首字母了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用拼音分析器时，有很多的选项可以设置。例如，是否显示单字拼音的首字母、是否显示组合词的首字母、是否显示查询词的全部拼音等</p>
</blockquote>
</blockquote>
<h3 id="◆-5-8-高亮显示搜索" tabindex="-1"><a class="header-anchor" href="#◆-5-8-高亮显示搜索" aria-hidden="true">#</a> ◆ 5.8 高亮显示搜索</h3>
<blockquote>
<blockquote>
<p>“高亮显示”的英文为highlight，是指在搜索结果中通过对文档标题的部分匹配字符串进行颜色（如红色）或者字体（如加粗）等处理，在视觉呈现上使匹配的字符串与未匹配的字符串有明显的区分效果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这可以让产品的属性和卖点受到更多的关注，从而提高搜索转化率。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-8-1-初步使用高亮显示搜索" tabindex="-1"><a class="header-anchor" href="#◆-5-8-1-初步使用高亮显示搜索" aria-hidden="true">#</a> ◆ 5.8.1 初步使用高亮显示搜索</h3>
<blockquote>
<blockquote>
<p>在ES中通过设置DSL的highlight参数可以对搜索的字段高亮显示。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面搜索title字段并且对结果进行高亮显示：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以上DSL中增加了highlight的子DSL，在其中设定对title字段的匹配结果进行高亮显示的标记标签，此处使用默认的HTML标签<em></em>，因此将title对应的值置为空对象。上述DSL的搜索结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在每个搜索结果中增加了一个highlight子结果，其中将查询字段中匹配上的字符串都用HTML标签<em></em>进行了标记，这样的结果可以直接传送到前端，前端根据标记标签进行特殊化处理即可完成匹配字符串的高亮显示。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果希望使用其他HTML标签对匹配内容进行标记，可以在DSL中进行更改。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-8-2-选择高亮显示搜索策略" tabindex="-1"><a class="header-anchor" href="#◆-5-8-2-选择高亮显示搜索策略" aria-hidden="true">#</a> ◆ 5.8.2 选择高亮显示搜索策略</h3>
<blockquote>
<blockquote>
<p>ES支持的高亮显示搜索策略有plain、unified和fvh，用户可以根据搜索场景进行选择。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>plain是精准度比较高的策略，因此它必须将文档全部加载到内存中，并重新执行查询分析。由此可见，plain策略在处理大量文档或者大文本的索引进行多字段高亮显示搜索时耗费的资源比较严重。因此plain策略适合在单个字段上进行简单的高亮显示搜索。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>unified策略是由Lucene Unified Highlighter来实现的，其使用BM25（Best Match25）算法进行匹配。在默认情况下，ES高亮显示使用的是该策略。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了弥补上述两种策略在大文本索引高亮显示搜索时的速度低问题，Lucene还提供了基于向量的高亮显示搜索策略fvh（fast vectorhighlighter）。fvh策略更适合在文档中包含大字段的情况（如超过1MB）下使用，如果计算机的I/O性能更好（如使用SSD），则fvh策略在速度上的优势更加明显。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>选择高亮显示搜索策略时，只需要在highlight子句中指定type字段的值即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果要使用fvh策略进行高亮显示搜索，需要设定字段的term_vector属性值为with_positions_offsets</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]然后在查询的DSL中指定高亮显示搜索的type为fvh，具体DSL如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-5-9-拼写纠错" tabindex="-1"><a class="header-anchor" href="#◆-5-9-拼写纠错" aria-hidden="true">#</a> ◆ 5.9 拼写纠错</h3>
<blockquote>
<blockquote>
<p>用户在使用搜索引擎的过程中，输入的关键词可能会出现拼写错误的情况。针对错误的关键词，绝大多数的搜索引擎都能自动识别并进行纠正，然后将纠正后的关键词放到索引中匹配数据。如果拼写错误特别多导致无法纠正，则会直接告知用户当前搜索没有匹配的结果。如图5.24所示的左右两幅图分别是在京东商城和天猫商城中搜索“薯偏”后的返回结果。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过图5.24可以看到，两个应用都识别出了“薯偏”是一种拼写错误，并给出了正确的拼写词“薯片”。在搜索结果的展示上，天猫商城保守一些，主要展示了“薯”对应的匹配结果；京东商城则直接展示了“薯片”对应的匹配结果。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-9-1-使用elasticsearch进行拼写纠错" tabindex="-1"><a class="header-anchor" href="#◆-5-9-1-使用elasticsearch进行拼写纠错" aria-hidden="true">#</a> ◆ 5.9.1 使用Elasticsearch进行拼写纠错</h3>
<blockquote>
<blockquote>
<p>也可以使用ES进行拼写纠错，首先需要搜集一段时间内用户搜索日志中有搜索结果的查询词，然后单独建立一个纠正词索引。当用户进行搜索时，如果在商品索引中没有匹配到结果，则在纠正词索引中进行匹配，如果有匹配结果则给出匹配词，并给出该匹配词对应的商品结果，如果没有匹配结果则告知用户没有搜索到商品</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在ES中进行纠错匹配时使用fuzzy-match搜索，该搜索使用编辑距离和倒排索引相结合的形式完成纠错</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>词语A经过多次编辑后和词语B相等，编辑的次数就叫作编辑距离。可以这样定义一次编辑：替换一个字符，或删除一个字符，或插入一个字符，或交换两个字符的位置。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设有词语A为“景王”，词语B为“王府井”，词语A需要进行如下编辑才能等于词语B：（1）将“景王”两个字符交换位置，变为“王景”。（2）在“王景”中间添加“府”，变成“王府景”。（3）将“王府景”中的“景”替换为“井”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5.25　使用ES拼写纠错的流程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>经过上述编辑，词语A和词语B相等，则词语A到词语B的编辑距离为3。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在搜索场景中，绝大多数查询词的编辑距离一般不超过2。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先创建一个纠错索引，名称为error_correct，索引创建语句如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>接着向该索引中写入以下数据：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES的match查询支持模糊匹配，这里的模糊匹配指的是ES将查询文本进行分词进而得到分词列表，然后将列表中的词语分别和索引中的词语进行匹配，这时按照编辑距离进行模糊匹配，在符合编辑距离阈值的情况下才算是匹配。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下是搜索“王府景”时，指定编辑距离为1的搜索纠错的DSL：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上述DSL的执行结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>成府路”也出现在搜索结果中，这是为什么呢？按照hot_word字段默认的分析器对查询词“王府景”和查询词“成府路”进行分析，查询词“王府景”被切分成了“王府”和“景”；查询词“成府路”被切分成了“成”“府”和“路”。因为“王府”和“府”的编辑距离为1，符合模糊匹配的编辑距离的阈值，因此“成府路”被匹配上。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-9-2-更精准的拼写纠错" tabindex="-1"><a class="header-anchor" href="#◆-5-9-2-更精准的拼写纠错" aria-hidden="true">#</a> ◆ 5.9.2 更精准的拼写纠错</h3>
<blockquote>
<blockquote>
<p>解决上面的问题有两种思路，第一种思路是将“成府路”作为新词加入用户的自定义词典中，此时ES会将“成府路”切分成一个整体“成府路”，它和“王府”的编辑距离是2，不符合阈值，因此不匹配；第二种思路是加入更严格的匹配条件。第一种思路受经验影响比较大，需要人工参与。本节主要介绍使用第二种思路来解决问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>针对5.9.1节的“王府景”匹配问题，可以采用短语进行匹配查询，但是其必须满足以下3个条件：·文档中必须包含“王府景”3个字；·文档中必须满足“府”的位置比“王”的位置大1；·文档中必须满足“景”的位置比“王”的位置大2。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上述条件缺一不可。但是，现有的文档中没有一个文档同时符合这个条件，甚至连第一个条件都不满足，与其最接近的文档是“王府井”，但是该文档中不包含“景”。我们可以换个角度考虑问题，“王府景”和“王府井”其实属于音同字不同的情况，如果将查询词和索引文档字段都切分成拼音的形式，“王府景”切分成拼音wang、fu、jing，候选项“王府井”切分的结果与查询词是一致的，且其拼音形式的位置排列与查询词也相同，这样就符合短语匹配的条件了。因此我们将字段hot_word变换一下，建立一个子字段pinyin，该字段使用拼音分析器进行切分，DSL如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的拼音分析器设置中，设置拼音单字的首字母和拼音组合的首字母全部不使用，只使用拼音单字的全拼形式。</p>
</blockquote>
</blockquote>
<h2 id="◆-第6章-搜索排序" tabindex="-1"><a class="header-anchor" href="#◆-第6章-搜索排序" aria-hidden="true">#</a> ◆ 第6章 搜索排序</h2>
<blockquote>
<blockquote>
<p>ES、Solr等开源的搜索引擎，它们在默认情况下使用的都是相关性排序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>相关性指的是搜索结果和查询条件的相关程度，它是搜索质量的重要指标之一。就ES来说，搜索结果中的每个结果都有一个_score字段，ES默认按照相关性算法计算每个命中的文档的_score字段值，命中的文档按照该字段的值进行降序排列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了使用相关性算法，ES还开放了用户可以重度参与的打分功能。可以使用Function Score对文档完成基于规则权重或者衰减函数的打分。对于用户来说，最自由的打分方式莫过于Script Score方式，因为它支持用户直接编写脚本代码对文档进行打分。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-相关性排序" tabindex="-1"><a class="header-anchor" href="#◆-6-1-相关性排序" aria-hidden="true">#</a> ◆ 6.1 相关性排序</h3>
<blockquote>
<blockquote>
<p>对于用户搜索，结果中的文档和查询条件相关性越高，排序越靠前。如果查询使用的是文本搜索，ES默认使用BM25算法进行相关性计算，用户也可以选择其他相关性算法。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-1-tf-idf模型" tabindex="-1"><a class="header-anchor" href="#◆-6-1-1-tf-idf模型" aria-hidden="true">#</a> ◆ 6.1.1 TF-IDF模型</h3>
<blockquote>
<blockquote>
<p>TF-IDF（Term Frequency-Inverse Document Frequency，词频-逆文档频率）是文本挖掘和信息检索工作中数据处理的常用加权技术之一，主要作用是评估词语在文档中的重要程度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>TF-IDF由TF和IDF两部分组成。TF指的是某个词语在文本中的词频，词频越大，TF值就越大。TF的计算公式为：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>i为某个词语，f为该词语在文档中的词频。TF的意义在于，如果一个词在文档中多次出现，说明该词对文档比较重要，甚至文档的主题很可能和该词相关。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>IDF指文档的重要程度与包含某个词的文档个数是负相关的，这也是其全称里有个Inverse的原因。IDF的计算公式为：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>i为某个词语，N为文档的总数量，n为包含某词语的文档数量。IDF的意义是词语重要程度的度量。如果一个词只在一个文档中出现，则该词是这个文档独特性的一种体现；反之，如果一个词在很多个文档中出现，则该词很可能是一个通用词语，它对文档之间区分度的贡献不高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有了TF和IDF的定义，最终TF-IDF值的定义为：TF-IDF=TF·IDF</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-2-向量空间模型" tabindex="-1"><a class="header-anchor" href="#◆-6-1-2-向量空间模型" aria-hidden="true">#</a> ◆ 6.1.2 向量空间模型</h3>
<blockquote>
<blockquote>
<p>在文本挖掘领域，一般将文本分词后进行向量化处理。每个词作为一个维度，将词的TF-IDF值作为该维度的值。假设某个文档由n个词语组成，每个词语的TF-IDF用S表示，则向量可以表示为一个一维数组：V=[S1,S2,…,Sn]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设查询词为“金都酒店”，查询词中“金都”不是很常见，其TF-IDF值假设为8，几乎每个文档中都包含“酒店”，因此假设“酒店”的TF-IDF值为6。所以，查询词的向量化表示为[8,6]，在二维直角坐标系中画一条直线，起点为[0,0]，终点为[8,6]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>鉴于查询词只包含“金都”和“酒店”两个词，因此在后续的匹配过程中，只使用这两个维度和候选文档进行匹配。假设有如下三个文档：·文档1为金都又金都酒店，因为其包含两个“金都”，所以“金都”的TF-IDF值可以更大一些，例如10，则该文档的向量化表示为[10,6]。·文档2为文雅酒店，则其向量化表示为[0,6]。·文档3为金都客栈，则其向量化表示为[8,0]。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-3-bm25算法简介" tabindex="-1"><a class="header-anchor" href="#◆-6-1-3-bm25算法简介" aria-hidden="true">#</a> ◆ 6.1.3 BM25算法简介</h3>
<blockquote>
<blockquote>
<p>当前的商用搜索引擎一般都使用BM25算法对搜索结果进行排序，从6.X开始，ES默认使用该算法对搜索的文档进行排序。与向量空间模型不同，BM25算法使用的是概率模型，它属于bag-of-words模型。bag-of-words模型只考虑文档中单个词的词频，不考虑句子结构或者词与词之间的顺序等关系。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面直接给出BM25算法的打分公式：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>搜索时，ES对搜索文本进行分词，qi代表每一个被切分的词语，文档的最终得分是文档与这些词语的匹配值之和。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般来说，文档如果足够短，则其分值应该更高。例如，在酒店的名称和描述中搜索“金都酒店”，如果酒店A的名称中包含“金都”和“酒店”这两个词，而酒店B的简介中包含这两个词，则酒店A的分值肯定比酒店B要高一些。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-5-bm25参数调节" tabindex="-1"><a class="header-anchor" href="#◆-6-1-5-bm25参数调节" aria-hidden="true">#</a> ◆ 6.1.5 BM25参数调节</h3>
<blockquote>
<blockquote>
<p>BM25算法的打分公式中有两个参数，即k1和b，分别用来控制TF和文档长度对打分的影响。在ES中，这两个参数的默认值分别为1.2和0.75。一般情况下，使用这两个参数的默认值已经能够提供不错的搜索效果，因此不需要更改。不过ES还是开放了参数调节的功能，用户可以在索引的settings中调节这两个参数来影响打分。在settings中，可以自定义一个相似度算法，然后指定该算法使用BM25算法，并对参数k1和参数b进行设置。参数k1的值一般介于1.2～2.0，参数b的值一般为0.3～0.9。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-6-分布式场景对排序的影响" tabindex="-1"><a class="header-anchor" href="#◆-6-1-6-分布式场景对排序的影响" aria-hidden="true">#</a> ◆ 6.1.6 分布式场景对排序的影响</h3>
<blockquote>
<blockquote>
<p>在理想情况下，我们希望计算索引中所有包含该词的文档个数。但是在分布式场景中，这种想法是不现实的，因为在多分片模式下，出于性能方面的原因，不可能在短时间内将这些文档都找到。因此在ES内部，IDF的计算是在当前分片内进行的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当文档分布不均匀时，每个分片内的IDF值可能是不一样的。假设当前索引中有10个文档都包含“金都”，其中有8个文档存储在分片1上，剩下的2个文档存储在分片2上。在这种情况下，两个分片“金都”中的IDF值是不同的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不过不用过于担心这种情况，因为在绝大多数生产环境中，文档的分布都是比较均匀的。可能索引刚刚建立后，文档比较少，有分布不均匀的情况，随着文档逐渐增多，数据分布将逐渐趋于均匀。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果文档确实比较少，多个分片的IDF值不同，用户希望使用整个索引文档的IDF，则可以设置索引的主分片数为1，这样便可以解决该问题。但是需要切记，进行这种设置的前提是文档比较少。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-7-使用其他相关性算法" tabindex="-1"><a class="header-anchor" href="#◆-6-1-7-使用其他相关性算法" aria-hidden="true">#</a> ◆ 6.1.7 使用其他相关性算法</h3>
<blockquote>
<blockquote>
<p>ES还提供了其他相关性排序算法，如DFR算法、DFI算法、IB算法、LM算法和Dirichlet算法等。这些算法在搜索场景中不常用</p>
</blockquote>
</blockquote>
<h3 id="◆-6-2-1-查询时boost参数的设置" tabindex="-1"><a class="header-anchor" href="#◆-6-2-1-查询时boost参数的设置" aria-hidden="true">#</a> ◆ 6.2.1 查询时boost参数的设置</h3>
<blockquote>
<blockquote>
<p>在ES中可以通过查询的boost值对某个查询设定其权重。在默认情况下，所有查询的boost值为1。但是当设置某个查询的boost为2时，不代表匹配该查询的文档评分是原来的2倍，而是代表匹配该查询的文档得分相对于其他文档得分被提升了。例如，可以为查询A设定boost值为3，为查询B设定boost值为6，则在进行相关性计算时，查询B的权重将比查询A相对更高一些。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>boost值的设置只限定在term查询和类match查询中，其他类型的查询不能使用boost设置。boost值没有特别约束，因为它代表的是一个相对值。当该值在0～1时表示对权重起负向作用，当该值大于1时表示对权重起正向作用。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-2-3-boosting查询" tabindex="-1"><a class="header-anchor" href="#◆-6-2-3-boosting查询" aria-hidden="true">#</a> ◆ 6.2.3 boosting查询</h3>
<blockquote>
<blockquote>
<p>使用boost值可以对查询的权重进行调整，但是仅限于term查询和类match查询。有时需要调整更多类型的查询，如搜索酒店时，需要将房价低于200的酒店权重降低，此时可能需要用到range查询，但是range查询不能使用boost参数，这时可以使用ES的boosting查询进行封装。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES的boosting查询分为两部分，一部分是positive查询，代表正向查询，另一部分是negative查询，代表负向查询。可以通过negative_boost参数设置负向查询的权重系数，该值的范围为0～1。最终的文档得分为：正向匹配值+负向匹配值×negative_boost。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-3-3-衰减函数" tabindex="-1"><a class="header-anchor" href="#◆-6-3-3-衰减函数" aria-hidden="true">#</a> ◆ 6.3.3 衰减函数</h3>
<blockquote>
<blockquote>
<p>在对文档进行打分时，希望在某个值域附近进行衰减打分。例如当搜索酒店时，酒店距离当前位置越近越好。假定距离当前位置1km范围内的酒店都可以接受，如果使用过滤器将超过1km的酒店排除掉，这种做法未免有些“生硬”。假设一个酒店距离当前位置刚好是1.1km，其好评度也不错，那么是可以考虑一下该酒店的。所以我们希望酒店最好距离当前位置在1km范围内，如果超过1km，酒店的评分应该随着距离的增大有一个明显的下降趋势。为了解决这类问题，可以在Function Score查询中使用衰减函数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES提供了3个衰减函数，分别为gauss、linear和exp，这3个函数的区别主要是衰减曲线形状不同，但是它们的用法和参数设置都是一样的。如图6.4所示为以年龄字段为例展示的这3个函数的衰减曲线图像。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>衰减函数可以用于数值型、日期型和地理位置型数据，需要用户设置一个中心值，如果实际值偏离中心值，无论大于中心值还是小于中心值，文档的分数都将降低。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>·使用衰减函数时，可以设定如下参数：·origin：用于设定计算距离的原点，该参数的值必须和字段类型相对应。·offset：用于设定距离原点多远范围内的数据将享有和原点一样的衰减值，其默认值为0。·scale：衰减曲线的一个锚点，即定义到该点的值，其衰减的值为某个值（即为decay的值）。这个锚点横坐标值的定义为原点+offset+scale，纵坐标为decay参数的值。·decay：和scale配套使用，用于设定锚点的纵坐标，即衰减值，其默认值为0.5。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-4-script-score查询简介" tabindex="-1"><a class="header-anchor" href="#◆-6-4-script-score查询简介" aria-hidden="true">#</a> ◆ 6.4 Script Score查询简介</h3>
<blockquote>
<blockquote>
<p>ES提供的Script Score查询可以以编写脚本的方式对文档进行灵活打分，以实现自定义干预结果排名的目的。Script Score默认的脚本语言为Painless，在Painless中可以访问文档字段，也可以使用ES内置的函数，甚至可以通过给脚本传递参数这种方式联通内部和外部数据。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-4-1-painless简介" tabindex="-1"><a class="header-anchor" href="#◆-6-4-1-painless简介" aria-hidden="true">#</a> ◆ 6.4.1 Painless简介</h3>
<blockquote>
<blockquote>
<p>Painless语言是一种专门用于ES中的脚本语言，它使用了类似于Groovy的语法。ES使用了沙箱技术运行Painless，且在Painless中没有任何网络连接的功能，因此它在安全性方面是有保障的。Painless是被编译成JVM字节码后运行的，它从语法上看是Java的子集，因此它又是一种简单高效的脚本语言。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-4-2-在script-score中使用painless" tabindex="-1"><a class="header-anchor" href="#◆-6-4-2-在script-score中使用painless" aria-hidden="true">#</a> ◆ 6.4.2 在Script Score中使用Painless</h3>
<blockquote>
<blockquote>
<p>在Script Score查询中可以使用Painless脚本进行打分脚本的开发，脚本代码主体放在参数source的值中，注意，Script Score查询中的脚本代码必须有返回值并且类型为数值型，如果没有返回值，则Script Score查询默认返回0。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-4-3-使用数组和集合" tabindex="-1"><a class="header-anchor" href="#◆-6-4-3-使用数组和集合" aria-hidden="true">#</a> ◆ 6.4.3 使用数组和集合</h3>
<blockquote>
<blockquote>
<p>在Painless中可以定义数组和集合，也可以使用文档中的数组和集合字段</p>
</blockquote>
</blockquote>
<h3 id="◆-6-5-二次打分" tabindex="-1"><a class="header-anchor" href="#◆-6-5-二次打分" aria-hidden="true">#</a> ◆ 6.5 二次打分</h3>
<blockquote>
<blockquote>
<p>如果一个搜索匹配了几十万个文档，对这些文档使用Function Score或者Script Score查询进行打分是非常耗时的，整个排序性能大打折扣。针对这种情况，ES提供了Query Rescore功能作为折中方案，它支持只针对返回文档的一部分文档进行打分。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-5-1-二次打分简介" tabindex="-1"><a class="header-anchor" href="#◆-6-5-1-二次打分简介" aria-hidden="true">#</a> ◆ 6.5.1 二次打分简介</h3>
<blockquote>
<blockquote>
<p>Query Rescore工作的阶段是在原始查询打分之后，它支持对打分后Top-N的文档集合执行第二次查询和打分。通过设置window_size参数可以控制在每个分片上进行二次打分查询的文档数量，在默认情况下window_size的值为10。在默认情况下，文档的最终得分等于原查询和rescore查询的分数之和。</p>
</blockquote>
</blockquote>
<h2 id="◆-第7章-聚合" tabindex="-1"><a class="header-anchor" href="#◆-第7章-聚合" aria-hidden="true">#</a> ◆ 第7章 聚合</h2>
<blockquote>
<blockquote>
<p>当用户使用搜索引擎完成搜索后，在展示结果中需要进行进一步的筛选，而筛选的维度需要根据当前的搜索结果进行汇总，这就用到了聚合技术。聚合的需求在很多应用程序中都有所体现，例如在京东App中搜索“咸鸭蛋”，然后单击搜索界面中的“筛选”按钮，在弹出的界面中可以对当前的搜索结果进行进一步的过滤。例如，可以从价格区间、品牌、分类、枚数等维度分别进行筛选，如图7.1所示。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES支持丰富的聚合操作，不仅可以使用聚合功能对文档进行计数，还可以计算文档字段的平均值、最大值和最小值等。ES还提供了桶聚合的功能，以便于对多维度数据进行聚合。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果希望搜索结果和聚合结果一起返回，其中绕不开的一个主题就是分页和排序</p>
</blockquote>
</blockquote>
<h3 id="◆-7-1-聚合指标" tabindex="-1"><a class="header-anchor" href="#◆-7-1-聚合指标" aria-hidden="true">#</a> ◆ 7.1 聚合指标</h3>
<blockquote>
<blockquote>
<p>在进行聚合搜索时，聚合的指标业务需求不仅是文档数量。例如，在酒店搜索场景中，我们希望能看到以当前位置为中心点，周边各个区域酒店的平均价格。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-1-1-常见的统计指标" tabindex="-1"><a class="header-anchor" href="#◆-7-1-1-常见的统计指标" aria-hidden="true">#</a> ◆ 7.1.1 常见的统计指标</h3>
<blockquote>
<blockquote>
<p>在搜索聚合时，用户可能会关注字段的相关统计信息，例如平均值、最大值、最小值及加和值等。例如，用户在使用一个二手房交易搜索引擎进行搜索时，可能会关注当前城市各个区域的房产平均价格。再例如，用户在搜索酒店时，也可能会关注附近各个区域酒店的最低价格。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES聚合请求的地址也是索引的搜索地址，可以使用aggs子句封装聚合请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当使用avg子句进行平均值的聚合时，可以在avg子句中指定聚合的字段。在默认情况下，查询将匹配所有文档，如果不需要返回匹配的文档信息，最好将返回的文档个数设置为0。这样既可以让结果看起来更整洁，又可以提高查询速度。下面的DSL将查询所有酒店的平均价格并且不返回匹配的文档信息。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的DSL中，设定avg聚合的字段为price字段，并设置size参数的值为0。该DSL被执行后，ES的返回结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的搜索结果中，索引中的5个文档全部命中，由于DSL设置size为0，所以命中文档的信息没有显示。在搜索结果的aggregations子句中存储着聚合结果，其中my_agg是聚合的名称，其对应的value值就是具体聚合结果，即酒店的平均价格。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果聚合的指标字段不是ES的基本类型，例如object类型，则可以使用点运算符进行引用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了避免多次请求，ES还提供了stats聚合。stats聚合可以将对应字段的最大值、最小值、平均值及加和值一起计算并返回计算结果。下面的DSL展示了stats的用法。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的DSL中，对所有酒店进行了常用统计指标的聚合，查询结果如下：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-7-1-2-空值处理" tabindex="-1"><a class="header-anchor" href="#◆-7-1-2-空值处理" aria-hidden="true">#</a> ◆ 7.1.2 空值处理</h3>
<blockquote>
<blockquote>
<p>在索引中的一部分文档很可能其某些字段是缺失的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ES聚合查询提供的value_count聚合，该聚合用于统计字段非空值的个数。以下示例使用value_count聚合统计了price字段中非空值的个数。[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果判断的字段是数组类型，则value_count统计的是符合条件的所有文档中该字段数组中非空元素个数的总和，而不是数组的个数总和。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-2-桶聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-2-桶聚合" aria-hidden="true">#</a> ◆ 7.2 桶聚合</h3>
<blockquote>
<blockquote>
<p>有时还需要根据某些维度进行聚合。例如在搜索酒店时，按照城市、是否满房、标签和创建时间等维度统计酒店的平均价格。这些字段统称为“桶”，在同一维度内有一个或者多个桶。例如城市桶，有“北京”“天津”等，是否满房桶，有“满房”“非满房”。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-2-1-单维度桶聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-2-1-单维度桶聚合" aria-hidden="true">#</a> ◆ 7.2.1 单维度桶聚合</h3>
<blockquote>
<blockquote>
<p>最简单的桶聚合是单维度桶聚合，指的是按照一个维度对文档进行分组聚合。在桶聚合时，聚合的桶也需要匹配，匹配的方式有terms、filter和ranges等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>terms聚合是按照字段的实际完整值进行匹配和分组的，它使用的维度字段必须是keyword、bool、keyword数组等适合精确匹配的数据类型，因此不能对text字段直接使用terms聚合，如果对text字段有terms聚合的需求，则需要在创建索引时为该字段增加多字段功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下的DSL描述的是按照城市进行聚合的查询：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>因为ES支持多桶聚合，所以每个桶聚合需要定义一个名字，此处定义了一个桶聚合，名字为my_agg。在这个桶聚合中使用了一个terms聚合，聚合字段选择了城市，目的是统计各个城市的酒店的文档个数。在聚合外面，因为不希望返回任何文档，所以指定查询返回的文档为0。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在默认情况下，进行桶聚合时如果不指定指标，则ES默认聚合的是文档计数，该值以doc_count为key存储在每一个bucket子句中。在聚合结果的buckets的两个bucket中，key字段的值分别为“北京”“天津”，表示两个bucket的唯一标识；doccount_字段的值分别为3和2，表示两个bucket的文档计数。返回的doccount_是近似值，并不是一个准确数，因此在聚合外围，ES给出了两个参考值doc_count_error_upper_bound和sum_other__doc_count，doc_count_error_upper表示被遗漏的文档数量可能存在的最大值，sum_other_doc_count表示除了返回给用户的文档外剩下的文档总数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了terms聚合，ranges聚合也是经常使用的一种聚合。它匹配的是数值字段，表示按照数值范围进行分组。用户可以在ranges中添加分组，每个分组用from和to表示分组的起止数值。注意该分组包含起始数值，不包含终止数值。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-2-2-多维度桶嵌套聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-2-2-多维度桶嵌套聚合" aria-hidden="true">#</a> ◆ 7.2.2 多维度桶嵌套聚合</h3>
<blockquote>
<blockquote>
<p>在某些业务需求中，不仅需要一个维度的桶聚合，而且还可能有多维度桶嵌套聚合的需求。例如在搜索酒店时，可能需要统计各个城市的满房和非满房状态下的酒店平均价格。ES支持嵌套桶聚合，进行嵌套时，可以使用aggs子句进行子桶的继续嵌套，指标放在最里面的子桶内。以下DSL演示了多维度桶的使用方法：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-7-2-3-地理距离聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-2-3-地理距离聚合" aria-hidden="true">#</a> ◆ 7.2.3 地理距离聚合</h3>
<blockquote>
<blockquote>
<p>按照地理距离进行聚合是一个非常实用的功能，例如在搜索酒店时，可能需要对附近的酒店个数先预览一下：查看距离当前位置2km范围内、2～3km范围内、5km范围内的酒店个数。再如，在与电动汽车相关的充电需求中，车主需要搜寻附近充电桩的数量，以便能快速地完成充电。如图7.3所示为国家电网“e充电”手机App的地图搜索模式，用户附近的汽车充电桩数量将随着地图的缩放而逐渐变化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图7.3　“e充电”手机App的聚合</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户可以使用geo_distance聚合进行地理距离聚合，通过field参数来设置距离计算的字段，可以在origin子句中设定距离的原点，通过unit参数来设置距离的单位，可以选择mi和km，分别表示米和千米。ranges子句用来对距离进行阶段性的分组，该子句的使用方式和前面介绍的range聚合类似。以下DSL演示了使用geo_distance聚合进行地理距离聚合的方法：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上述DSL中，给定了一个地理位置，此处使用ranges聚合对距离该位置的酒店划分了3个分组的桶：第1个桶为3km范围内；第2个桶为3～10km；第3个桶为大于等于10km</p>
</blockquote>
</blockquote>
<h3 id="◆-7-3-聚合方式" tabindex="-1"><a class="header-anchor" href="#◆-7-3-聚合方式" aria-hidden="true">#</a> ◆ 7.3 聚合方式</h3>
<blockquote>
<blockquote>
<p>ES支持灵活的聚合方式，它不仅支持聚合和查询相结合，而且还可以使聚合的过滤条件不影响搜索条件，并且还支持在聚合后的结果中进行过滤筛选。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-3-1-直接聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-3-1-直接聚合" aria-hidden="true">#</a> ◆ 7.3.1 直接聚合</h3>
<blockquote>
<blockquote>
<p>直接聚合指的是聚合时的DSL没有query子句，是直接对索引内的所有文档进行聚合。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-3-2-先查询再聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-3-2-先查询再聚合" aria-hidden="true">#</a> ◆ 7.3.2 先查询再聚合</h3>
<blockquote>
<blockquote>
<p>与直接聚合相对应，这种查询方式需要增加query子句，query子句和普通的query查询没有区别，参加聚合的文档必须匹配query查询。下面的DSL演示了这种用法：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-7-3-3-前过滤器" tabindex="-1"><a class="header-anchor" href="#◆-7-3-3-前过滤器" aria-hidden="true">#</a> ◆ 7.3.3 前过滤器</h3>
<blockquote>
<blockquote>
<p>有时需要对聚合条件进一步地过滤，但是又不能影响当前的查询条件。例如用户进行酒店搜索时的搜索条件是天津的酒店，但是聚合时需要将非满房的酒店平均价格进行聚合并展示给用户。此时不能变更用户的查询条件，需要在聚合子句中添加过滤条件。下面的DSL展示了在聚合时使用过滤条件的用法：[插图][插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-7-3-4-后过滤器" tabindex="-1"><a class="header-anchor" href="#◆-7-3-4-后过滤器" aria-hidden="true">#</a> ◆ 7.3.4 后过滤器</h3>
<blockquote>
<blockquote>
<p>在有些场景中，需要根据条件进行数据查询，但是聚合的结果集不受影响。例如在酒店搜索场景中，用户的查询词为“假日”，此时应该展现标题中带有“假日”的酒店。但是在该页面中，如果还希望给用户呈现出全国各个城市的酒店的平均价格，这时可以使用ES提供的后过滤器功能。该过滤器是在查询和聚合之后进行过滤的，因此它的过滤条件对聚合没有影响。以下的DSL展示了后过滤器的使用：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上面的查询中，使用match匹配title中包含“假日”的酒店，并且查询出这些酒店的平均价格，最后使用post_filter设置后过滤器的条件，将酒店的城市锁定为“北京”</p>
</blockquote>
</blockquote>
<h3 id="◆-7-4-聚合排序" tabindex="-1"><a class="header-anchor" href="#◆-7-4-聚合排序" aria-hidden="true">#</a> ◆ 7.4 聚合排序</h3>
<blockquote>
<blockquote>
<p>ES对于聚合结果的默认排序规则有时并非是我们期望的。可以使用ES提供的sort子句进行自定义排序，有多种排序方式供用户选择：可以按照聚合后的文档计数的大小进行排序；可以按照聚合后的某个指标进行排序；还可以按照每个组的名称进行排序。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-4-1-按文档计数排序" tabindex="-1"><a class="header-anchor" href="#◆-7-4-1-按文档计数排序" aria-hidden="true">#</a> ◆ 7.4.1 按文档计数排序</h3>
<blockquote>
<blockquote>
<p>在聚合排序时，业务需求可能有按照每个组聚合后的文档数量进行排序的场景。此时可以使用_count来引用每组聚合的文档计数进行排序。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-4-2-按聚合指标排序" tabindex="-1"><a class="header-anchor" href="#◆-7-4-2-按聚合指标排序" aria-hidden="true">#</a> ◆ 7.4.2 按聚合指标排序</h3>
<blockquote>
<blockquote>
<p>在聚合排序时，业务需求可能有按照每个组聚合后的指标值进行排序的场景。此时可以使用指标的聚合名称来引用每组聚合的文档计数。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-4-3-按分组key排序" tabindex="-1"><a class="header-anchor" href="#◆-7-4-3-按分组key排序" aria-hidden="true">#</a> ◆ 7.4.3 按分组key排序</h3>
<blockquote>
<blockquote>
<p>在聚合排序时，业务需求可能有按照每个分组的组名称排序的场景。此时可以使用_key来引用分组名称。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-5-聚合分页" tabindex="-1"><a class="header-anchor" href="#◆-7-5-聚合分页" aria-hidden="true">#</a> ◆ 7.5 聚合分页</h3>
<blockquote>
<blockquote>
<p>ES支持同时返回查询结果和聚合结果</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>查询结果和聚合结果各自封装在不同的子句中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有时我们希望聚合的结果按照每组选出前N个文档的方式进行呈现，最常见的一个场景就是电商搜索，如搜索苹果手机6S，搜索结果应该展示苹果手机6S型号中的一款手机即可，而不论该型号手机的颜色有多少种。另外，当聚合结果和查询结果封装在一起时，还需要考虑对结果分页的问题，此时前面介绍的聚合查询就不能解决这些问题了。ES提供的Top hits聚合和Collapse聚合可以满足上述需求，但是这两种查询的分页方案是不同的。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-5-1-top-hits聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-5-1-top-hits聚合" aria-hidden="true">#</a> ◆ 7.5.1 Top hits聚合</h3>
<blockquote>
<blockquote>
<p>Top hits聚合指的是聚合时在每个分组内部按照某个规则选出前N个文档进行展示。例如，搜索“金都”时，如果希望按照城市分组，每组按照匹配分数降序展示3条文档数据</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Top hits聚合能满足“聚合的结果按照每组选出N个文档的方式进行呈现”的需求，但是很遗憾，它不能完成自动分页功能。如果在聚合中使用Top hits聚合并期望对数据进行分页，则要求聚合的结果一定不能太多，因为需要由客户端自行进行分页，此时对分页内存的存储能力是一个挑战。可以一次性获取聚合结果并将其存放在内存中或者Redis中，然后自行实现翻页逻辑，完成翻页。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-5-2-collapse聚合" tabindex="-1"><a class="header-anchor" href="#◆-7-5-2-collapse聚合" aria-hidden="true">#</a> ◆ 7.5.2 Collapse聚合</h3>
<blockquote>
<blockquote>
<p>当在索引中有大量数据命中时，Top hits聚合存在效率问题，并且需要用户自行排序。针对上述问题，ES推出了Collapse聚合，即用户可以在collapse子句中指定分组字段，匹配query的结果按照该字段进行分组，并在每个分组中按照得分高低展示组内的文档。当用户在query子句外指定from和size时，将作用在Collapse聚合之后，即此时的分页是作用在分组之后的。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-1-1-背景简介" tabindex="-1"><a class="header-anchor" href="#◆-8-1-1-背景简介" aria-hidden="true">#</a> ◆ 8.1.1 背景简介</h3>
<blockquote>
<blockquote>
<p>与百度和Google等互联网搜索引擎不同，酒店搜索引擎是专门面向酒店搜索和预订的垂直搜索引擎，它的数据不是来自互联网，而是来自业务系统。另外，业务的垂直性也决定了搜索的垂直性，用户可以针对酒店的属性、服务及评分等各种维度对酒店进行筛选。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本项目的目的是让用户能够根据自身的需求搜索到匹配的酒店，然后可以直接预订酒店的房间，进而享受酒店的相关配套服务。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-1-2-搜索建议功能简介" tabindex="-1"><a class="header-anchor" href="#◆-8-1-2-搜索建议功能简介" aria-hidden="true">#</a> ◆ 8.1.2 搜索建议功能简介</h3>
<blockquote>
<blockquote>
<p>搜索建议的需求主要关注两点，即匹配和排序。匹配即能够通过用户的输入进行前缀匹配，给出匹配的搜索热词。用户的输入分为3种，即根据汉字输入、根据拼音全拼输入和根据拼音的首字母输入。排序即根据建议词的优先级进行排序，排序的优先级按照汉字输入匹配、拼音全拼输入匹配和拼音的首字母输入匹配逐次递减。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在图8.1的左图中，用户在搜索框内输入qs，表示期望搜索拼音的首字母为qs的关键词，则匹配出的结果为以“轻奢”开头的关键词。在图8.1中间的图中，用户在搜索框内输入changsheng，表示期望搜索拼音为changsheng的关键词，则匹配出的结果大多数为以“昌盛”开头的关键词。在图8.1的右图中，用户在搜索框内输入“如意”，则匹配出的结果为以“如意”开头的关键词。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h3 id="◆-8-1-3-搜索功能简介" tabindex="-1"><a class="header-anchor" href="#◆-8-1-3-搜索功能简介" aria-hidden="true">#</a> ◆ 8.1.3 搜索功能简介</h3>
<blockquote>
<blockquote>
<p>本项目的搜索功能分为两个阶段，不同阶段的搜索条件不同。第一阶段为搜索的初始状态，用户可以根据城市、经纬度和酒店关键词搜索酒店，如图8.2所示。[插图]图8.2　第一阶段搜索功能的效果第二阶段为搜索结果展示状态，在第一阶段的搜索结果中，需要对命中的酒店集合进行聚合，聚合的维度包括酒店与用户之间的距离、酒店价格和酒店星级等。用户可以根据这些聚合结果对搜索结果进一步过滤，如图8.3所示。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图8.3　第二阶段搜索功能的效果</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>酒店的搜索结果包含酒店名称、酒店与用户当前位置之间的距离、价格、好评率、网友印象、商圈、酒店地址和星级等。另外，上述两个阶段的搜索结果列表都支持分页展示功能，单击页码后搜索条件保持不变，可以翻页展示搜索结果列表。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-1-4-排序功能简介" tabindex="-1"><a class="header-anchor" href="#◆-8-1-4-排序功能简介" aria-hidden="true">#</a> ◆ 8.1.4 排序功能简介</h3>
<blockquote>
<blockquote>
<p>排序功能对于商业搜索引擎来说至关重要。搜索作为酒店的引流入口之一，其排序的结果决定酒店被展示机会的多少。酒店搜索排序支持常见的用户维度的排序，如按好评率从高到低排序、按价格从低到高或从高到低排序，以及按距离从近到远排序等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>综合排序功能需要考虑多种因素，包括搜索关键词和酒店标题的匹配程度、酒店与用户之间的距离、好评率和价格等。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-2-1-总体架构设计" tabindex="-1"><a class="header-anchor" href="#◆-8-2-1-总体架构设计" aria-hidden="true">#</a> ◆ 8.2.1 总体架构设计</h3>
<blockquote>
<blockquote>
<p>酒店搜索引擎的后端服务主要包含两个子服务，即搜索服务和搜索建议服务。当用户在搜索框中输入部分关键字时，搜索建议服务会弹出一个下拉列表，其中列出的是与当前关键字相关的查询词，用户可以根据自己的需求选择查询词，从而减少输入查询词的时间，提升搜索体验。搜索服务主要负责根据用户的查询词和筛选条件搜索出匹配的酒店，并结合搜索结果的酒店多维度返回聚合结果，从而帮助用户对当前结果进行进一步筛选，触发二次搜索。搜索建议因为和酒店的搜索业务关联不大，因此作为单独服务进行拆分，这样既对业务进行了解耦，后续单独优化处理时又不会影响主搜索流程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图8.7　酒店搜索项目的总体架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>酒店搜索引擎涉及的组件比较多，这是因为数据的流通需要借助多种组件来完成。例如，“酒店数据”到“ES”索引，这部分需要两个模块来完成，一是离线模块，主要负责一次性将酒店的数据导入ES索引中；二是实时模块，主要负责将实时增量的酒店数据导入ES中。再如对搜索日志的处理，一般情况下，搜索服务部署在多台计算机上，后端需要将用户搜索日志收集在一起，以供搜索建议等模块使用，如果数据量比较大，还需要用到Hadoop等分布式存储服务。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-2-2-组件简介" tabindex="-1"><a class="header-anchor" href="#◆-8-2-2-组件简介" aria-hidden="true">#</a> ◆ 8.2.2 组件简介</h3>
<blockquote>
<blockquote>
<p>总体架构用到了Canal、Flume和Hadoop等组件</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.Canal简介在介绍Canal之前，先介绍一下MySQL的Binlog日志。Binlog日志用于记录MySQL Master的所有数据表中更新的操作，包括新增、修改和删除数据，它是以二进制形式存储的数据操作日志，所以叫作Binlog。Binlog日志用于同步关系型数据库中的主从数据，然后对其进行重放，从而达到与Master数据同步的目的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Canal是阿里巴巴开源的监听Binlog日志的组件，它实现了MySQL Slave与MySQL Master之间的通信协议，将自己伪装成MySQL Slave，从而获取和解析Binlog日志。对于解析结果的存储，Canal提供了很多对接方案，用户可选择配置Kafka、HBase、ES等存储组件</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.Flume简介Flume是一种高可用、高并发、分布式的数据传输系统，它不仅具有故障转移和恢复机制，而且具有一定的健壮性和容错性。借助Flume，用户可以在多种日志场景中定义数据的输入端和输出端</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过Flume可以将业务日志传输到HDFS中。Flume可用于传输大量事件数据，如行为日志、图像信息流等，因此业界一般都用它来完成数据的汇总工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图8.9　Flume数据流模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.Hadoop简介Hadoop是一个分布式系统基础架构。用户可以使用Hadoop提供的开发接口开发分布式程序，也可以使用其生态圈中的Hive进行SQL的数据开发。Hadoop的设计理念是将数千台服务器有效地组织成集群，该集群可以提供大规模的数据处理和存储功能，但是底层的细节用户是无感知的，这使得用户可以将更多的精力放在业务开发上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Hadoop实现了一个分布式文件系统（Hadoop Distributed File System，简称HDFS），它具有高容错性的特点，而且提供高传输率进行数据的输入/输出。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HDFS模型，其主要角色分为NameNode节点和DataNode节点，NameNode节点主要负责管理文件系统的元数据及维护DataNode节点的心跳检测；DataNode节点主要负责数据的存储和读取。一个传统的文件在HDFS中被切分为块（block），每个块在HDFS中存储时可以选择多个副本策略进行存储，以防止出现部分DataNode节点发生故障时数据丢失的问题。在客户端进行数据读写操作时，需要先和NameNode节点进行通信确认，之后再向DataNode节点进行数据的传输工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图8.10　Hadoop的HDFS模型</p>
</blockquote>
</blockquote>
<h3 id="◆-8-2-3-搜索建议方案" tabindex="-1"><a class="header-anchor" href="#◆-8-2-3-搜索建议方案" aria-hidden="true">#</a> ◆ 8.2.3 搜索建议方案</h3>
<blockquote>
<blockquote>
<p>搜索建议所使用的查询词来源于搜索系统中的用户历史搜索行为日志，因此需要一段时间的业务积累。用户搜索日志存储在Hadoop中。从Hadoop中获取用户搜索日志后，需要对搜索关键字进行统计，如统计每个搜索关键字的搜索次数</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>统计的数值将作为suggest匹配后的排序权重，最后由初始化程序将处理的结果存入ES中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在将数据存储到ES中时，需要满足根据拼音首字母和拼音全拼匹配查询词的场景，因此需要借助HanLP工具得到查询词对应的拼音首字母和拼音全拼，之后将查询词、拼音首字母和拼音全拼写入索引中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为满足搜索建议的匹配逻辑，在ES中建立搜索建议索引时需要考虑3个比较重要的字段：一是提示词字段，该字段为原始的用户搜索的中文字段；二是提示词的拼音全拼字段；三是提示词的拼音首字母字段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>客户端发起搜索建议请求，搜索建议服务基于查询词、拼音首字母和拼音全拼到搜索建议索引中进行匹配，并对不同匹配赋予一定的排序权重值后进行排序，最后将匹配结果添加到最终的列表中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图8.12　搜索建议服务的工作流程图</p>
</blockquote>
</blockquote>
<h3 id="◆-8-2-4-匹配方案" tabindex="-1"><a class="header-anchor" href="#◆-8-2-4-匹配方案" aria-hidden="true">#</a> ◆ 8.2.4 匹配方案</h3>
<blockquote>
<blockquote>
<p>通过前面对搜索匹配功能的介绍可以知道，酒店的匹配涉及ES中的多种查询功能，如term查询、match查询、geo_distance查询和布尔查询等，并且匹配阶段还需要返回根据多个字段聚合的结果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在进行结果展示时需要翻页展示，为简单起见，本项目采用前端进行翻页计算，后端进行翻页返回的方式实现翻页功能，即前端根据每页的结果数和搜索结果总数进行页码区域的翻页展示，后端根据前端传入的页码和每页的结果数对ES发出翻页请求，然后将结果返回给前端。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-2-5-排序方案" tabindex="-1"><a class="header-anchor" href="#◆-8-2-5-排序方案" aria-hidden="true">#</a> ◆ 8.2.5 排序方案</h3>
<blockquote>
<blockquote>
<p>为支持酒店用户维度的排序，在使用ES进行查询时需要加入排序子句。在综合排序功能中，酒店排序需要考虑多种因素，包括搜索关键词和酒店标题的匹配程度、酒店与用户之间的距离、好评率和满房状态等。下面对这些因素采用线性加权的方式对酒店进行打分，打分公式为：score=w1·m+w2·d+w3·f+w4·r其中：m代表搜索关键词和酒店标题的匹配程度，该值和酒店打分为正相关趋势；d代表酒店与用户之间的距离，该值和酒店打分为负相关趋势，即距离值越大，酒店打分越低；f代表好评率，该值和酒店打分为正相关趋势；r代表满房状态，如果酒店处于满房状态，则不论该酒店在上述3个因素中得分有多高，该酒店的得分一定小于非满房状态的酒店得分；w1、w2、w3和w4分别代表各个维度的权重值。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-3-1-索引创建" tabindex="-1"><a class="header-anchor" href="#◆-8-3-1-索引创建" aria-hidden="true">#</a> ◆ 8.3.1 索引创建</h3>
<blockquote>
<blockquote>
<p>在Kibana中执行索引创建的语句如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在真实环境中，用户在搜索框内每输入一个字符，前端都会向搜索建议服务发起一次请求。在这种情况下，系统对搜索建议的响应速度的要求是非常高的。同时，大量并发的请求也会加重搜索建议的负载。为提高系统的访问速度，减轻系统负载，这里设置了3个分片；同时，为了提高系统的高可用性，这里设置的副分片个数为2。在mappings设置中，chinese为提示词字段；full_pinyin为提示词的拼音全拼字段；head_pinyin为提示词的拼音首字母字段。上述3个字段的类型均为completion。注意只有将字段类型设置为completion，该字段才能作为suggest查询字段进行使用。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-3-2-后端服务" tabindex="-1"><a class="header-anchor" href="#◆-8-3-2-后端服务" aria-hidden="true">#</a> ◆ 8.3.2 后端服务</h3>
<blockquote>
<blockquote>
<p>搜索建议的数据源是用户搜索日志，这里假设我们已经获取了该数据，并且将该数据存储在本地的suggest_words.csv文件中。该文件中每行有两个字段，用逗号分隔，第一个字段表示提示词的汉字形式，第二个字段表示该提示词的热度。</p>
</blockquote>
</blockquote>
</div></template>


