<template><div><h1 id="操作系统-第四版" tabindex="-1"><a class="header-anchor" href="#操作系统-第四版" aria-hidden="true">#</a> 操作系统（第四版）</h1>
<p>刘振鹏 张明 王煜</p>
<h3 id="◆-1-1-1-计算机系统" tabindex="-1"><a class="header-anchor" href="#◆-1-1-1-计算机系统" aria-hidden="true">#</a> ◆ 1.1.1 计算机系统</h3>
<blockquote>
<blockquote>
<p>人与硬件系统之间是软件系统，大致可分为系统软件、支撑软件和应用软件3层。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-1　计算机系统的层次结构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>计算机硬件系统主要由运算器、内存储器、控制器、I/O控制系统、辅助存储设备等功能部件组成。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-1-2-操作系统简介" tabindex="-1"><a class="header-anchor" href="#◆-1-1-2-操作系统简介" aria-hidden="true">#</a> ◆ 1.1.2 操作系统简介</h3>
<blockquote>
<blockquote>
<p>（1）“有效”主要指操作系统在管理资源方面要考虑到系统运行效率和资源的利用率，要尽可能地提高处理机的利用率，让它尽可能少地空转，其他的资源，例如内存、硬盘，则应该在保证访问效能的前提下尽可能地减少浪费的空间等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）“合理”主要是指操作系统对于不同的用户程序要“公平”，以保证系统不发生“死锁”和“饥饿”的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）“方便”主要是指人机界面方面，包括用户使用界面和程序设计接口两方面的易用性、易学性和易维护性。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-1-操作系统的形成" tabindex="-1"><a class="header-anchor" href="#◆-1-2-1-操作系统的形成" aria-hidden="true">#</a> ◆ 1.2.1 操作系统的形成</h3>
<blockquote>
<blockquote>
<p>1.无操作系统时的计算机系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）人工操作方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①用户独占全机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②处理机等待人工操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.单道批处理操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于系统对作业的处理都是成批地进行的，且在内存中始终只保持一个作业，故称为单道批处理系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>批处理系统旨在提高系统资源的利用率和系统吞吐量。但这种单道批处理系统仍然不能很好地利用系统资源，现在已很少使用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）单道批处理系统的特征。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①自动性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②顺序性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③单道性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.多道批处理操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在早期的单道批处理系统中，内存中仅有一道作业，这使得系统中仍有较多的空闲资源，致使系统的性能较差。为了进一步提高资源的利用率和增加系统的吞吐量，在20世纪60年代中期引入了多道程序设计技术，由此而形成了多道批处理系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在多道批处理系统中，用户所提交的作业都先存放在外存并排成一个队列，该队列称为“后备队列”；然后，由作业调度程序按一定的算法从后备队列中选择若干个作业调入内存，使它们共享处理机和系统中的各种资源，以达到提高资源利用率和系统吞吐量的目的。在操作系统中引入多道程序设计可带来以下好处：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①提高处理机的利用率。当内存中仅存放一道程序时，每逢该程序在运行中发出I/O请求后，处理机空闲，必须在其I/O完成后才继续运行；尤其是I/O设备的低速性，更使处理机的利用率显著降低。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②可提高内存和I/O设备利用率。为了能运行较大作业，通常内存都具有较大容量，但由于80％以上的程序都属于中小型，因此在单道程序环境下也必定会造成内存的浪费。类似地，对于系统中所配置的多种类型的I/O设备，在单道程序环境下也不能充分利用。如果允许在内存中装入多道程序，并允许它们并发执行，则会大大提高内存利用率和I/O设备的利用率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③增加系统吞吐量。在保持处理机、I/O设备不断忙碌的同时，也必然会大幅度地提高系统的吞吐量，从而降低作业加工所需的费用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）多道批处理系统的特征。在操作系统中引入多道程序设计技术后，系统具有以下特征：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①多道性。在内存中可同时驻留多道程序，并允许它们并发执行，从而有效地提高了资源利用率和增加系统吞吐量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②无序性。多个作业完成的先后顺序与它们进入内存的顺序之间并无严格的对应关系，即先进入内存的可能较后甚至最后完成，而后进入内存的又可能先完成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③调度性。作业从提交给系统开始直至完成，需要经过以下两次调度：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　作业调度。指按一定的作业调度算法，从外存的后备程序队列中选择若干个作业调入内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　进程调度。指按一定的进程调度算法，从已在内存的作业中选择一个作业，将处理机分配给它，使之执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>多道批处理系统的主要优点如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①资源利用率高。由于在内存中装入了多道程序，使它们共享资源，保持资源处于忙碌状态，从而使各种资源得以充分利用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②系统吞吐量大。系统吞吐量是指系统在单位时间内所完成的总工作量。能提高系统吞吐量的原因可归结为：第一，处理机和其他资源保持“忙碌”状态；第二，仅当作业完成或运行不下去时才进行切换，系统开销小。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>多道批处理系统的主要缺点如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①平均周转时间长。作业的周转时间是指从作业进入系统开始，直至其完成并退出系统为止所经历的时间。在批处理系统中，由于作业要排队依次进行处理，因而作业的周转时间较长，通常需几小时甚至几天。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②无交互能力。用户一旦把作业提交给系统后直至作业完成，用户都不能与自己的作业进行交互，这对修改和调试程序都是极不方便的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>多道批处理系统需要解决的问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①处理机管理问题。在多道程序之间应如何分配被它们共享的处理机，使处理机既能满足各程序的需要，又能提高处理机的利用率，以及一旦将处理机分配给某程序后又应在何时收回等一系列问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②内存管理问题。包括应如何为每道程序分配必要的内存空间，使它们“各得其所”且不致因互相重叠而丢失信息，以及应如何防止因某道程序出现异常情况而破坏其他程序等问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③I/O设备管理问题。系统中可能具有多种类型的I/O设备供多道程序共享，应如何分配这些I/O设备，如何做到既方便用户对设备的使用、又能提高设备的利用率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④文件管理问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>⑤作业管理问题。对于系统中的各种应用程序，例如：有的属于计算型，即以计算为主的程序；有的属于I/O型，即以I/O为主的程序；有些作业既重要又紧迫，有的又要求系统能及时响应，这时应如何对它们进行组织。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.分时系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）分时系统的产生。如果说，推动多道批处理系统形成和发展的主要动力是提高资源利用率和增加系统吞吐量，那么，推动分时系统形成和发展的主要动力则是用户的需要。具体地说，用户需要表现在以下几个方面：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①人机交互。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②共享主机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户也在使用该计算机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③便于用户上机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分时系统恰是为了满足上述的用户需要所形成的一种新型操作系统。它与多道批处理系统有着截然不同的性能。分时系统是指一台主机上连接了多个带有显示器和键盘的终端，同时允许多个用户共享主机中的资源，每个用户都可通过自己的终端以交互方式使用计算机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了实现分时系统必须解决一系列问题，其中最关键的问题是如何使用户能与自己的作业交互，即当用户在自己的终端输入命令时系统应能及时接收和及时处理该命令，并将处理结果返回给用户。接着用户可输入下一条命令，此即人机交互。应当强调指出，即使有多个用户同时通过自己的键盘输入命令，系统也应能全部地及时接收并及时处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①及时接收。要及时接收用户输入的命令或数据并不困难，只需在系统中配置一个多路卡。例如，当要在主机上连接8个终端时，须配置一个8用户的多路卡。多路卡的作用是使主机能同时接收用户从各个终端上输入的数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>还需为每个终端配置一个缓冲区，用来暂存用户输入的命令。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②及时处理。人机交互的关键是使用户输入命令后能及时地控制自己的程序运行或修改自己的程序。为此，各个用户的程序都必须在内存中，且应能频繁地获得处理机而运行；否则，用户输入的命令将无法作用到自己的程序上。批处理系统是无法实现人机交互的，因为通常大多数作业都是驻留在外存上，即使调入内存的作业也经常要经过较长时间的等待后方能运行，因而用户输入的命令很难及时地作用到自己的作业上。可见，为了实现人机交互应该做到：使所有的用户程序都直接进入内存；在不长的时间内，就能使每个程序都运行一次（较短的时间），这样方能使用户输入的命令获得及时处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）分时系统的实现方法。为了确保系统能及时处理，必须彻底改变原来批处理系统的运行方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一方面用户程序不能先进入磁盘，然后再调入内存。因为程序在磁盘上不能运行，当然用户也就无法与程序进行交互，因此，程序应直接进入内存；另一方面不允许一个程序长期占用处理机直至它运行结束或发生I/O请求后，才调度其他程序运行。应该规定每个程序只运行一个很短的时间（例如，0.1s，通常把这段时间称为时间片），然后便暂停该程序的运行并立即调度下一个程序运行。如果在不长的时间（例如3s）内，能使所有的用户程序都执行一次（一个时间片时间），便可使每个用户都能及时地与自己的程序交互，从而可使用户的请求及时得到响应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具体的方法有以下几种：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①单道分时系统。在20世纪60年代初期，由美国麻省理工学院建立的第一个分时系统CTSS便属于单道分时系统。在该系统中内存只驻留一道程序，其余程序都在外存上。每当内存中的程序运行一个时间片后，便被调至外存（称为调出），再从外存上选一个程序装入内存（称为调入）并运行一个时间片，以此方法使所有的程序都能在一个规定的时间内轮流运行一个时间片，这样便能使所有的用户都能与自己的程序交互。由于单道分时系统只有一道程序驻留在内存，在多个程序的轮流运行过程中，每个程序往往可能频繁地被调入/调出多次，开销很大，因此系统性能较差。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②具有“前台”和“后台”的分时系统。在单道批处理系统中，作业调入/调出时，处理机空闲；内存中的作业在执行I/O请求时处理机也空闲。为了充分利用处理机而引入了“前台”和“后台”的概念。在具有前、后台的系统中，内存被固定地划分为“前台区”和“后台区”两部分，“前台区”存放按时间片“调入”和“调出”的交互式程序，“后台区”存放批处理作业。仅当前台调入/调出时，或前台已无程序可运行时，才运行“后台区”中的作业。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③多道分时系统。在分时系统中引入多道程序设计技术后，可在内存中同时存放多道程序，每道程序无固定位置，如果程序都较小，内存中便可多装入几道程序，由系统把已具备运行条件的所有程序排成一个队列，使它们以此轮流地获得一个时间片来运行。由于切换程序就在内存，不用花费调入、调出开销，故多道分时系统具有较好的系统性能。现代的分时系统都属于多道分时系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分时系统的特征。分时系统与多道批处理系统相比，具有完全不同的特征。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①多路性。允许在一台主机上同时连接多台联机终端，系统按分时原则为每个用户服务。宏观上，是多个用户同时工作，共享系统资源；微观上，则是每个用户程序轮流运行一个时间片。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②独立性。每个用户各占一个终端，彼此独立操作、互不干扰。因此，用户会感觉到就像一人独占主机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③及时性。用户的请求能在很短时间内获得响应，此时间间隔是以人们所能接受的等待时间来确定的，通常为2～3s。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④交互性。用户可通过终端与系统进行广泛的人机对话。其广泛性表现在：用户可以请求系统提供各方面的服务，如文件编辑、数据处理和资源共享等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.实时系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）实时系统的引入。虽然多道批处理系统和分时系统已获得了令人较为满意的资源利用率和响应时间，从而使计算机的应用范围日益扩大，但它们仍然不能满足以下两个领域的需要：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①实时控制。当把计算机用于生产过程的控制以形成以计算机为中心的控制系统时，系统要求能实时采集现场数据，并对所采集的数据进行及时处理，进而自动地控制相应的执行机构，使某些（个）参数（例如温度、压力、方位等）能按预定的规律变化，以保证产品的质量和提高产量。类似地，也可将计算机用于武器的控制，例如火炮的自动控制系统、飞机的自动驾驶系统，以及导弹的制导系统等。通常把要求进行实时控制的系统统称为实时控制系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②实时信息处理。通常把要求对信息进行实时处理的系统称为实时信息处理系统。该系统由一台或多台主机通过通信线路连接成百上千个远程终端，主机接收从远程终端发来的服务请求，根据用户提出的问题，对信息进行检索和处理，并在很短的时间内为用户做出正确的回答。典型的实时信息处理系统有飞机订票系统、情报检索系统等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实时控制系统和实时信息处理系统统称为实时系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）实时任务的类型。在实时系统中必须存在着若干个实时任务，由它们反映或控制某个（些）外部事件，因而带有某种程度的紧迫性。可从不同的角度对实时任务加以分类。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①按任务执行时是否呈现周期性来划分</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>周期性实时任务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>非周期性实时任务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②根据对截止时间的要求来划分，包括：强实时任务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>弱实时任务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实时系统与分时系统的比较</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①多路性。实时信息处理系统与分时系统一样具有多路性，系统按分时原则为多个终端用户服务；而对实时控制系统，其多路性主要表现在经常对多路的现场信息进行采集以及对多个对象或多个执行机构进行控制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②独立性。实时信息处理系统与分时系统一样具有独立性，每个终端用户在向实时系统提出服务请求时，彼此独立地操作，互不干扰；而在实时控制系统中信息的采集和对对象的控制，也都是彼此互不干扰。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③及时性。实时信息系统对实时性的要求与分时系统类似，都是以人们所能接受的等待时间来确定；而实时控制系统的及时性，则是以控制对象所要求的开始截止时间或完成截止时间来确定的，一般为秒级、百毫秒级直至毫秒级。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④交互性。实时信息处理系统虽然也具有交互性，但这里人与系统的交互，仅限于访问系统中某些特定的专用服务程序。它不像分时系统那样能向终端用户提供数据处理、资源共享等服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>⑤可靠性。分时系统虽然也要求系统可靠，但相比之下，实时系统则要求系统高度可靠。因为任何差错都可能带来巨大的经济损失，甚至无法预料的灾难性后果。因此，在实时系统中，往往都采取了多级容错措施，以此保证系统的安全及数据的安全。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>批处理系统、分时系统和实时系统是3种基本的操作系统类型。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-2-操作系统的进一步发展" tabindex="-1"><a class="header-anchor" href="#◆-1-2-2-操作系统的进一步发展" aria-hidden="true">#</a> ◆ 1.2.2 操作系统的进一步发展</h3>
<blockquote>
<blockquote>
<p>1.微机操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>配置在微机上的操作系统称为微机操作系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可按微机的字长分成8位、16位、32位和64位的微机操作系统，也可分为单用户单任务操作系统、单用户多任务操作系统和多用户多任务操作系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）单用户单任务操作系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最有代表性的单用户单任务操作系统是CP/M和MS-DOS。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）单用户多任务操作系统。单用户多任务操作系统的含义是：只允许一个用户上机，但允许将一个用户程序分成若干个任务，使它们并发执行，从而有效地改善系统的性能。在32位微机上所配置的32位微机操作系统大多数是单用户多任务操作系统，其中最有代表性的是OS/2、MS Windows和Linux。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）多用户多任务操作系统。多用户多任务的含义是，允许多个用户通过各自的终端使用同一台主机，共享主机系统中的各类资源，而每个用户程序又可进一步分为几个任务，使它们并发执行，从而可进一步提高资源利用率和增加系统吞吐量。在大、中、小型机中所配置的都是多用户多任务操作系统；而在32位微机上，也有不少配置的是多用户多任务操作系统。其中，最有代表性的是UNIX操作系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.多处理机操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）多处理机系统的引入。短短几十年的计算机发展历史清楚地表明提高计算机系统性能的主要途径有两条：一是提高构成计算机系统的元器件的运行速度；二是改进计算机系统的体系结构。早期的计算机系统基本上都是单处理机系统。进入20世纪70年代出现了多处理机系统（Multi-Processor System，MPS），试图从计算机体系结构上来改善系统性能。引入多处理机系统的原因可归结为以下几点：①增加系统的吞吐量。随着系统中处理机数目的增多，可使系统在较短的时间内完成更多的工作。但为使多台处理机能协调地工作，系统必须为此付出一定的开销。因此，利用n个处理机运行时所获得的加速比达不到n倍。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②节省投资。在达到相同处理能力的情况下，与用n台独立的计算机系统相比，采用具有n个处理机的系统，可以节省费用。这是因为这时的n个处理机包含在同一个机箱内，且用同一电源和共享一部分资源，例如外设、内存等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③提高系统的可靠性。在MPS中通常都具有系统重构的功能，即当其中任何一个处理机发生故障时，系统能立即将该处理机上所处理的任务迁移到其他的一个或多个处理机上去处理，整个系统仍能正常运行，仅使系统的性能有所降低。例如，对于一个含有10个处理机的系统，当其中某一个处理机出现故障时，系统性能大约降低10％。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）多处理机系统的类型。根据多个处理机之间耦合的紧密程度，可把多处理机系统分为两类：紧密耦合多处理机系统和松散耦合多处理机系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①紧密耦合多处理机系统。在紧密耦合多处理机系统中，通常是通过高速总线或高速交叉开关来实现多个处理机之间的相互连接。它们共享内存和I/O设备，并要求将内存储器划分为若干个能独立访问的存储器模块，以便多个处理机能同时对内存进行访问。系统中所有的资源和进程都由操作系统实施统一的控制和管理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②松散耦合多处理机系统。在松散耦合MPS中，通常是通过通道或通信线路来实现多台计算机之间的互联。每台计算机都有自己的存储器、I/O设备，并配置了操作系统来管理本地资源和在本地运行的进程。因此，每一台计算机都能独立地工作，必要时可通过通信线路与其他计算机交换信息，以及协调它们之间的工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）多处理机操作系统的类型。在多处理机系统中所配置的多处理机操作系统，可分成以下两种模式：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①非对称多处理机模式，又称主-从模式。在非对称多处理机系统中，把处理机分为主处理机和从处理机两类。主处理机只有一个，其上配置了操作系统，用于管理整个系统的资源，并负责为各从处理机分配任务。从处理机可有多个，它们执行预先规定的即由主处理机所分配的任务。在早期的特大型系统中，较多地采用主-从式操作系统。一般来说，主-从式操作系统易于实现，但资源利用率低。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②对称多处理机模式。通常在对称多处理机系统中，所有的处理机都是相同的。在每个处理机上运行一个相同的操作系统备份，用它来管理本地资源和控制进程的运行以及各计算机之间的通信。这种模式的优点是允许多个进程同时运行。例如，当有n个处理机时，可同时运行n个进程而不会引起系统性能的恶化。然而必须小心地控制I/O设备，以保证能将数据送至适当的处理机。同时，还必须注意使各处理机的负载平衡，以免有的处理机超载运行，而有的处理机空闲。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.网络操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）计算机网络的类型。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>根据网络拓扑结构的不同，可将网络分成以下5类：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　星形网络。每一个远地结点通过一条单独的传输线路与中心点连接，即采用点-点连接方式，使网络呈现星形。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　树形网络。将一个多级星形网络按层次排列便形成树形网络。树的根，即网络的最高层，是中央处理机，树的叶，即网络的最底层，为终端式个人计算机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　总线形网络。将若干个结点通过一条高速总线互联起来所形成的网络。采用广播方式，即由一个结点发出的信息可被总线上的所有结点接收。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　环形网络。采用高速点-点信道，将各结点连接成环形，网络中的信息流是定向的，由一个源结点发出的信息将绕环传输一周后返回源结点。●　网状形网络。各个结点间通过点-点连接，形成不规则的形状，结点之间通常都有多条通路。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>按网络所覆盖地理范围的大小，可把计算机网络分成以下两类：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　广域网（WAN）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络所覆盖的范围可以为一个地区或一个国家，乃至几大洲，其传输速率可达到数Mbit/s；网络中的通信设施属国家所有。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>●　局域网（LAN）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络所覆盖的范围为一栋楼或一个单位；其传输速率较高，可达到100Mbit/s；网络设施属单位所有。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络操作系统有以下两种工作模式：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①客户机/服务器（Client/Server，C/S）模式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②对等模式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.分布式操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在以往的计算机系统中，其处理和控制功能都高度地集中在一台主机上，所有的任务都由主机处理，这样的系统称为集中式系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式系统中，系统的处理和控制功能分散在系统的各个处理单元上。系统中的所有任务也可动态地被分配到各个处理单元中，使它们并行执行，实现分布处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式系统最基本的特征是处理上的分布。而处理分布的实质是资源、功能、任务和控制都是分布的。在分布式系统中，如果每个处理单元都是计算机，则可称为分布式计算机系统；如果处理单元只是处理机和局部存储器，则只能称为分布式（处理）系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式操作系统与网络操作系统的比较。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面从5个方面对两者进行比较：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①分布性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②并行性。在分布式处理系统中，具有多个处理单元，因此，分布式操作系统的任务分配程序可将多个任务分配到多个处理单元上，使这些任务并行执行，从而加速任务的执行。而在计算机网络中，每个用户的一个或多个任务通常都在自己（本地）的计算机上处理，因此在网络操作系统中通常无任务分配功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③透明性。分布式操作系统通常能很好地隐藏系统内部的实现细节。例如，对象的物理位置、并发控制、系统故障等对用户都是透明的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④共享性。在分布式系统中，分布在各个站点上的软、硬件资源可供全系统中的所有用户共享，并能以透明方式对它们进行访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>⑤健壮性。由于分布式系统的处理和控制功能是分布的，因此任何站点上的故障都不会给系统造成太大的影响；加之当某设备出现故障时，可通过容错技术实现系统重构，从而仍能保证系统的正常运行，因而系统具有健壮性，即具有较好的可用性和可靠性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.嵌入式操作系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>典型的例子有微波炉、电视机、汽车DVD、移动电话以及MP3播放器一类的设备。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不可信的软件肯定不能在嵌入式系统上运行。用户不能给自己的微波炉下载新的应用程序，所有的软件都保存在ROM中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>主要的嵌入式操作系统有Linux、Symbian和VxWorks等。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-3-推动操作系统发展的主要动力" tabindex="-1"><a class="header-anchor" href="#◆-1-2-3-推动操作系统发展的主要动力" aria-hidden="true">#</a> ◆ 1.2.3 推动操作系统发展的主要动力</h3>
<blockquote>
<blockquote>
<p>推动操作系统发展的主要动力</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）不断提高计算机资源利用率的需要。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）方便用户。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）器件的不断更新换代。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）计算机体系结构的不断发展。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当计算机由单处理机系统发展为多处理机系统时，操作系统也就相应地由单处理机操作系统发展为多处理机操作系统。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-2-计算机系统资源管理的观点" tabindex="-1"><a class="header-anchor" href="#◆-1-3-2-计算机系统资源管理的观点" aria-hidden="true">#</a> ◆ 1.3.2 计算机系统资源管理的观点</h3>
<blockquote>
<blockquote>
<p>计算机系统资源</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>资源分为4类：处理机、存储器、文件（程序和数据）以及I/O设备。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统要提供一些机制去协调程序间的竞争与同步，提供机制对资源进行合理使用，施加保护，以及采取虚拟技术来“扩充”资源等。操作系统的主要功能也是针对以下4类资源进行有效的管理：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）处理机管理。用于分配和控制处理机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）存储器管理。主要负责内存的分配和回收。（3）文件管理。负责文件的存取、共享和保护。（4）I/O设备管理。主要负责I/O设备的分配和操纵。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-3-进程的观点" tabindex="-1"><a class="header-anchor" href="#◆-1-3-3-进程的观点" aria-hidden="true">#</a> ◆ 1.3.3 进程的观点</h3>
<blockquote>
<blockquote>
<p>把操作系统看作由若干个可以同时独立运行的程序和一个对这些程序进行协调的核心所组成，这些同时运行的程序称为进程。每个进程都完成某一特定任务（例如控制用户程序的运行、处理某个设备的输入与输出……），而操作系统的核心则控制和协调这些进程的运行，解决进程之间的通信。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过进程之间的通信来解决共享资源时所带来的竞争问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程可以分为用户进程和系统进程两大类</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在研究、设计操作系统时面临的一个困难问题是系统中包含大量的程序模块，它们除了存在相互调用关系外，还有动态变化的相互制约和并行工作的关系。引入进程概念后，首先可以从那些能够并发运行的程序模块中归纳出若干系统进程，画出它们的状态转换图；然后逐个地研究各进程的状态转换图，列出状态转换的原因，找出转换时的主要工作过程及其有关程序；最后确定它们的功能及相互制约关系。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-4-用户与计算机硬件系统之间接口的观点" tabindex="-1"><a class="header-anchor" href="#◆-1-3-4-用户与计算机硬件系统之间接口的观点" aria-hidden="true">#</a> ◆ 1.3.4 用户与计算机硬件系统之间接口的观点</h3>
<blockquote>
<blockquote>
<p>用户可以通过以下两种方式来使用计算机：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）命令方式。这是指由操作系统提供了一组联机命令（语言），用户可通过键盘输入有关的命令来直接操纵计算机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）系统调用方式。操作系统提供了一组系统调用，用户可在应用程序中通过调用相应的系统调用来操纵计算机。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-4-操作系统的功能与特征" tabindex="-1"><a class="header-anchor" href="#◆-1-4-操作系统的功能与特征" aria-hidden="true">#</a> ◆ 1.4 操作系统的功能与特征</h3>
<blockquote>
<blockquote>
<p>批处理系统、分时系统和实时系统是大、中、小型计算机上操作系统所具有的3种形式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个系统兼有批处理、分时处理和实时处理三者或其中两者的功能，从而形成通用操作系统。如分时和批处理相结合，将分时任务作为前台任务，将批处理作业作为后台任务，便是分时批处理系统。</p>
</blockquote>
</blockquote>
<h4 id="◆-1-4-1-操作系统的功能" tabindex="-1"><a class="header-anchor" href="#◆-1-4-1-操作系统的功能" aria-hidden="true">#</a> ◆ 1.4.1 操作系统的功能</h4>
<blockquote>
<blockquote>
<p>在多道程序环境下，系统通常无法同时满足所有程序的资源要求。为使多道程序能有条不紊地运行，操作系统应具有如下五方面的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.处理机管理的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机管理的主要任务是对处理机进行分配，并对其运行进行有效的控制和管理。在多道程序环境下，处理机的分配和运行都是以进程为基本单位，因而对处理机的管理可归结为对进程的管理，它包括以下几个方面：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程控制。在多道程序环境下，要使程序运行，必须先为它创建一个或几个进程，并为之分配必要的资源。进程运行结束时，要立即撤销该进程，以便及时回收该进程所占用的各类资源。进程控制的主要任务便是为程序创建进程，撤销已结束的进程，以及控制进程在运行过程中的状态转换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程同步。进程是以异步方式运行的，并以人们不可预知的速度向前推进。为使多个进程能有条不紊地运行，系统中必须设置进程同步机制。进程同步的主要任务是对诸进程的运行进行协调。协调方式有两种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①进程互斥方式。指诸进程在对临界资源进行访问时，应采用互斥方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②进程同步方式。指在相互合作完成共同任务的进程间，由同步机制对它们的执行次序加以协调。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了实现进程互斥与同步，系统中必须设置进程同步机制。最简单的用于实现进程互斥的机制是为每一种临界资源配置一把锁。当锁打开时，进程可以对临界资源进行访问；而当锁关上时，则禁止进程访问该临界资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）进程通信。在多道程序环境下，可由系统为一个应用程序建立多个进程。这些进程相互合作去完成一项共同任务，而在这些相互合作的进程之间往往需要交换信息。例如，有3个相互合作的进程，它们分别是输入进程、计算进程和打印进程。输入进程负责将所输入的数据传送给计算进程；计算进程利用输入数据进行计算，并把计算结果传送给打印进程，由打印进程把结果打印出来。进程通信的任务就是实现相互合作进程之间的信息交换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当相互合作的进程处于同一计算机系统时，通常是采用直接通信方式，即由源进程利用发送命令直接将消息挂到目标进程的消息队列上，之后由目标进程利用接收命令从其消息队列中取出消息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当相互合作的进程处于不同的系统中时，常采用间接通信方式，即由源进程利用发送命令将消息送入一个存放消息的中间实体中，之后由目标进程利用接收命令从中间实体中取走消息。该中间实体通常称为邮箱，相应的通信系统称为电子邮件系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）调度。等待在后备队列中的每个作业，通常要经过调度（包括作业调度和进程调度两步）才能执行。作业调度的基本任务是从后备队列中按照一定的算法，选择若干个作业，为它们分配必要的资源（首先是分配内存）。在将它们调入内存后，便为它们建立进程，使之成为可能获得处理机的就绪进程；并将它们按一定算法插入就绪队列。而进程调度的任务则是从进程的就绪队列中，按照一定的算法选出一进程，把处理机分配给它，并为它设置运行现场，使其投入运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在进行作业调度和进程调度时，都必须遵循某种调度算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.存储器管理的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储器管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率，以及能从逻辑上来扩充内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储器管理应具有以下功能：内存分配、内存保护、地址映射和内存扩充等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）内存分配。内存分配的主要任务是为每个程序分配内存空间，使它们“各得其所”，提高存储器的利用率，以减少不可用的内存空间，允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统在实现内存分配时，可采取以下两种方式：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①静态分配方式。每个程序的内存空间是在程序装入时确定的；在程序装入后的整个运行期间，不允许再申请新的内存空间，也不允许程序在内存中“移动”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②动态分配方式。每个程序所要求的基本内存空间也是在装入时确定的；但允许程序在运行过程中继续申请新的附加空间，以适应程序和数据的动态增长，也允许程序在内存中“移动”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了实现内存分配，在内存分配的机制中应具有以下结构和功能：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①内存分配数据结构。该结构用于记录内存空间的使用情况，作为内存分配的依据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②内存分配功能。系统按照一定的内存分配算法为用户程序分配内存空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③内存回收功能。系统对于用户不再需要的内存，通过用户的释放请求，去完成系统的回收功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）内存保护。内存保护的主要任务是确保每道用户程序都在自己的内存空间中运行，互不干扰。进一步说，绝不允许用户程序访问操作系统的程序和数据；也不允许转移到非共享的其他用户程序中去执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了确保每道程序只在自己的内存区内运行，必须设置内存保护机制。一种比较简单的内存保护机制是设置两个界限寄存器，分别用于存放正在执行的程序的上界和下界。系统需对每条指令所访问的地址进行越界检查，如果发生越界，便发出越界中断请求，以停止该程序的执行。如果这种检查完全用软件实现，则每执行一条指令，便需要增加若干条指令去进行越界检查，这将显著地降低程序的执行速度。因此，越界检查都由硬件实现。当然，对发生越界后的处理，还须与软件配合来完成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）地址映射。一个应用程序（源程序）经编译后，通常会形成若干个目标程序；这些目标程序再经过链接而形成可装入程序。这些程序的地址都是从“0”开始的，程序中的其他地址都是相对于起始地址计算的；由这些地址所形成的地址范围称为“地址空间”，其中的地址称为“逻辑地址”或“相对地址”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由内存中的一系列单元所限定的地址范围称为“内存空间”，其中的地址称为“物理地址”或“绝对地址”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在多道程序环境下，地址空间中的逻辑地址和内存空间中的物理地址是不可能一致的。因此，存储器管理必须提供地址映射功能，将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）内存扩充。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储器管理中的内存扩充任务并非是去增加物理内存的容量，而是借助于虚拟存储技术从逻辑上去扩充内存容量，使用户所感觉到的内存比物理内存大得多；或者是让更多的用户程序能并发运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了从逻辑上扩充内存，系统必须具有内存扩充机制，用于实现下述各功能：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①请求调入功能。允许在仅装入一部分用户程序和数据的情况下，启动该程序运行。在运行过程中，当发现继续运行时所需的程序和数据尚未装入内存时，可向操作系统发出请求，由操作系统将所需部分调入内存，以便继续运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②置换功能。若内存中已无足够的空间来装入需要调入的部分，系统应能将内存中的一部分暂时不用的程序和数据调出至磁盘上，以便腾出内存空间，然后再将所需部分调入内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.文件管理的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.设备管理的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>设备管理的主要任务是：完成用户提出的I/O请求，为用户分配I/O设备；提高处理机和I/O设备的利用率；提高I/O速度；方便用户使用I/O设备。为实现上述任务，设备管理应具有缓冲管理、设备分配回收、设备驱动程序以及设备独立性和虚拟设备等功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.用户接口</p>
</blockquote>
</blockquote>
<h4 id="◆-1-4-2-操作系统的特征" tabindex="-1"><a class="header-anchor" href="#◆-1-4-2-操作系统的特征" aria-hidden="true">#</a> ◆ 1.4.2 操作系统的特征</h4>
<blockquote>
<blockquote>
<p>操作系统的特征</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具有以下4个基本的共同特征。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.并发</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>并行性和并发性是既相似又有区别的两个概念。并行性是指两个或多个事件在同一时刻发生；而并发性是指两个或多个事件在同一时间间隔内发生。在多道程序环境下，并发性是指宏观上在一段时间内有多道程序在同时运行。但在单处理机系统中，每一时刻仅能执行一道程序，故微观上这些程序是在交替执行的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通常的程序是静态实体，它们是不能并发执行的。为使程序能并发执行，系统必须分别为每个程序建立进程。进程，又称任务，简单说来，是在系统中能独立运行并作为资源分配的基本单位，它是一个活动实体。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.共享</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>共享是指系统中的资源可供内存中多个并发执行的进程共同使用。由于资源的属性不同，故多个进程对资源的共享方式也不同，可分为以下两种资源共享方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）互斥共享方式。系统中的某些资源，如打印机、磁带机，虽然它们可以提供给多个进程使用，但在一段时间内却只允许一个进程访问该资源。当一个进程正在访问该资源时，其他欲访问该资源的进程必须等待，仅当该进程访问完并释放该资源后，才允许另一进程对该资源进行访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）同时访问方式。系统中还有另一类资源，允许在一段时间内有多个进程同时对它进行访问。典型的可供多个进程同时访问的资源是磁盘。一些用重入码编写的文件，也可同时共享。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>并发和共享是操作系统的两个最基本的特征，它们又互为存在条件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>资源共享是以程序（进程）的并发执行为条件的，若系统不允许程序并发执行，自然不存在资源共享问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>若系统不能对资源共享实施有效管理，也必将影响程序的并发执行，甚至根本无法并发执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.虚拟</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统中的所谓“虚拟”是指通过某种技术把一个物理实体变成若干个逻辑上的对应物。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例如，在多道分时系统中，虽然只有一个处理机，但每个终端用户却都以为是有一个处理机在专门为他服务，即利用多道程序技术可以把一台物理设备上的处理机虚拟为多台逻辑上的处理机，也称为虚处理机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统中虚拟的实现主要是通过分时使用的办法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果n是某一物理设备所对应的虚拟的逻辑设备数，则虚拟设备的速度必然是物理设备速度的1/n。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.异步性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在多道程序环境下，允许多个进程并发执行。但由于资源等因素的限制，进程的执行通常并非“一气呵成”，而是以“走走停停”的方式运行。内存中的每个进程在何时执行，何时暂停，以怎样的速度向前推进，每道程序总共需要多少时间才能完成，都是不可预知的。很可能是先进入内存的程序后完成，而后进入内存的程序先完成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程是以异步方式运行的。</p>
</blockquote>
</blockquote>
<h4 id="◆-1-5-2-现代的操作系统结构" tabindex="-1"><a class="header-anchor" href="#◆-1-5-2-现代的操作系统结构" aria-hidden="true">#</a> ◆ 1.5.2 现代的操作系统结构</h4>
<blockquote>
<blockquote>
<p>[插图]图1-7　微内核结构的操作系统</p>
</blockquote>
</blockquote>
<h3 id="◆-习题" tabindex="-1"><a class="header-anchor" href="#◆-习题" aria-hidden="true">#</a> ◆ 习题</h3>
<blockquote>
<blockquote>
<p>习题1.什么是硬件系统？什么是软件系统？它们之间有什么联系？2.什么是操作系统？操作系统追求的主要目标是什么？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.在用户程序与计算机硬件之间，操作系统可以分为哪几个模块？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.操作系统如何实现计算机操作的自动化？如何看待操作系统在计算机系统中的地位？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.操作系统分成哪几类？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.从资源管理观点看，操作系统具有哪些功能？7.讨论操作系统可以从哪些观点出发？8.简述操作系统发展的几个阶段。9.什么是批处理系统？它可分为哪两种？10.什么是多道程序系统？其主要特点是什么？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>11.什么是分时系统？其主要特点是什么？12.什么是实时系统？主要有哪几大类？13.实时系统与分时系统的主要差别有哪些？14.简述操作系统的特征。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统的运行环境主要包括系统的硬件环境和由其他的系统软件形成的软件环境。</p>
</blockquote>
</blockquote>
<h3 id="◆-2-1-中央处理机" tabindex="-1"><a class="header-anchor" href="#◆-2-1-中央处理机" aria-hidden="true">#</a> ◆ 2.1 中央处理机</h3>
<blockquote>
<blockquote>
<p>操作系统作为一个程序要在处理机上执行。如果—个计算机系统只有一个处理机，则称为单机系统；如果有多个处理机，则称为多处理机系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每个中央处理机（又称微处理机，简称处理机）都有自己的指令系统。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-1-1-处理机的构成与基本工作方式" tabindex="-1"><a class="header-anchor" href="#◆-2-1-1-处理机的构成与基本工作方式" aria-hidden="true">#</a> ◆ 2.1.1 处理机的构成与基本工作方式</h4>
<blockquote>
<blockquote>
<p>处理机的构成与基本工作方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般的处理机由运算器、控制器、一系列的寄存器以及高速缓存构成。运算器实现任何指令中的算术和逻辑运算，是计算机计算的核心；控制器负责控制程序运行的流程，包括取指令、维护处理机状态、处理机与内存的交互等；寄存器是指令在处理机内部作处理的过程中暂存数据、地址以及指令信息的存储设备，在计算机的存储系统中具有最快的访问速度；高速缓存处于处理机和物理内存之间，一般由控制器中的内存管理单元（Memory Management Unit，MMU）管理，它的访问速度高于内存、低于寄存器，它利用程序局部性原理使得高速指令处理和低速内存访问得以匹配，从而大大地提高处理机的效率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.处理机中的寄存器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>寄存器为处理机本身提供了一定的存储能力，它们的速度比内存储器快得多，但是因为造价很高，存储容量一般都很小。处理机一般包括两类寄存器：一类称为用户可见寄存器，对于高级语言来说，编译器可通过一定的算法分配并使用这些寄存器，以最大限度地减少程序运行时访问内存储器的次数，这对程序的运行速度影响很大；第二类称为控制和状态寄存器，它们用于控制处理机的操作，一般由具有特权的操作系统代码使用，以控制其他程序的执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户可见寄存器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>它一般包括数据寄存器、地址寄存器以及条件码寄存器。数据寄存器有时又称通用寄存器，主要用于各种算术逻辑指令和访存指令。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>浮点处理过程的数据寄存器和整数处理时的数据寄存器一般是分离的。地址寄存器用于存储数据及指令的物理地址、线性地址或者有效地址，以及某种特定方式的寻址。例如，变址寄存器、段指针、栈指针等。条件码寄存器保存处理机操作结果的各种标记位，例如算术运算产生的溢出、符号等，这些标记在条件分支指令中被测试，以控制程序指令的流向。一般来讲，条件码可以被隐式访问，但不能通过显式的方式修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最常见的控制和状态寄存器包括程序计数器（ProgramCounter，PC），它记录了将要取出的指令的地址；指令寄存器（InstructionRegister，IR），它包含了最近取出的指令；程序状态字（Program StatusWord，PSW），它记录了处理机的运行模式信息等，有的处理机中还包含条件码。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.指令执行的基本过程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理指令最简单的方式包括两个步骤：处理机先从存储器中每次读取一条指令，然后执行这条指令，一个这样的单条指令处理过程称为一个指令周期。程序的执行就是由不断取指令和执行指令的指令周期组成的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每个指令周期开始的时候，处理机依据在程序计数器中保存的指令地址从存储器中取一条指令，并在取指令完成后根据指令类别自动将程序计数器的值变成下一条指令的地址，通常是自增1。取到的指令被放在处理机的指令寄存器中，指令中包含了处理机将要采取的动作的位，处理机于是解释并执行所要求的动作。这些指令大致可以分成5类：访问存储器指令，它们负责处理机和存储器之间的数据传送；I/O指令，它们负责处理机和I/O模块之间的数据传送和命令发送；算术逻辑指令，又称数据处理指令，用以执行有关数据的算术和逻辑操作；控制转移指令，这种指令可以指定一个新指令的执行起点；处理机控制指令，这种指令用于修改处理机状态，改变处理机的工作方式等。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-1-2-处理机的状态" tabindex="-1"><a class="header-anchor" href="#◆-2-1-2-处理机的状态" aria-hidden="true">#</a> ◆ 2.1.2 处理机的状态</h4>
<blockquote>
<blockquote>
<p>处理机的状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.特权指令和非特权指令</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>特权指令，是指在指令系统中那些只能由操作系统使用的指令。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果允许用户随便使用这些指令（例如，启动某设备指令、设置时钟指令、控制中断屏蔽的某些指令、清内存指令和建立存储保护指令等），就有可能使系统陷入混乱，所以一个使用多道程序设计技术的微型计算机的指令系统必须要区分特权指令和非特权指令。用户只能使用非特权指令，只有操作系统才能使用所有的指令（包括特权指令和非特权指令）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一台微型计算机的指令系统中，如果不能区分特权指令和非特权指令，那么在这样的硬件环境下要设计出—个具有多道程序运行的操作系统是相当困难的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.处理机的状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机有时执行用户程序，有时执行操作系统的程序。在执行不同程序时，根据运行程序对资源和机器指令的使用权限而将此时的处理机设置为不同状态。多数系统将处理机工作状态划分为管态和目态。前者一般指操作系统管理程序运行时的状态，具有较高的特权级别，又称特权态（特态）、系统态；后者一般指用户程序运行时的状态，具有较低的特权级别，又称普通态（普态）、用户态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>还有些系统将处理机工作状态划分为多个系统状态，例如核心状态、管理状态和用户程序状态（又称目标状态）3种</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作为一个实例，Intel公司出品的x86系列处理机（包括386、486、Pentium、Pentium Pro、Pentium Ⅱ、Pentium Ⅲ、Pentium4），都支持4个处理机特权级别（特权环：R0，R1，R2和R3）。从R0到R3特权能力依次降低，R0相当于双状态系统的管态，R3相当于目态，而Rl和R2则介于两者之间，它们能够运行的指令集合具备包含关系：IR0⊇IR1⊇IR2⊇IR3，处理机在各个级别下的保护性检查（例如地址校验、I/O限制）以及特权级别之间的转换方式也不尽相同。这4个级别被设计成运行不同类别的程序：R0运行操作系统核心代码；R1运行关键设备驱动程序和I/O处理例程；R2运行其他受保护的共享代码，例如语言系统运行环境，R3运行各种用户程序。基于x86处理机的操作系统包括多数的UNIX系统、Linux以及Windows系列，大都只用到了R0和R3两个特权级别。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当处理机处于管态时，全部指令（包括特权指令）可以执行，可使用所有资源，并具有改变处理机状态的能力。当处理机处于目态时，就只有非特权指令能执行。不同处理机状态之间的区别在于赋予运行程序的特权级别不同，可以运行的指令集合也不相同，一般说来，特权级别越高，可以运行的指令集合越大，而且高特权级别对应的可运行指令集合包含低特权级的可运行指令集。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.程序状态字</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了解决处理机当前工作状态的问题，所有的处理机都有一些特殊寄存器，用以表明处理机当前的工作状态。比如用一个专门的寄存器来指示处理机状态，称为程序状态字（PSW）；用程序计数器（PC）这个专门的寄存器来指示下一条要执行的指令。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机的状态字通常包括以下状态代码：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）处理机的工作状态代码。指明是管态还是目态，用来说明当前在处理机上执行的是操作系统还是一般用户，从而决定其是否可以使用特权指令或拥有其他的特殊权力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）条件码。反映指令执行后的结果特征。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）中断屏蔽码。指出是否允许中断。</p>
</blockquote>
</blockquote>
<h3 id="◆-2-2-存储系统" tabindex="-1"><a class="header-anchor" href="#◆-2-2-存储系统" aria-hidden="true">#</a> ◆ 2.2 存储系统</h3>
<blockquote>
<blockquote>
<p>程序和数据存放在内存储器（又称内部存储器、内存）中才能运行。在多道程序系统中，有若干个程序和相关的数据要放入内存储器。操作系统不但要管理、保护这些程序和数据，使它们不至于受到破坏，而且操作系统本身也要存放在内存储器中并运行。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-2-1-存储器的类型" tabindex="-1"><a class="header-anchor" href="#◆-2-2-1-存储器的类型" aria-hidden="true">#</a> ◆ 2.2.1 存储器的类型</h4>
<blockquote>
<blockquote>
<p>存储器的类型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一种是读写型存储器，另一种是只读型存储器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>读写型存储器是指可以把数据存入其中任一地址单元，并且可在以后的任何时候把数据读出来，或者重新存入别的数据的一种存储器。这种类型的存储器常被称为随机访问存储器（Random Access Memory，RAM）。RAM主要用于存放随机存取的程序和数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>只读型存储器是指只能从其中读取数据，但不能随意地用普通的方法向其中写入数据（向其中写入数据只能用特殊方法进行）的一种存储器。这种类型的存储器常被称为只读存储器（Read-Only Memory，ROM）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在微型计算机中，通常把一些常驻内存的模块以微程序形式固化在ROM中，例如早期IBM PC的基本I/O系统程序BIOS和BASIC解释程序就被固化于ROM中。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-2-2-存储器的层次结构" tabindex="-1"><a class="header-anchor" href="#◆-2-2-2-存储器的层次结构" aria-hidden="true">#</a> ◆ 2.2.2 存储器的层次结构</h4>
<blockquote>
<blockquote>
<p>计算机存储系统的设计主要考虑3个问题：容量、速度和成本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3个目标不可能同时达到最优，要作权衡。存取速度越快，每比特价格越高；容量越大，每比特价格越低，同时存取速度也越慢。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图2-2　计算机系统中的存储体系结构</p>
</blockquote>
</blockquote>
<h4 id="◆-2-2-3-存储分块和存储保护" tabindex="-1"><a class="header-anchor" href="#◆-2-2-3-存储分块和存储保护" aria-hidden="true">#</a> ◆ 2.2.3 存储分块和存储保护</h4>
<blockquote>
<blockquote>
<p>1.存储分块</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储的最小单位称为“二进制位”，它包含的信息为0或1。存储器的最小编址单位是字节，1个字节包含8个二进制位。而两个字节称为1个字，4个字节称为1个双字。1024个字节称为1KB，1024KB称为1MB，1024MB称为1GB，1024GB称为1TB</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了简化对存储器的分配和管理，在不少计算机系统中把存储器分成块。在为用户分配内存空间时，以块为最小单位，这样的块有时被称为一个物理页。而块的大小随计算机而异，512B、1KB、4KB、8KB的都有，也有其他大小的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.存储保护</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存放在内存中的用户程序和操作系统以及它们的数据，很可能受到正在处理机上运行的某用户程序的有意或无意地破坏，这会造成十分严重的后果。例如，该用户程序向操作系统区写入了数据，就有可能造成系统崩溃。所以，必须对内存中的信息加以严格的保护，使操作系统及其他程序不被破坏，这是其正确运行的基本条件之一。下面介绍几种最常用的存储保护机制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）界地址寄存器（界限寄存器）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其方法是在处理机中设置一对界限寄存器来存放该用户程序在内存中的下限和上限地址，分别称为下限寄存器和上限寄存器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每当处理机要访问内存时，硬件自动将被访问的内存地址与界限寄存器的内容进行比较，以判断是否越界。如果未越界，则按此地址访问内存，否则将产生程序中断——越界中断（或称存储保护中断）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）存储键。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了存储保护的目的，每个存储块都有一个与其相关的由二进位组成的存储保护键附加在每个存储块上。当一个用户程序被允许进入内存时，操作系统分给它一个唯一的不与其他程序相同的存储键号。并将分配给该程序的各存储块的存储键也设置成同样的键号。当操作系统挑选该程序上处理机运行时，操作系统同时将它的存储键号放入程序状态字（PSW）的存储键（“钥匙”）域中。每当处理机访问内存时，都将该内存块的存储键与PSW中的“钥匙”进行比较。如果相匹配，则允许访问；否则，拒绝并报警。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-3-1-缓冲技术" tabindex="-1"><a class="header-anchor" href="#◆-2-3-1-缓冲技术" aria-hidden="true">#</a> ◆ 2.3.1 缓冲技术</h4>
<blockquote>
<blockquote>
<p>缓冲区是硬件设备之间进行数据传输时，专门用来暂存这些数据的一个存储区域。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓冲技术一般有3种用途。一种是用在处理机与内存之间的；另一种是用在处理机和其他外围设备之间的；还有一种是用在设备与设备之间的通信上的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>都是为了解决部件之间速度不匹配的问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当从某输入设备输入数据时，通常是先把数据送入缓冲区中，然后处理机再把数据从缓冲区读入用户工作区中进行处理和计算。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为什么不直接把数据送入用户工作区，而要设置缓冲来暂存呢？最根本的原因是处理机处理数据速度与设备传输数据速度不相匹配，用缓冲区可缓解其间的速度矛盾。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了提高设备利用率，通常使用单个缓冲区是不够的。因为在单缓冲区情况下，设备向缓冲区输入数据直到装满后，必须等待处理机将其取完，才能继续向其中输入数据。如果有两个缓冲区时，设备利用率就可大为提高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前许多计算机系统广泛使用多缓冲区（Cache）技术。Cache离处理机最近，能使处理机更快速地访问经常使用的数据。在运行过程中，处理机首先到一级Cache中去找数据（可能是数据，也可能是一段指令序列）。如果没有找到，那么处理机接着到二级Cache中去找，如果还找不到，处理机就只好到速度较慢的系统内存中去找（如果有三级Cache，处理机还会在Cache中找下去）。从以上的分析可以看出，一级Cache是处理机首先访问的，因此一级Cache的性能对系统的性能提升作用很大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>内存储器一般由2n个可寻址的字组成，每个字有一个唯一的n位地址。为了使Cache中的存储单元和内存中的存储单元可以对应，一般将内存视作一些固定大小的块，每块含K个字，即将内存划分为M=2n/K个块。Cache中有C个存储槽，每个槽也是K个字，当然C远小于M。内存中的一些块的集合常驻留在Cache的相应槽中，如果读到了某一块中的一个字，而它又不在Cache的槽中，那个块将整个被移到一个槽中。替换哪一个槽中的内容将由处理机的Cache管理单元按照一定的策略来选择，并且相应的Cache槽中会有一个专门的标记，以表明它对应的是内存的什么地址的块。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-3-2-中断技术" tabindex="-1"><a class="header-anchor" href="#◆-2-3-2-中断技术" aria-hidden="true">#</a> ◆ 2.3.2 中断技术</h4>
<blockquote>
<blockquote>
<p>中断对于操作系统的重要性就像机器中的齿轮一样，所以也有人称操作系统由“中断”驱动或者“中断事件”驱动。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓中断，是指处理机对系统中或系统外发生的异步事件的响应。异步事件是指无一定时序关系的随机发生的事件，如外围设备完成数据传输，实时控制设备出现异常情况等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当这些异步事件发生后，打断了处理机对当前程序的执行，而转去处理该异步事件（执行该事件的中断处理程序）。直到处理完成之后，再转回原程序的中断点继续执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>中断的出现解决了主机和外围设备并行工作的问题，消除了因外围设备的慢速而使得主机等待的现象，提高了可靠性，为多机操作和实时处理提供了硬件基础。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>典型的中断包括以下4种：①程序中断。在某些条件下由指令执行结果产生，例如算术溢出、被零除、试图执行非法指令以及访问不被允许访问的存储位置等。②时钟中断。由处理机内部的计时器产生，允许操作系统以一定规律执行函数。③I/O中断。由I/O控制器产生，用于通知一个I/O操作的正常完成或者发生的错误。④硬件失效中断。由掉电、存储器校验错等硬件故障引起。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>中断依据中断事件发生和处理是否是异步的可以分为异步中断和同步中断。在很多系统中，异步中断简称中断（Interrupt），而同步中断一般称为异常（Exception）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有的系统还依据中断源的类型将中断分成硬件中断和软件中断。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>中断系统是现代计算机系统的核心机制之一，它不是单纯的硬件或者软件的概念，而是硬件和软件相互配合、相互渗透而使得计算机系统得以充分发挥能力的计算模式。中断系统包括两大组成部分：中断系统的硬件中断装置和软件中断处理程序。中断装置负责捕获中断源发出的中断请求，并以一定的方式响应中断源，然后将处理机的控制权移交给特定的中断处理程序。中断处理程序则负责辨别中断类型，并根据请求做出相应的操作。中断装置提供了中断系统的基本框架，是中断系统的机制部分；中断处理程序是利用中断机制对处理能力的扩展和对多种处理需求的适应，属于中断系统的策略部分。</p>
</blockquote>
</blockquote>
<h4 id="◆-2-3-3-时钟" tabindex="-1"><a class="header-anchor" href="#◆-2-3-3-时钟" aria-hidden="true">#</a> ◆ 2.3.3 时钟</h4>
<blockquote>
<blockquote>
<p>在计算机系统中，设置时钟是十分必要的。这是由于时钟可以为计算机完成以下的必不可少的工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）在多道程序运行的环境中，它可以为系统发现一个陷入死循环（编程错误）的程序，从而防止机时的浪费。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）在分时系统中，用间隔时钟来实现程序间按时间片轮转。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）在实时系统中，按要求的时间间隔输出正确的时间信号给一个实时的控制设备（例如A/D、D/A转换设备）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）定时唤醒那些要求延迟执行的各个外部事件（例如定时为各进程计算优先数，银行系统中定时运行某类结账程序等）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）记录用户使用各种设备的时间和记录某外部事件发生的时间间隔。（6）记录用户和系统所需要的绝对时间，即年、月、日。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不管是什么时钟，实际上都是硬件的时钟寄存器按时钟电路所产生的脉冲数进行加1或减1的操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>绝对时钟记录当前的时间（年、月、日、时、分、秒）。一般来说，绝对时钟非常准确。当计算机停机时，绝对时钟值仍然自动修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>间隔时钟又称相对时钟，也是通过时钟寄存器来实现的，同样由操作人员设置时间间隔的初值，以后每经过—个单位的时间，时钟的值减1。直到该值为负时，则触发一个时钟中断，并进行相应的处理。</p>
</blockquote>
</blockquote>
<h3 id="◆-习题-1" tabindex="-1"><a class="header-anchor" href="#◆-习题-1" aria-hidden="true">#</a> ◆ 习题</h3>
<blockquote>
<blockquote>
<p>习题1.简述处理机的组成和工作原理。你认为哪些部分和操作系统密切相关，为什么？2.为了支持操作系统，现代处理机一般都提供哪两种工作状态，以隔离操作系统和普通程序？两种状态各有什么特点？3.什么是分级的存储体系结构？它主要解决了什么问题？4.内存通常有哪两种类型？它们各自的特点是什么？用在哪里？5.缓冲技术在计算机系统中起着什么样的作用？它是如何工作的？6.简述中断和操作系统的关系。操作系统是如何利用中断机制的？7.时钟对操作系统有什么重要作用？</p>
</blockquote>
</blockquote>
<h2 id="◆-第二部分-进程" tabindex="-1"><a class="header-anchor" href="#◆-第二部分-进程" aria-hidden="true">#</a> ◆ 第二部分 进程</h2>
<blockquote>
<blockquote>
<p>在多道程序批处理系统和分时系统中，程序不能独立运行。资源分配和独立运行的基本单位是进程。操作系统所具有的四大特征都是基于进程而形成的</p>
</blockquote>
</blockquote>
<h2 id="◆-第3章-进程与进程管理" tabindex="-1"><a class="header-anchor" href="#◆-第3章-进程与进程管理" aria-hidden="true">#</a> ◆ 第3章 进程与进程管理</h2>
<blockquote>
<blockquote>
<p>操作系统中最核心的概念是进程。在多道程序批处理系统和分时系统中，程序不能独立运行。资源分配和独立运行的基本单位是进程。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-进程的引入" tabindex="-1"><a class="header-anchor" href="#◆-3-1-进程的引入" aria-hidden="true">#</a> ◆ 3.1 进程的引入</h3>
<blockquote>
<blockquote>
<p>进程是对正在运行的程序的一个抽象</p>
</blockquote>
</blockquote>
<h4 id="◆-3-1-2-程序顺序执行" tabindex="-1"><a class="header-anchor" href="#◆-3-1-2-程序顺序执行" aria-hidden="true">#</a> ◆ 3.1.2 程序顺序执行</h4>
<blockquote>
<blockquote>
<p>一切程序顺序执行时都具有以下特征：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）程序执行的顺序性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）程序执行的封闭性。程序是在封闭的环境下运行的，即程序在运行时，它独占全机资源，因而机内各资源的状态（除初始状态外）只有本程序才能改变。程序一旦开始运行，其执行结果不受外界因素的影响。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）程序执行结果的确定性。程序执行的结果与它的执行速度无关，程序无论是从头到尾不停地执行，还是“停停走走”地执行，都不会影响得到最终结果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）程序结果的可再现性。只要程序执行时的环境和初始条件相同，当程序多次重复执行时，都将获得相同的结果。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-1-3-程序并发执行" tabindex="-1"><a class="header-anchor" href="#◆-3-1-3-程序并发执行" aria-hidden="true">#</a> ◆ 3.1.3 程序并发执行</h4>
<blockquote>
<blockquote>
<p>程序执行结果的不可再现性。程序在并发执行时，由于失去了封闭性，也将导致失去其可再现性。例如，有两个循环程序A和B，它们共享一个变量n。程序A每执行一次时，都要做n++操作；程序B则每执行一次时，都要执行cout&lt;&lt;n操作（此处以C++语言为例），然后再将n置成“0”，程序A和B以不同的速度运行。这样，可能出现下述3种情况（假定某时刻变量n的值为c）。①n++在cout&lt;&lt;n和n=0之前，此时得到的n值分别为c+1，c+1，0。②n++在cout&lt;&lt;n和n=0之后，此时得到的n值分别为c，0，1。③n++在cout&lt;&lt;n和n=0之间，此时得到的n值分别为c，c+1，0。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上述情况说明：程序在并发执行时，由于失去了封闭性，其计算结果与并发程序的执行速度有关，从而使程序失去了可再现性。亦即，程序经过多次执行后，虽然其执行时的环境和初始条件都相同，但得到的结果却不相同。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>引入并发的目的是提高资源利用率，从而提高系统效率。程序并发执行，虽然能有效地提高资源利用率和系统的吞吐量，但必须采取某种措施以使并发程序能保持其“可再现性”。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-1-4-多道程序设计" tabindex="-1"><a class="header-anchor" href="#◆-3-1-4-多道程序设计" aria-hidden="true">#</a> ◆ 3.1.4 多道程序设计</h4>
<blockquote>
<blockquote>
<p>在采用多道程序设计的计算机系统中，允许多个程序同时进入一个计算机系统的内存并运行，这种让多个程序同时进入计算机计算的方法称为多道程序设计。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-进程" tabindex="-1"><a class="header-anchor" href="#◆-3-2-进程" aria-hidden="true">#</a> ◆ 3.2 进程</h3>
<blockquote>
<blockquote>
<p>在多道程序工作环境下，程序的并发执行产生了一些新的特征，使得一些程序不能并发执行。例如，程序在执行中一旦受阻而停下来时，系统无法保留该程序的现场，因而也就无法再恢复该程序的现场以继续执行。为了使程序在多道程序环境下能够并发执行，并对并发执行的程序加以控制和描述，引入了进程的概念。操作系统专门为之设置一个称为“进程控制块”的数据结构，其中存放了进程标识符、进程运行的当前状态、程序和数据的地址以及保存该程序运行时处理机的环境信息。程序段、数据段及进程控制块3部分构成了一个进程的实体。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-2-1-进程的概念" tabindex="-1"><a class="header-anchor" href="#◆-3-2-1-进程的概念" aria-hidden="true">#</a> ◆ 3.2.1 进程的概念</h4>
<blockquote>
<blockquote>
<p>下面是几个操作系统的权威人士对进程所下的定义。（1）行为的一个规则称为程序，程序在处理机上执行时所发生的活动称为进程（Dijkstra）。（2）进程是可以和别的计算并发执行的计算（Madnick and Donowan）。（3）进程是一个程序及其数据在处理机上顺序执行时所发生的活动（A.C.Shaw）。（4）进程是程序在一个数据集合上的运行过程，是系统进行资源分配和调度的一个独立单位（PeterDenning）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程是具有独立功能的可并发执行的程序在一个数据集合上的运行过程，是系统进行资源分配和调度的独立单位”，或者说，“进程”是进程实体的运行过程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程与程序之间的关系</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程是程序的一次执行，它是一个动态的概念，程序是完成某个特定功能的指令的有序序列，它是一个静态的概念。进程是把程序作为它的运行实体，没有程序，也就没有进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程和程序的区别还在于一个进程可以执行一个或几个程序。例如，一个执行C编译程序的进程先后执行了预处理、词法分析、语法分析、目标代码生成和优化等几个程序。反之，同一程序也可能由多个进程同时执行。例如，在分时系统中，几个用户同时使用内存中的同一C语言编译程序分别编译各自不同的C语言源程序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程是系统进行资源分配和调度的一个独立单位；程序则不是。以多用户进程共享一个编译程序为例，为多个用户执行编译时，资源分配显然是以进程为单位，而不是以程序为单位。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）程序可以作为一种软件资源长期保存，而进程是程序的一次执行过程。进程是临时的、有生命期的，表现在它由创建而产生，完成任务后被撤销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）进程是具有结构的。为了描述进程的运行变化过程，应为每个进程建立一个结构——进程控制块。从结构上看，进程由程序、数据和进程控制块3部分组成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的特征</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）动态性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程有一定的生命期。而程序只是一组有序指令的集合，并存放在某种介质上，本身并无运动的含义。因此，程序是个静态体。但是，进程离开了程序也就失去了存在的意义，进程是执行程序的动态过程，而程序是进程运行的静态文本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）并发性。并发性是指多个进程实体同存于内存中，能在一段时间内同时运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>引入进程的目的也正是为了使其程序的执行能和其他程序的执行并发执行，而程序是不能并发执行的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）独立性。独立性是指进程实体是一个能独立运行的基本单位，同时也是系统中独立获得资源和独立调度的基本单位。凡未建立进程的程序都不能作为一个独立的单位参加运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）异步性。异步性是指进程按各自独立的、不可预知的速度向前推进；或者说，进程按异步方式运行。这一特征将导致程序执行的不可再现性。因此，在操作系统中必须采取某种措施来保证各程序之间能协调运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）结构特征。从结构上看，进程实体是由程序段、数据段及进程控制块3部分组成，有人把这3部分统称为“进程映像”。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-2-2-进程的基本状态及其转换" tabindex="-1"><a class="header-anchor" href="#◆-3-2-2-进程的基本状态及其转换" aria-hidden="true">#</a> ◆ 3.2.2 进程的基本状态及其转换</h4>
<blockquote>
<blockquote>
<p>因为系统中的诸进程并发运行，并因竞争系统资源而相互依赖、相互制约，因而进程执行时呈现了“运行—暂停—运行”的间断性。进程执行时的间断性可用进程的状态及其转换来描述。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的3种基本状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程在运行中不断地改变其运行状态。通常，一个进程必须具有以下3种基本状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）就绪状态。当进程已分配到除处理机以外的所有必要的资源后，只要能再获得处理机便可立即执行，这时的状态称为就绪状态。在一个系统中，可以有多个进程同时处于就绪状态，通常把这些进程排成一个或多个队列，称这些队列为就绪队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）执行状态。执行状态指进程已获得处理机，其程序正在执行。在单处理机系统中，只能有一个进程处于执行状态。在多处理机系统中，则可能有多个进程处于执行状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）阻塞状态。进程因发生某种事件（例如I/O请求、申请缓冲空间等）而暂停执行时的状态，亦即进程的执行受到阻塞，故称这种状态为阻塞状态，有时也称“等待”状态或“睡眠”状态。通常将处于阻塞状态的进程排成一个队列，称为阻塞队列。在有的系统中，按阻塞的原因不同而将处于阻塞状态的进程排成多个队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的3种基本状态及其转换如图3-7所示。[插图]图3-7　进程的3种基本状态及其转换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.进程状态的转换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程在运行期间不断地从一个状态转换到另一个状态，进程的各种调度状态依据一定的条件而发生变化，它可以多次处于就绪状态和执行状态，也可多次处于阻塞状态，但可能排在不同的阻塞队列。下面简要地阐述进程状态转换的原因。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）就绪→执行状态。当进程调度为处于就绪状态的进程分配了处理机后，该进程便由就绪状态变为执行状态。正在执行的进程也称当前进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）执行→阻塞状态。正在执行的进程因出现某种事件而无法执行，例如，进程请求访问临界资源，而该资源正被其他进程访问，则请求该资源的进程将由执行状态变为阻塞状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）执行→就绪状态。在分时系统中，正在执行的进程因时间片用完而被暂停执行，该进程便由执行状态变为就绪状态。又如，在抢占调度方式中，一个优先级高的进程到来后可以抢占一个正在执行的优先级低的进程的处理机，该低优先级进程也将由执行状态转换为就绪状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）阻塞→就绪状态。处于阻塞状态的进程，在其等待的事件已经发生，例如I/O请求完成，则进程由阻塞状态变为就绪状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.进程的挂起状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）挂起状态的引入。在不少系统中，进程只有上述3种基本状态，但在另一些系统中，基于某种需要又增加了一些新的进程状态，其中最重要的是挂起状态。引入挂起状态可能基于下述需要：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①终端用户的需要。当终端用户在自己的程序运行期间发现有可疑问题时，往往希望暂时使自己的进程静止下来。也就是说，若进程处于执行状态则暂停执行；若进程处于就绪状态则暂不接受调度，以便研究其执行情况或对程序进行修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②父进程的需要。父进程常常希望考察和修改子进程或者当要协调各子进程间的活动时要挂起自己的子进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③操作系统的需要。操作系统有时需要挂起某些进程，检查运行中资源的使用情况及进行记账，以便改善系统运行的性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④对换的需要。为了缓解内存紧张的情况，即将内存中处于阻塞状态的进程换至外存上，使进程又处于一种有别于阻塞状态的新状态。因为即使该进程所期待的事件发生，处于挂起状态的进程仍不具备执行条件，故而仍不能进入就绪队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>⑤负荷调节的需要。当实时系统中的负荷较重可能影响到对实时任务的控制时，可由系统把一些不重要或不紧迫的进程挂起，以保证系统仍然能正常运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程状态的转换。在引入挂起状态后，又将增加从挂起状态（又称静止状态）到非挂起状态（又称活动状态）的转换，可以有4种情况：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①活动就绪→静止就绪。当进程处于未被挂起的就绪状态时，称此状态为活动就绪状态。当用挂起原语suspend（）将该进程挂起后，该进程便转变为静止就绪状态，处于静止就绪状态的进程不再被调度执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②活动阻塞→静止阻塞。当进程处于未被挂起的阻塞状态时，称它处于活动阻塞状态。当用挂起原语suspend（）将它挂起后，进程便转变为静止阻塞状态。处于该状态的进程在其所期待的事件出现后，它将从静止阻塞变为静止就绪。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③静止就绪→活动就绪。处于静止就绪状态的进程，若用激活原语active（）激活后，该进程将转变为活动就绪状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④静止阻塞→活动阻塞。处于静止阻塞状态的进程，若用激活原语active（）激活后，该进程将转变为活动阻塞状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-8　具有挂起状态的进程转换图</p>
</blockquote>
</blockquote>
<h4 id="◆-3-2-3-进程控制块" tabindex="-1"><a class="header-anchor" href="#◆-3-2-3-进程控制块" aria-hidden="true">#</a> ◆ 3.2.3 进程控制块</h4>
<blockquote>
<blockquote>
<p>进程控制块PCB是进程实体的一部分，是操作系统中最重要的数据结构。PCB记录了操作系统所需的、用于描述进程情况及控制进程运行所需的全部信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.进程控制块的作用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程控制块PCB的作用是使一个在多道程序环境下不能独立运行的程序（含数据）成为一个能独立运行的基本单位，一个能与其他进程并发执行的进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统是根据PCB来对并发执行的进程进行控制和管理的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当操作系统要调度某进程执行时，要从该进程的PCB中查出其现行状态及优先级；在调度到某进程后，要根据其PCB中所保存的处理机状态信息去设置该进程恢复运行的现场，并根据其PCB中的程序和数据的内存地址找到其程序和数据；进程在执行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也都需要访问进程控制块PCB；当进程因某种原因而暂停执行时，又需将其断点的处理机环境保存在PCB中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统是根据进程的PCB而感知到该进程的存在，进程控制块PCB是进程存在的唯一标志。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当系统创建一个新进程时就为它建立了一个进程控制块PCB；进程结束时又回收其PCB，进程也随之消亡。进程控制块PCB可以被操作系统中的多个模块读或修改，如被调度程序、资源分配程序、中断处理程序以及监督和分析程序等读或修改。因为进程控制块PCB经常被系统访问，尤其是被运行频率很高的进程调度及分派程序访问，故PCB应常驻内存。系统将所有的PCB组织成若干个链表（或队列），存放在操作系统中专门开辟的PCB区内。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在进程控制块PCB中，主要包括下述4个方面用于描述和控制进程运行的信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程标识符信息。进程标识符用于唯一地标识一个进程。一个进程通常有以下两种标识符。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①外部标识符。外部标识符由创建者提供，通常由字母、数字所组成，往往是由用户（进程）在访问该进程时使用。外部标识符便于记忆，如计算进程、打印进程、发送进程、接收进程等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②内部标识符。这是为了方便系统使用而设置的。在所有操作系统中都为每一个进程赋予一个唯一的整数作为内部标识符，它通常就是一个进程的序号。为了描述进程的家族关系，还应设置父进程标识符及子进程标识符。此外，还可以设置用户标识符以指示拥有该进程的用户。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）处理机状态信息。处理机状态信息主要是由处理机各种寄存器中的内容所组成。处理机在运行时，许多信息都放在寄存器中。当处理机被中断时，所有这些信息都必须保存在被中断进程的PCB中，以便在该进程重新执行时能从断点顺序执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这组存放处理机状态信息的寄存器包括以下几个：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①通用寄存器。又称用户可视寄存器，可被用户程序访问，用于暂存信息。在大多数处理机中有8～12个通用寄存器，在RISC结构的计算机中，可超过100个。②指令计数器。其中存放要访问的下一条指令的地址。③程序状态字PSW。其中含有状态信息，如条件码、执行方式、中断屏蔽标志等。④用户栈指针。每个用户进程有一个或若干个与之相关的系统栈，用于存放过程和系统的调用参数及调用地址，栈指针指向该栈的栈顶。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）进程调度信息。在进程控制块PCB中还存放了一些与进程调度和进程对换有关的信息，包括以下4种：①进程状态。指明进程的当前状态，可作为进程调度和对换时的依据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②进程优先级。用于描述进程使用处理机的优先级别的一个整数，优先级高的进程应优先获得处理机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③进程调度所需的其他信息。它们与所采用的进程调度算法有关。比如，进程已等待CPU的时间总和、进程已执行的时间总和等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④事件。这是指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）进程控制信息。进程控制信息包括以下4种：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①程序和数据的地址。它是指该进程的程序和数据所在的内存或外存地址，以便再调度到该进程时能从中找到其程序和数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②进程同步和通信机制。它是指实现进程同步和进程通信时所必需的机制，如消息队列指针、信号量等，它们可能全部或部分地放在PCB中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③资源清单。它是一张列出了除处理机外的进程所需的全部资源及已经分配到该进程的资源清单。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④链接指针。它给出了本进程所在队列中的下一个进程的PCB首地址。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在一个系统中，通常可拥有数十个、数百个乃至数千个进程控制块PCB。为能对它们进行有效的管理，应该用适当的方式将它们组织起来。目前常用的组织方式有以下两种：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）链接方式。把具有相同状态的进程控制块PCB链接成一个队列，这样可形成就绪队列、若干个阻塞队列和空队列等。处于就绪状态的进程的PCB可按照某种策略排成多个就绪队列；根据阻塞原因的不同可把处于阻塞状态的进程的PCB排列成等待I/O操作完成队列、等待分配内存队列等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-9　按链接方式组织的PCB</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）索引方式。系统根据所有进程的状态建立几张索引表，例如，就绪索引表、阻塞索引表等，并把各索引表在内存的首地址记录于内存中的一些专用单元中。在每个索引表的表目中，记录具有相应状态的某个进程控制块PCB在PCB表中的地址。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<h4 id="◆-3-2-4-进程控制" tabindex="-1"><a class="header-anchor" href="#◆-3-2-4-进程控制" aria-hidden="true">#</a> ◆ 3.2.4 进程控制</h4>
<blockquote>
<blockquote>
<p>例如I/O指令，是不允许用户程序直接使用的。如果用户直接使用这部分指令必须了解硬件特性、组织启动等具体工作，加大了用户的负担，并且用户直接使用这些指令启动外围设备工作还可能会造成错误。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当处理机处于管态时可以执行包括特权指令在内的一切机器指令，当处理机处于目态时不允许执行特权指令。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>操作系统程序占用处理机时，应让处理机在管态下工作，而用户程序占用处理机时，应让处理机在目态下工作。如果处理机在目态工作，却取到了一条特权指令，此时处理机将拒绝执行该指令，并形成一个“非法操作”事件。中断装置识别到该事件后，转交给操作系统处理，由操作系统通知用户“程序中有非法指令”，必须修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当系统启动时，硬件设置处理机的初始状态为管态，然后装入操作系统程序。如果操作系统选择了用户程序占用处理机，则把管态变成目态。如果中断装置发现了一个事件，则又将其设置为管态，让操作系统去处理出现的事件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程控制的主要任务是创建和撤销进程以及实现进程的状态转换。进程控制一般由操作系统的内核来实现。为了防止操作系统及关键数据如PCB等受到用户程序有意或无意的破坏，通常用户程序运行在用户态，它不能去执行操作系统指令和访问操作系统区域，这样也就防止了用户程序对操作系统的破坏。操作系统内核通常是运行在系统态的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.操作系统内核</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将一些与硬件紧密相关的模块，诸如中断处理程序、各种常用设备的驱动程序以及运行频率较高的模块（例如时钟管理、进程调度以及许多模块公用的一些基本操作），都安排在紧靠硬件的软件层次中并使它们常驻内存，以便提高操作系统的运行效率，并对它们加以特殊的保护。通常把这一部分称为操作系统的内核。内核是计算机硬件的第一层扩充软件，它们为系统对进程进行控制、对存储器进行管理提供了有效的机制。内核所提供的功能随操作系统的不同而异。可归纳为3个方面：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）中断处理。中断处理功能在操作系统中既是内核的最基本功能，也是整个操作系统赖以活动的基础</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>各种类型的系统调用、键盘命令的输入、进程调度、设备驱动及文件操作等无不依赖于中断。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>内核只对中断进行“有限地处理”，然后便转由有关进程继续处理。这不仅可减少中断处理机的时间，也可提高程序执行的并发性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程管理。进程管理的任务有：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①进程的建立和撤销。为一个程序建立一个或多个进程、撤销已结束的进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②进程状态的转换。从进程状态转换图可以看出，系统应能使进程从阻塞变为就绪，把活动进程挂起或把挂起的进程激活。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③进程调度。进行处理机的重新分配。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④控制进程的并发执行。为使诸进程有条不紊地运行，应能保证进程间的同步，实现相互合作进程间的通信。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）资源管理中的基本操作。包括对时钟、I/O设备和文件系统进行控制和管理的基本操作。一般来说，这些操作与硬件的关系比较密切。例如，设备驱动程序、磁盘读写程序、时钟处理程序等，也都属于内核。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>内核在执行上述操作时，往往是通过执行各种原语操作来实现的。它是机器指令的延伸，是由若干条机器指令构成用以完成特定功能的一段程序。为保证操作的正确性，它们应当是原子操作。所谓原子操作是指：一个操作中的所有动作，要么全做，要么全不做。换言之，原子操作是一个不可分割的操作。在单处理机中，操作的“原子”性可以通过屏蔽中断来实现。在内核中可能有许多原语，例如，用于建立进程和撤销进程的原语、改变进程状态的原语、实现进程同步和通信的原语等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.进程的创建</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程图。一个进程能够创建若干个新进程，新创建的进程又可继续创建进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程图是用于描述进程家族关系的有向树。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>子进程可以继承父进程所拥有的资源。例如，继承父进程打开的文件、继承父进程所分配的缓冲区等。当子进程撤销时，应将从父进程那里获得的资源归还给父进程。在撤销父进程时，也必须同时撤销其所有的子进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）引起创建进程的事件。在多道程序环境中，只有进程才能在系统中运行。因此，为使程序能运行就必须为它创建进程。导致一个进程去创建另一进程的典型事件可有以下4类：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①用户登录。在分时系统中，用户在终端输入登录命令后，若是合法用户，系统将为该终端用户建立一进程并把它插入就绪队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②作业调度。在批处理系统中，当作业调度程序按一定的算法调度到某个作业时，便将该作业装入内存，为它分配必要的资源并立即为它创建进程，再插入就绪队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③提供服务。当运行中的用户程序提出某种请求后，系统将专门创建一个进程来提供用户所需要的服务。例如，如果用户程序要求进行文件打印，操作系统将为之创建一个打印进程，不仅可使打印进程与该用户进程并发执行，而且还便于计算为完成打印任务所花费的时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④应用请求。基于应用进程的需要，由应用进程自己创建一个新进程，以便使新进程以并发运行方式完成特定任务。例如，某应用程序需要不断地从键盘终端读入输入数据，继而又要对输入数据进行相应的处理，然后又将处理结果以表格形式在屏幕上显示。该应用进程为使这几个操作能并发执行以加速任务的完成，可以分别建立键盘输入进程、数据处理进程、表格输出进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）进程的创建过程。一旦操作系统发现了要求创建新进程的事件后，便调用进程创建原语create（），按下述步骤创建一新进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①申请空白进程控制块。为新进程分配唯一的数字标识符，并从进程控制块PCB集合中索取一空白PCB。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②为新进程分配资源。为新进程的程序和数据以及用户栈分配必要的内存空间。操作系统必须知道新进程所需内存的大小。批处理作业的大小可在用户提出创建进程要求时提供。若是为应用进程创建子进程，也应在该进程的创建进程的请求中给出内存的大小。对于交互式程序，用户可以不给出内存要求，而由系统分配一定的空间。如果新进程要共享某个已在内存的地址空间（已装入内存的共享段），则必须建立相应的链接。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③初始化进程控制块。进程控制块PCB的初始化工作包括：初始化标识符信息，将系统分配的标识符、父进程标识符填入新PCB中；初始化处理机状态信息，将程序计数器指向程序的入口地址，使栈指针指向栈顶；初始化调度及控制信息，将进程的状态设置为就绪状态或静止就绪状态；对于优先级，通常是将它设置为最低优先级，除非用户以显式方式提出高优先级要求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④将新进程插入就绪队列。如果进程就绪队列能够容纳新进程，便将新进程插入就绪队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.进程的终止</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）引起进程终止的事件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①正常结束。在任何计算机系统中，都应有一个用于表示进程已经运行完成的指示。例如，在批处理系统中，通常在程序的最后安排一条Halt指令或终止系统调用。当程序运行到Halt指令时，将产生一个中断，去通知操作系统一个进程已经完成。在分时系统中，用户可利用Logs Off去表示进程运行完毕，此时同样可产生一个中断，去通知操作系统已运行完毕。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②异常结束。在进程运行期间，由于出现某些错误和故障而迫使进程终止。这类异常事件很多，常见的有：越界错误，指程序所访问的存储区已越出该进程的区域；保护错误，进程试图去访问一个未被允许访问的资源或文件，或者以不适当的方式进行访问，例如，试图去写一个只读文件；特权指令错误，用户进程试图去执行一条只允许操作系统执行的指令；非法指令错，进程试图去执行一条不存在的指令，出现该错误的原因可能是程序错误地转移到数据区，把数据当成了指令；运行超时，进程的执行时间超过了指定的最大值；等待超时，进程等待某事件的时间超过了规定的最大值；算术运算错，进程试图去执行一个被禁止的计算，例如，被零除；I/O故障，在I/O过程中发生了错误等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③外界干预。外界干预并非指在本进程运行中出现了异常事件，而是进程应外界的请求而终止运行。这些干预有：操作员或操作系统干预，由于某种原因（例如，发生了死锁）由操作员或操作系统终止该进程；父进程请求，由于父进程具有终止自己的任何子孙进程的权利，因而当父进程提出请求时，系统将终止该进程；父进程终止，当父进程终止时，操作系统也将它的所有子孙进程终止。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程的终止过程。一旦系统发生了上述要求终止进程的事件后，操作系统便调用进程终止原语destroy（），按下述过程终止指定进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①根据被终止进程的标识符从进程控制块PCB集合中检索出该进程的PCB，从中读出该进程的状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②若被终止进程正处于执行状态，应立即终止该进程的执行并设置调度标志为真，用于指示该进程被终止后应重新进行调度，选择一新进程，把处理机分配给它。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③若该进程还有子孙进程，还应将其所有子孙进程予以终止，以防它们成为不可控的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④将该进程所拥有的全部资源或者归还其父进程或者归还给系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>⑤将被终止进程的PCB从所在队列中移出，等待其他程序来搜集信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.进程的阻塞与唤醒</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）引起进程阻塞和唤醒的事件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①请求系统服务。当正在执行的进程请求操作系统提供某种服务时，由于某种原因，操作系统并不能立即满足该进程的要求时，该进程只能转变为阻塞状态来等待。例如，一进程请求使用打印机，但系统已将它分配给其他进程而不能分配给请求进程，故请求进程只能被阻塞，仅在其他进程释放出打印机的同时再由释放者将请求者唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②启动某种操作。当进程启动某种操作后，如果该进程必须在该操作完成之后才能继续执行，则必须先使进程阻塞。例如，进程启动某个I/O设备，如果只有在I/O设备完成了指定I/O任务后进程才能继续执行，则进程在启动了I/O操作后，便自动进入阻塞状态去等待。在I/O操作完成后，由中断处理程序或中断进程将该进程唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③新数据尚未到达。对于相互合作的进程，如果其中一个进程需要先获得另一进程提供的数据后才能运行（对数据进行处理），则只要其所需数据尚未到达，进程只有阻塞（等待）。例如，有两个进程，进程A用于输入数据，进程B对输入数据进行加工。假如A尚未将数据输入完毕，则进程B将因无所需的处理数据而阻塞；一旦进程A把数据输入完后，便可唤醒进程B。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④无新工作可做。系统往往设置一些具有某特定功能的系统进程，每当这种进程完成任务后，便把自己阻塞起来等待新任务的到来。例如，系统中的发送进程的主要工作是发送数据，若已有的数据已全部发送完成而又无新的发送请求，进程将使自己进入阻塞状态；而当又有进程提出新的发送请求时，才将发送进程唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程阻塞过程。正在执行的进程当出现上述某个事件时，由于无法继续执行，于是进程便通过调用阻塞原语block（）把自己阻塞。可见，进程的阻塞是进程自身的一种主动行为。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进入block过程后，由于此时该进程还处于执行状态，所以应先立即停止执行，把进程控制块中的现行状态由“执行”改为“阻塞”，并把它插入到阻塞队列。如果系统中设置了因不同事件而阻塞的多个阻塞队列，则应将该进程插入到具有相同事件的阻塞（等待）队列。最后，转到调度程序进行重新调度，将处理机分配给另一就绪进程并进行切换。亦即保留被阻塞进程的处理机状态（在PCB中），再按新进程的PCB中的处理机状态设置处理机环境。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）进程唤醒过程。当被阻塞进程所期待的事件出现时，如I/O操作完成或其所期待的数据已经到达，则由有关进程（例如，用完并释放了该I/O设备的进程）调用唤醒原语wakeup（）将等待该事件的进程唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>唤醒原语执行的过程是：首先把被阻塞进程从等待该事件的阻塞队列中移出，将其进程控制块PCB中的现行状态由“阻塞”改为就绪，然后再将该进程插入到就绪队列中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应当指出，block（）原语和wakeup（）原语是一对作用刚好相反的原语。因此，如果在某进程中调用了阻塞原语，则必须在与之相合作的另一进程或其他相关进程中调用唤醒原语来唤醒阻塞进程；否则，被阻塞进程将会因不能被唤醒而长久地处于阻塞状态，从而再无机会运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.进程的挂起与激活</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程的挂起过程。当出现了引起进程挂起的事件时，例如，用户进程请求将自己挂起或者父进程请求将自己的某个子进程挂起时，系统就利用挂起原语suspend（）将指定进程或处于阻塞状态的进程挂起。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>挂起原语的执行过程是：检查被挂起进程的状态，若正处于活动就绪状态，便将其改为静止就绪；对于活动阻塞状态的进程，则将其改为静止阻塞。为了方便用户或父进程考察该进程的运行情况，而把该进程的PCB复制到某指定的内存区域。最后，如被挂起的进程正在执行，则转到调度程序重新调度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程的激活过程。当发生激活进程的事件时，例如用户进程或父进程请求激活指定进程，若进程驻留在外存而内存又有足够空间，则可将在外存上处于静止就绪状态的进程换入内存。这时，系统将利用激活原语active（）将指定进程激活。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>激活原语先将进程从外存调入内存，检查该进程的现行状态：若是静止就绪，便将其改为活动就绪；若为静止阻塞，便将其改为活动阻塞。假如采用的是抢占调度策略，则每当有新进程进入就绪队列时，应检查是否要进行重新调度，即由调度程序将被激活进程与当前进程进行优先级的比较，如果被激活进程的优先级更低，就不必重新调度；否则，立即剥夺当前进程的运行，把处理机分配给刚激活的进程。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-进程调度" tabindex="-1"><a class="header-anchor" href="#◆-3-3-进程调度" aria-hidden="true">#</a> ◆ 3.3 进程调度</h3>
<blockquote>
<blockquote>
<p>3.3　进程调度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>。在多道程序环境下，进程数目往往多于处理机数目，致使它们竞争处理机。这就要求系统能按某种算法，动态地把处理机分配给就绪队列中的一个进程，使之执行。分配处理机的任务是由进程调度程序完成的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>提高处理机的利用率及改善系统性能（吞吐量、响应时间）在很大程度上取决于进程调度性能的好坏</p>
</blockquote>
</blockquote>
<h4 id="◆-3-3-1-调度的基本概念" tabindex="-1"><a class="header-anchor" href="#◆-3-3-1-调度的基本概念" aria-hidden="true">#</a> ◆ 3.3.1 调度的基本概念</h4>
<blockquote>
<blockquote>
<p>1.高级、中级和低级调度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个程序从提交开始直到完成，往往要经历下述三级调度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）高级调度。高级调度又称作业调度，它决定将哪些在外存上处于后备状态的作业调入主机内存，准备执行。有时把它称为接纳调度。系统一旦接纳了一个作业，便将为它创建一个或一组进程，为它们分配必要的资源，并挂到就绪队列上。在批处理系统中，大多配有高级调度。但在分时系统中，却往往不配置高级调度。高级调度的执行频率较低，它与作业的大小、到达的速率有关，通常为几分钟一次，甚至更久。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）低级调度。低级调度又称进程调度，它决定就绪队列中哪个进程将获得处理机，并实际执行将处理机分配给该进程的操作。执行分配处理机的程序称为分派程序。分派程序的执行频率非常高，典型情况是几十毫秒一次，它必须常驻内存。进程调度是操作系统中最基本的调度，在批处理及分时系统中都必须配置它</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-12　简单的排队调度模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）中级调度。在有些系统中，特别是分时系统及具有虚拟存储器的系统中，可能增加一级中级调度。其主要作用是在内存和外存对换区之间进行进程对换，以解决内存紧张问题，即它将内存中处于等待状态的某些进程调至外存对换区，以腾出内存空间，而将外存对换区上已具备运行条件的进程重新调入内存，准备运行。—个进程在运行期间可能多次调进调出。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.进程调度的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程调度就是系统按照某种算法把处理机动态地分配给某一就绪进程。进程调度工作是通过进程调度程序来完成的。进程调度程序的主要功能可描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）选择占有处理机的进程。选择占有处理机的进程是进程调度的实质，即按照系统规定的调度策略从就绪队列中选择一个进程占有处理机执行。进程调度程序就是通过进程控制块PCB来准确地掌握系统中所有进程的执行情况和状态特征的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于批处理系统常采用短作业的进程优先，以减少各作业的周转时间。而对于分时系统，更多地采用时间片轮转调度算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进行进程上下文的切换。当进程调度选中一个进程占有处理机时，进程调度程序要做的主要工作是进行进程上下文切换：将正在执行进程的上下文保存在该进程的PCB中，以便以后该进程恢复执行。将刚选中进程的运行现场恢复起来，并将处理机的控制权交给被选中进程，使其执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.调度方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程调度有两种方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）非剥夺方式。非剥夺方式规定：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生某事件（如提出I/O请求）而阻塞时才把处理机分配给另一进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种调度方式的优点是简单，系统开销小，貌似公正，但却可能导致系统性能的恶化，表现为：①一个紧急任务到达时，不能立即投入运行，以致延误时机。②若干个后到的短进程须等待长进程运行完毕，导致短进程的周转时间增长。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例如，有3个进程P1、P2、P3先后（但又几乎在同时）到达，它们分别需要30、6和3个单位时间运行完毕。若它们就按P1、P2、P3的顺序执行，且不可剥夺，则3进程各自的周转时间分别为30、36和39个单位时间，平均周转时间是35个单位时间。这种非剥夺方式对短进程P3而言是不公平的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）剥夺方式。剥夺方式规定：当一个进程正在运行时，系统可以基于某种原则剥夺已分配给它的处理机，将之分配给其他进程。剥夺原则有：①优先权原则，优先权高的进程可以剥夺优先权低的进程而运行。②短进程优先原则，短进程到达后可以剥夺长进程的运行。③时间片原则，一个时间片用完后更新调度。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-3-2-进程调度算法" tabindex="-1"><a class="header-anchor" href="#◆-3-3-2-进程调度算法" aria-hidden="true">#</a> ◆ 3.3.2 进程调度算法</h4>
<blockquote>
<blockquote>
<p>进程调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在批处理系统中，系统的设计目标是增加系统吞吐量和提高系统资源的利用率，而分时系统则保证每个分时用户能容忍的响应时间。因此，进程调度通常采用如下一些算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.先进先出算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>先进先出算法（First In First Out，FIFO）是把处理机分配给最先进入就绪队列的进程，即就绪队列按进入的先后次序排队。调度时，选就绪队列中的队首进程投入执行。一个进程一旦分得了处理机，便可一直执行下去，直到该进程完成或因发生某事件而阻塞时，才释放处理机。例如，有3个进程P1、P2和P3，它们先后（但几乎又是同时）进入就绪队列。它们的CPU执行期分别是18、6和3个单位时间。按FIFO算法调度，它们的执行情况如图3-13（a）所示。对于P1，其周转时间是18，P2的周转时间是24，P3的周转时间是27，它们的平均周转时间是23。若它们按P3、P2、P1次序到达，它们的执行情况如图3-13（b）所示。对于P3、P2和P1的周转时间分别是3、9和27，它们的平均周转时间是13。由上述两种情况可以看出：虽然FIFO调度算法易于实现、表面上也公平，但服务质量不佳，容易引起短进程不满，因而FIFO算法很少作为进程调度的主要调度算法，常作为一种辅助调度算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-13　FIFO调度算法的示例</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.最短处理机运行期优先调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>该算法从就绪队列中选出“下一个处理机执行期”最短的进程，为之分配处理机使之执行。例如，在就绪队列中有4个进程P1、P2、P3和P4，它们的下一个处理机执行期分别是13、7、4和3个单位时间。在利用本算法进行调度时，它们的执行情况如图3-14所示。可看出P1、P2、P3和P4的周转时间分别为27、14、7和3个单位时间，它们的平均周转时间近似为13个单位时间。但若用FIFO算法调度，它们的执行情况如图3-15所示。Pl、P2、P3和P4的周转时间分别是13、20、24和27个单位时间，它们的平均周转时间是21。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-14　最短处理机执行期优先调度算法[插图]图3-15　FIFO 调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>虽然最短处理机执行期优先调度算法可获得较好的调度性能，但它所依赖的下一个处理机执行期却难以准确地知道，而只能根据每一个进程的执行历史来预测。令tn是第n个实际的处理机执行期，τn是其预测值，可写出计算下一个处理机执行期的预测公式为τn+1=αtn+（1-α）τn式中，α用于控制最近的tn和其预测值τn在预测中的作用，其值常在0.5左右。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.最高响应比优先调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最高响应比优先调度算法是一个非剥夺的调度算法。按照此算法每个进程都有一个响应比，响应比不但是要求的服务时间的函数，而且是该进程为得到服务所花费的等待时间的函数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的响应比计算公式为[插图]要求的服务时间是分母，所以对短进程有利，可优先运行。但是由于等待时间是分子，所以长进程由于其等待了较长时间，提高了其响应比，因而被分给了处理机。进程一旦得到了处理机，就会执行到进程结束或因等待事件主动让出处理机，中间不被剥夺。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.优先级调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>优先级调度算法是最常用的一种进程调度方法。当发生进程调度时，将处理机分配给就绪队列中优先级最高的进程。通常确定优先级的方法有两种，即静态优先级法和动态优先级法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）静态优先级。静态优先级是在进程创建时确定的。确定进程优先级的依据有以下几种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①进程的类型。依据是用户进程还是系统进程赋予进程一定的优先级。通常赋予系统进程较高优先级，特别是在某些系统中，应赋予它一种特权，只要它需要处理机，应尽快予以满足。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②进程对资源的需求。如估计运行时间、内存需要量、I/O设备的数量等，申请资源量少的赋予较高优先级。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③用户申请的优先级。根据用户所提供的外部优先权，确定该程序所对应的进程优先级。这通常是用高的经济费用换取高的优先级。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一旦进程的优先级确定，在其整个运行过程中保持不变。这种算法的最大优点是简单，但不能动态反映进程特点，系统调度性能差。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）动态优先级。为了克服静态优先级的缺点，可采用动态优先级。所谓动态优先级是指：进程在开始创建时，根据某种原则确定一个优先级后，随着进程执行时间的变化，其优先级不断地进行动态调整。例如，在就绪队列中的进程，其优先级以速率α增加，若所有进程具有相同的优先级初值，这将使最先进入就绪队列的进程最先获得处理机。若所有进程具有不同的优先级初值，优先级低的进程在等待足够长的时间后，其优先级便可升为最高而获得处理机执行。在采用可剥夺式调度方式时，若再令正在执行进程的优先级以速率β下降，便可防止一个长进程长期垄断处理机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通常根据进程占有处理机时间的长短或等待处理机时间的长短动态调整。UNIX系统进程优先级正是采用这种方法实现的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.时间片轮转调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>时间片轮转调度算法（Round Robin，RR）通常用在分时系统，它按照先进先出原则轮流地调度就绪队列中的进程。在实现时，它利用一个定时时钟，使之定时地发出中断。时钟中断处理程序在设置新的时钟常量后，即转入进程调度程序，选择一个新的进程占用处理机。时间片长短的确定遵循这样的原则：既要保证系统各个用户进程及时地得到响应，又不要由于时间片太短而增加调度的开销，降低系统的效率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>就绪队列中的进程在依次执行时，可能发生以下3种情况：（1）进程未用完一个时间片便结束，这时系统应提前进行调度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程在执行过程中提出I/O请求而阻塞，系统应将它放入相应的阻塞队列并引起调度。（3）进程用完一个时间片后尚未完成，系统应将它重新放到就绪队列的末尾，等待下次执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>简单时间片轮转法的调度模型如图3-16所示。[插图]图3-16　简单时间片轮转法的调度模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.前后台调度算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>前后台调度算法用在批处理和分时相结合的系统中。将分时用户程序放在前台，把批处理程序放在后台。系统对前台程序按照时间片轮转法进行调度，仅当前台无程序时，才把处理机分配给后台程序的进程。后台进程通常按先来先服务方式运行。这样既能使分时用户进程得到及时响应，又提高了系统资源的利用率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在有的系统中，把进程分成更多类型，如系统进程、交互型进程、编辑型进程、批处理型进程、学生型进程5种。这样，系统中就应设置5个就绪队列，并赋予它们不同的优先级。对每个队列可采用不同的调度算法，如对系统进程队列可采用优先级调度算法；对交互型进程队列采用时间片轮转调度算法；对批处理型进程队列采用FIFO算法等。仅当无系统进程时，才运行交互型进程；仅当无系统型和交互型进程时，才运行编辑型进程；学生型进程队列的优先级最低。因此，仅当系统中无其他类型进程时，才运行学生型进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>7.多级反馈队列轮转算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在轮转法中，进程在就绪队列的情况有如下3种：一种是刚刚被创建的进程在等待进程调度；一种是已经被调度执行过，但还没有执行完，等待下一次调度；还有一种是正在执行的进程还未用完分给它的时间片，因请求I/O、等待I/O完成等原因被迫放弃处理机，当等待原因解除后又一次进入就绪队列等待运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于上述3种情况，系统通常设置多个就绪队列，且进程在其生命期内可能在多队列中存在。通常刚创建的进程和因请求I/O未用完时间片的进程排在最高优先级队列，在这个队列中运行2～3个时间片未完成的进程排入下一个较低优先级队列。这样，系统可设置n个优先级队列。系统在调度时，总是先调度优先级最高的队列。仅当该队列为空时，才调度次高优先级队列。依此类推，第n个队列进程被调度时，必须是前n-1个队列为空。无论什么时候，只要较高优先级队列有进程进入，立即转到进程调度，及时调度较高优先级队列进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种多级队列反馈算法能较好地满足各类进程的用户要求，既能使分时用户进程得到满意的响应，又能使批处理用户的进程获得较合理的周转时间。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-3-3-进程调度的时机和过程" tabindex="-1"><a class="header-anchor" href="#◆-3-3-3-进程调度的时机和过程" aria-hidden="true">#</a> ◆ 3.3.3 进程调度的时机和过程</h4>
<blockquote>
<blockquote>
<p>1.进程调度的时机执行进程调度一般是在下述情况下发生的。（1）正在执行的进程运行完毕。（2）正在执行的进程调用阻塞原语将自己阻塞起来进入等待状态。（3）在采用抢占式优先级调度时，有优先级高于正在运行进程的进程进入就绪队列。（4）在分时系统中时间片已经用完。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以上都是在处理机为不可剥夺方式时引起进程调度的原因。当处理机方式是可剥夺时，还有下面的原因：就绪队列中的某个进程越优先级变为高于当前运行进程的优先级，这时也将引起进程调度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.进程调度的过程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程调度所依赖的数据结构通常是调度队列，由于调度的原因不同，在单处理机系统中设置了多种等待队列。例如，等待处理机的就绪队列、等待I/O请求响应的设备队列、等待实时时钟的睡眠队列、等待通信信息的通信队列等。每种队列中的进程都可能引起调度，都可以采用上述各种算法和算法组合。但是，只有就绪队列中的进程能够获得处理机而最终运行，其他队列中的进程从队列中调度出来后，必须进入就绪队列才能分配处理机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>新创建的进程可以处于自由状态，排入一个队列，也可以直接进入挂起队列或者就绪队列，分别处于挂起状态和就绪状态。到底进入哪个队列与操作系统的设计有关，大多数情况下，新进程是进入就绪队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>队列数据结构的组成可以是堆栈、树、链表等，队列可以是双向队列，也可以是单向或者循环队列，它们的建立结构与调度算法密切相关。例如，在时间片轮转法中，就绪进程常组织成FIFO队列形式。在最高优先级优先调度算法中（常采用优先级队列形式），进程在进入就绪队列时，根据其优先级的高低，把它插在队列中相应优先级的位置上。调度程序总是把处理机分配给就绪队列中的队首进程。在最高优先级优先的调度算法中，也可采用无序链表方式，即每次进程进入就绪队列时，只被放在队尾，而由调度程序在每次调度时，依次比较队列中各进程的优先级，从中找出优先级最高的进程，把处理机分配给它。比起优先级队列来，这种方式的调度效率较低。对就绪队列的操作也是使用系统原语进行的，例如，对就绪队列操作，可以包含newqueue（队列创建）、enqueue（插入队列项）、dequeue（撤销队列项）等原语。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程调度算法只是决定哪一个进程将获得处理机，而将处理机分配给该进程的具体操作是由分派程序完成的。分派程序首先将正在执行进程的处理机状态保存在该进程PCB的现场保留区中，再从被调度程序选中的进程的PCB现场保留区中，取出其处理机状态信息来重新布置处理机现场。处理机状态信息包括程序状态寄存器、若干个通用寄存器、程序计数器等信息。这样，被调度到的进程便可继续执行。由于分派程序的执行频率较高，典型情况是几十毫秒一次，因而应尽量提高其运行效率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假定就绪队列中的进程，已按其优先级的大小排列并允许剥夺调度，当就绪队列的队首出现其优先级比当前正在执行进程j的优先级更高的进程i时，应立即停止当前进程j的执行并将它按其优先级的大小，插入到就绪队列中的适当位置上（调用enqueue（RQ，j）），然后用进程i所保存的处理机现场信息去恢复处理机现场。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-4-1-线程的引入" tabindex="-1"><a class="header-anchor" href="#◆-3-4-1-线程的引入" aria-hidden="true">#</a> ◆ 3.4.1 线程的引入</h4>
<blockquote>
<blockquote>
<p>在操作系统中引入进程的目的是使多个程序并发执行以改善资源利用率及提高系统的吞吐量；那么，在操作系统中再引入线程，则是为了减少程序并发执行时所付出的时空开销，使操作系统具有更好的并发性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的两个基本属性：一是进程是一个可拥有资源的独立单位；二是进程同时又是一个可以独立调度和分派的基本单位。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为使程序能并发执行，系统还必须进行以下的一系列操作：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）创建进程。系统在创建进程时，必须为之分配其所必需的、除处理机以外的所有资源，如内存空间、I/O设备以及建立相应的PCB。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）撤销进程。系统在撤销进程时，必须先对资源进行回收操作，然后再撤销PCB。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）进程切换。在对进程进行切换时，由于要保留当前进程的处理机环境和设置新选中进程的处理机环境，需花费不少处理机时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于进程是一个资源拥有者，因而在进程的创建、撤销和切换中，系统必须为之付出较大的时空开销。也正因如此，在系统中所设置的进程数目不宜过多，进程切换的频率也不宜过高，但这也就限制了并发程度的进一步提高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如何能使多个程序更好地并发执行，同时又尽量减少系统的开销，这已成为近年来设计操作系统时所追求的重要目标。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可否将进程的上述两个属性分开，由操作系统分开进行处理？即对作为调度和分派的基本单位，不同时作为独立分配资源的单位，以使之轻装运行；而对拥有资源的基本单位，又不频繁地对之进行切换。正是在这种思想的指导下，产生了线程概念。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-4-2-线程的定义和属性" tabindex="-1"><a class="header-anchor" href="#◆-3-4-2-线程的定义和属性" aria-hidden="true">#</a> ◆ 3.4.2 线程的定义和属性</h4>
<blockquote>
<blockquote>
<p>线程是进程的一个实体，是被系统独立调度和分派的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器、一组寄存器和栈），但它可与同属一个进程的其他线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程；同一进程中的多个线程之间可以并发执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>线程也同样有就绪、阻塞和执行3种基本状态。线程有如下属性：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）每个线程有一个唯一的标识符和一张线程描述表，线程描述表记录了线程执行的寄存器和栈等现场状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）不同的线程可以执行相同的程序，即同一个服务程序被不同用户调用时操作系统为它们创建成不同的线程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）同一进程中的各个线程共享该进程的内存地址空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）线程是处理机的独立调度单位，多个线程是可以并发执行的。在单处理机的计算机系统中，各线程可交替地占用处理机。在多处理机的计算机系统中，各线程可同时占用不同的处理机，若各个处理机同时为一个进程内的各线程服务则可缩短进程的处理时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）一个线程被创建后便开始了它的生命周期，直至终止，线程在生命周期内会经历阻塞状态、就绪状态和执行状态等各种状态变化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>线程的好处</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）创建一个新线程花费时间少（结束亦如此）。创建线程不需另行分配资源，因而创建线程的速度比创建进程的速度快，且系统的开销也少。（2）两个线程的切换花费时间少。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）由于同一进程内的线程共享内存和文件，线程之间相互通信无须调用内核，故不需要额外的通信机制，使通信更简便，信息传送速度也快。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）线程能独立执行，能充分利用和发挥处理机与外围设备并行工作的能力。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-4-3-线程与进程的比较" tabindex="-1"><a class="header-anchor" href="#◆-3-4-3-线程与进程的比较" aria-hidden="true">#</a> ◆ 3.4.3 线程与进程的比较</h4>
<blockquote>
<blockquote>
<p>线程与进程的比较</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>线程具有许多传统进程所具有的特征，故又称轻型进程或进程元；而把传统的进程称为重型进程，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少也需要有一个线程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从调度、并发性、拥有资源、系统开销等方面来比较线程和进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.调度在传统的操作系统中，拥有资源的基本单位和独立调度、分派的基本单位都是进程。而在引入线程的操作系统中，则把线程作为调度和分派的基本单位，而把进程作为资源拥有的基本单位，使传统进程的两个属性分开，线程便能轻装运行，从而可显著地提高系统的并发程度。在同一进程中，线程的切换不会引起进程切换；在由一个进程中的线程切换到另一个进程中的线程时，将会引起进程切换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.并发性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，因而使操作系统具有更好的并发性，从而能更有效地使用系统资源和提高系统吞吐量。例如，在一个未引入线程的单处理机操作系统中，若仅设置一个文件服务进程，当它由于某种原因而被阻塞时，便没有其他的文件服务进程来提供服务。在引入了线程的操作系统中，可以在一个文件服务进程中设置多个服务线程，当第一个线程等待时，文件服务进程中的第二个线程可以继续运行；当第二个线程受阻塞时，第三个线程可以继续执行，从而显著地提高了文件服务的质量以及系统吞吐量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.拥有资源</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不论是传统的操作系统，还是设有线程的操作系统，进程都是拥有资源的一个独立单位，它可以拥有自己的资源。一般地说，线程自己不拥有系统资源（也有一点必不可少的资源），但它可以访问其隶属进程的资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个进程的代码段、数据段以及系统资源，如已打开的文件、I/O设备等，可供同一进程的所有线程共享。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.系统开销</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于在创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等，因此，操作系统所付出的开销将显著地大于在创建或撤销线程时的开销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在进行进程切换时，涉及整个当前进程处理机环境的保存以及新被调度运行的进程的处理机环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程切换的开销也远大于线程切换的开销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现也变得比较容易。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-4-4-线程的实现机制" tabindex="-1"><a class="header-anchor" href="#◆-3-4-4-线程的实现机制" aria-hidden="true">#</a> ◆ 3.4.4 线程的实现机制</h4>
<blockquote>
<blockquote>
<p>线程的实现机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.用户级线程和内核支持线程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一些数据库管理系统（如Informix）实现的是用户线程，这种线程不依赖于内核。而另一些系统（如Mach和OS/2操作系统）实现的是内核支持线程，这种线程依赖于内核。还有一些系统（如Solaris操作系统），则同时实现了这两种类型的线程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于通常的进程，不论是系统进程还是用户进程，在进行切换时都要依赖于内核中的进程调度。因此，不论什么进程都是与内核有关的，是在内核支持下进行切换的。对于线程来说，则可分为两类：一类是内核支持线程，它们是依赖于内核的，即无论是在用户进程中的线程，还是系统进程中的线程，它们的创建、撤销和切换都由内核实现。在内核中保留了一张线程控制块，内核根据该控制块而感知该线程的存在并对线程进行控制。另一类是用户级线程。它仅存在于用户级中，对于这种线程的创建、撤销和切换，都不利用系统调用来实现，因而这种线程与内核无关。相应地，内核也并不知道有用户级线程的存在。这两种线程各有优缺点，因此它们也各有其适用场所。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从3个方面对用户级线程和内核支持线程进行比较</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）线程的调度与切换速度。内核支持线程的调度和切换与进程的调度和切换十分相似。例如，在线程调度时的调度方式同样也是抢占方式和非抢占方式两种。在线程的调度算法上也同样采用时间片轮转调度算法、优先级调度算法等。由线程调度选中一个线程后，再将处理机分配给它。当然，线程在调度和切换上所花费的开销要比进程的小得多。用户级线程的切换通常是发生在一个应用进程的诸线程之间</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>无须通过中断进入操作系统的内核</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当一个线程阻塞后会自动地切换到下一个具有相同功能的线程。因此，用户级线程的切换速度特别快。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）系统调用。当传统的用户进程调用一个系统调用时，要由用户态转入核心态，用户进程将被阻塞。当内核完成系统调用而返回时才将该进程唤醒继续执行。而在用户级线程调用一个系统调用时，由于内核并不知道该用户级线程的存在，因而把系统调用看作整个进程的行为，于是使该进程等待，而调度另一进程执行，同样是在内核完成系统调用而返回时进程才继续执行。如果系统中设置的是内核支持线程，则调度是以线程为单位，当一个线程调用一个系统调用时，内核把系统调用只看作该线程的行为，因而阻塞该线程，于是可以再调度该进程中的其他线程执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）线程执行时间。对于只设置了用户级线程的系统，调度是以进程为单位进行的。在采用时间片轮转调度算法时，各个进程轮流执行一个时间片，这对诸进程而言似乎是公平的。但假如在进程A中包含了一个用户级线程，而在另一个进程B中含有100个线程，这样，进程A中线程的运行时间将是进程B中各线程运行时间的100倍；相应地，速度就快100倍。假如系统中设置的是内核支持线程，其调度是以线程为单位进行的，这样，进程B可以获得的处理机时间是进程A的100倍，进程B可使100个系统调用并发工作。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-5-linux的进程与进程管理" tabindex="-1"><a class="header-anchor" href="#◆-3-5-linux的进程与进程管理" aria-hidden="true">#</a> ◆ 3.5 Linux的进程与进程管理</h3>
<blockquote>
<blockquote>
<p>Linux系统中主要的活动实体就是进程，每个进程执行一段独立的程序并在进程初始化时拥有一个独立的控制线程。由于Linux是一个多道程序设计系统，因此系统中有多个批次相互独立的进程在同时运行。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-5-1-linux的进程结构与进程控制" tabindex="-1"><a class="header-anchor" href="#◆-3-5-1-linux的进程结构与进程控制" aria-hidden="true">#</a> ◆ 3.5.1 Linux的进程结构与进程控制</h4>
<blockquote>
<blockquote>
<p>1.Linux的进程结构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux支持多进程。进程控制块是系统中最为重要的数据结构之一，用来存放进程所必需的各种信息。进程控制块用结构task_struct来表示，定义在文件include\linux\seched.h中，包括如下一些内容：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程状态。Linux把进程状态区分为运行态、等待态、暂停态和僵死态。其中，运行态指进程正在运行或处于就绪队列中；等待态指进程处于等待队列中，待资源有效时被唤醒；暂停态指进程接收信号或出现故障后暂停运行的状态；僵死态指进程已经停止运行，但进程控制块仍然存在。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程调度信息。用于进程调度，决定优先级。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）进程标识。Linux进程都有唯一的标识PID，另外还有一个组标识GID，均用数字表示，用于访问系统文件和设备时使用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）内部通信信息。用于消息队列、信号量或共享内存等进程通信操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）进程指针。表示父子进程、兄弟进程之间的连接关系。（6）时钟信息。用于追踪使用处理机时间、软件定时等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（7）文件系统。记录进程访问文件的信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（8）虚拟存储信息。记录进程的内存空间分配信息。（9）进程上下文。记录进程当前运行现场的各种必要信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统中还有一个数组task[]，用来存放每一个进程控制块的指针，相当于一个矢量表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux的进程控制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程的建立。一个进程可以通过调用fork（）创建新的进程，其中原进程称为父进程，新进程称为子进程。父子进程除了进程标识PID不同以外，代码段和数据的内容都是相同的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程执行。启动一个进程可以通过调用exec（）来实现，其参数就是需要执行的文件名。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）等待子进程结束。父进程创建子进程后，可以调用wait（）等待子进程执行结束。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）结束子进程。需要结束一个进程时，调用exit（）实现。</p>
</blockquote>
</blockquote>
<h4 id="◆-3-5-2-linux的核心进程调度" tabindex="-1"><a class="header-anchor" href="#◆-3-5-2-linux的核心进程调度" aria-hidden="true">#</a> ◆ 3.5.2 Linux的核心进程调度</h4>
<blockquote>
<blockquote>
<p>Linux中的进程调度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作为一种通用操作系统的Linux的进程调度采用了最一般的调度策略，系统中的普通进程采取优先级调度策略，系统中的实时进程采用先进先出（FIFO）与时间片轮转调度算法（Round Robin）相结合的方法进行调度，这样的调度算法在大多数情况下都能很好地工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux系统中存在两类进程——普通进程与实时进程。实时进程的优先级要高于其他进程。如果一个实时进程处于可执行状态，它将先得到执行。实时进程又有两种策略：时间片轮转和先进先出。在时间片轮转策略中，每个可执行的实时进程轮流执行一个时间片，而先进先出策略中每个可执行进程按各自在运行队列中的顺序执行，并且顺序不能变化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Linux中，进程调度策略共定义了3种：（1）SCHED_FIFO。用于实时进程的调度。（2）SCHED_RR。用于实时进程的调度。（3）SCHED_OTHER。用于非实时进程的调度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux核心中的软中断机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>发生中断时，处理机要停止当前正在执行的指令，而操作系统负责将中断发送到对应的设备驱动程序去处理。在中断的处理过程中，系统不能进行其他任何工作，在这段时间内，设备驱动程序要以最快的速度完成中断处理，而其他大部分工作在中断处理过程之外进行。Linux内核利用底层处理过程帮助实现中断的快速处理，它可以让设备驱动和Linux核心其他部分将这些工作进行排序以延迟执行。软中断机制在Linux核心中的文件softirq.c中实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux中的3个系统任务队列</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任务队列是核心延迟任务启动的主要手段。Linux提供了对任务队列中任务排队以及处理的通用机制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.Linux中调度程序运行的时机Linux中的调度程序在以下情况下运行：当前进程被放入等待队列后或者系统调用结束时，以及从系统模式返回用户模式时。此时系统时钟将当前进程的counter值设为0来驱动调度管理器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.Linux中具体的调度流程Linux核心调度程序在文件sched.c中定义。每次调度管理器运行时将进行下列操作：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）处理任务队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）核心工作。系统调度程序需要判断当前是否在中断处理过程中，在中断处理中不能运行调度程序，调度程序将退出。调度程序运行bottom half处理程序并处理调度任务队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）保存当前进程的工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）选择将要运行的进程。调度器在运行队列中选择一个最迫切需要运行的进程。如果运行队列中存在实时进程（那些具有实时调度策略的进程），则它们比普通进程具有更高的优先级权值。普通进程的权值是它的counter值，而实时进程则是counter加上1000。这表明如果系统中存在可运行的实时进程，它们将总是在任何普通进程之前运行。如果系统中存在和当前进程相同优先级的其他进程，这时当前运行进程已经用掉了一些时间片，所以它将处在不利形势（其counter已经变小）；而原来优先级与它相同的进程的counter值显然比它大，这样位于运行队列中最前面的进程将开始执行而当前进程被放回到运行队列中。在存在多个相同优先级进程的平衡系统中，每个进程被依次执行，这就是时间片轮转法（Round Robin）策略。然而由于进程经常需要等待某些资源（例如I/O等），所以它们的运行顺序也经常发生变化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）换出当前运行的进程。如果系统选择其他进程运行，则必须挂起当前进程且开始执行新进程。进程执行时将使用寄存器、物理内存以及处理机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当挂起一个进程时，系统的机器状态，包括程序计数器（PC）和全部的处理机寄存器，必须存储在进程的task_struct数据结构中，同时加载新进程的机器状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的切换发生在调度管理器运行之后。以前进程保存的上下文与当前进程加载时的上下文相同，包括进程程序计数器和寄存器内容。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果以前或者当前进程使用了虚拟内存，则系统必须更新其页表入口</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>SPINLOCK自旋锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>自旋锁是一种保护数据结构或代码片段的原始方式，在某个时刻只允许一个进程访问临界区内的代码。自旋锁的定义在文件spinlock.h中。在Linux中定义了两种自旋锁，一种是普通自旋锁，另一种是用于读/写操作的自旋锁（允许多个读者和一个写者）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux还同时将一个整数域作为锁来限制对数据结构中某些域的存取。每个希望进入此区域的进程都试图将此锁的初始值从0改成1。如果当前值是1，则进程将再次尝试，此时进程好像在一段循环代码中自旋。对包含此锁的内存区域的存取必须是原子性的，即检验值是否为0并将其改变成1的过程不能被任何进程中断。多数处理机结构通过特殊指令提供对此方式的支持，同时可以在一个非缓冲内存中实现这个自旋锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当控制进程离开临界区时将递减此自旋锁。任何处于自旋状态的进程都可以读取它，它们中最快的那个将递增此值并进入临界区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>SEMAPHORE信号量</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux中使用的信号量在文件semaphore.h中定义。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号量被用来保护临界区中的代码和数据。每次对临界区数据，如描述某个目录VFS inode的访问，是通过代表进程的核心代码来进行的。允许某个进程擅自修改由其他进程使用的临界区数据是非常危险的。防止此问题发生的一种方式是在被存取临界区周围使用自旋锁，但这种简单的方式将降低系统性能。Linux使用信号量来迫使某个时刻只有唯一进程访问临界区代码和数据，其他进程都必须等待资源被释放才可使用。这些等待进程将被挂起而系统中其他进程可以继续运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux的信号量的实现对于SMP和中断都是安全的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Linux中一个信号量结构的定义和其中各个域的作用如下：[插图]count：此域用来保存希望访问此资源的进程个数。当它为正数时表示资源可用，负数和0表示进程必须等待，当它初始值为1时表示一次仅允许一个进程来访问此资源。当进程需要此资源时它们必须将此count域减1，并且在使用完后将其加1。可以看到，对该域的操作应该是一个原子操作。waking：这是等待此资源的进程个数，同时也是当资源可利用时等待被唤醒的进程个数。wait_queue：当进程等待此资源时，它们被放入此等待队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设此信号量的初始值为1，第一个使用它的进程看到此计数为正值，然后将其减去1而得到0。现在此进程拥有了这些被信号量保护的段代码和资源。当此进程离开临界区时它将增加此信号量的计数值，最好的情况是没有其他进程与之争夺临界区的控制权。Linux将信号量设计成可以在多数情况下有效工作。如果此时另外一个进程希望进入此已被别其他进程占据的临界区时，它也将此计数减1。当它看到此计数值为-1，则知道现在不能进入临界区，必须等到此进程退出使用临界区为止。在这个过程中Linux将让这个等待进程睡眠。等待进程将其自身添加到信号量的等待队列中，然后系统在一个循环中检验waking域的值并当waking非0时调用调度管理器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>临界区的所有者将信号量计数值加1，但是如果此值仍然小于等于0则表示还有等待此资源的进程在睡眠。在理想情况下此信号量的计数将返回到初始值1而无须做其他工作，所有者进程将递增waking计数并唤醒在此信号量等待队列上睡眠的进程。当等待进程醒来时，发现waking计数值已为1，那么就知道现在可以进入临界区了。然后将递减waking计数，将其变成0并继续。所有对信号量waking域的访问都将受到使用信号量的自旋锁的保护。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>9.原子操作</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>C语言并没有提供有效的手段用于原子操作以保证对一个数据的操作是原子的（操作过程是不可中断的），因此，在众多需要对某关键数据进行操作的地方为保证其原子性引入了原子操作，原子操作在文件atomic.k中定义。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>原子操作其实就是保证在单处理机的情况下编译器产生的数据操作代码只是一条汇编语句而已。需要注意的是，在SMP的情况下，在进行原子操作前需要进行LOCK，而且进行原子操作的数据也是volatile的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux中的实时钟</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux的时钟观念很简单，它表示系统启动后的以时钟滴答计数的时间。所有的系统时钟都基于这种量度，在系统中的名称和一个全局变量相同——jiffies。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux包含两种类型的系统定时器，它们都可以在某个系统时间上被队列例程使用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>第一个是旧的定时器机制，它包含指向timer_struct结构的32位指针的静态数组，以及当前活动定时器的屏蔽码time_active</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>旧的定时器已经被淘汰，只是因为兼容性的原因在源代码中还存在，在编写新的内核代码和应用程序代码时应该使用新的定时器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>第二种是相对较新的定时器，它使用一个以升序排列到期时间的timer_list结构链表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>新定时器机制的优点之一是能传递一个参数给定时器例程，而旧的定时器机制则不行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux中的对称多处理机支持</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>只能支持单处理机的核心是不能在多处理机上正常工作的，在编译Linux内核的过程中，根据是否支持对称多处理机编译条件设置的不同将产生不同的内核。一般说来，单处理机的内核要比多处理机的内核简单一些。</p>
</blockquote>
</blockquote>
<h3 id="◆-习题-2" tabindex="-1"><a class="header-anchor" href="#◆-习题-2" aria-hidden="true">#</a> ◆ 习题</h3>
<blockquote>
<blockquote>
<p>习题1.什么是进程？它与程序有哪些异同点？2.进程控制块的作用是什么？它主要包括哪几部分内容？3.进程有哪几种基本状态？试举出使进程状态发生变化的事件并描绘它的状态转换图。4.什么是操作系统的内核？5.大多数时间片轮转调度算法使用一个固定大小的时间片，给出选择小时间片的理由，然后再给出选择大时间片的理由。6.某系统采用最高响应比优先的调度算法，某个时刻根据用户要求创建了一个进程P，进程P在其存在过程中依次经历了以下过程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）进程调度选中了进程P占用处理机运行，进程P运行中提出资源申请，要求增加内存使用量，没有得到。（2）进程等待一段时间后得到内存。（3）进程调度再次选中了进程P占用处理机运行。（4）有紧急进程Q进入，系统停止进程P的运行，将处理机分配给进程Q。（5）进程Q运行完，进程调度再次选中了进程P占用处理机运行。（6）进程P运行完。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分析进程P在其整个生命过程中的状态变化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>7.什么是线程？进程和线程的主要区别是什么？8.简述创建进程的步骤。</p>
</blockquote>
</blockquote>
<h2 id="第4章-进程同步与通信" tabindex="-1"><a class="header-anchor" href="#第4章-进程同步与通信" aria-hidden="true">#</a> 第4章　进程同步与通信</h2>
<h3 id="◆-4-1-进程间的相互作用" tabindex="-1"><a class="header-anchor" href="#◆-4-1-进程间的相互作用" aria-hidden="true">#</a> ◆ 4.1 进程间的相互作用</h3>
<blockquote>
<blockquote>
<p>相对独立的多个用户程序可以并发运行；操作系统本身的许多不同功能的程序可以并发执行；一个程序内部的不同程序段可以并发执行。操作系统支持这些活动是通过进程来实现的。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-1-1-进程间的联系" tabindex="-1"><a class="header-anchor" href="#◆-4-1-1-进程间的联系" aria-hidden="true">#</a> ◆ 4.1.1 进程间的联系</h4>
<blockquote>
<blockquote>
<p>在多道程序环境下，系统中可能有许多进程，在这些进程之间可能存在以下两种关系。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）资源共享关系。多个进程之间彼此无关，它们并不知道其他进程的存在。例如，在批处理系统中，系统分别为各个作业建立了进程；在分时系统中，系统分别为每个用户（终端）建立一个进程。但这些进程既然是同处于一个系统中，也就必然存在着资源共享的关系，如共享CPU和I/O设备等。此时，进程同步的主要任务是保证诸进程能互斥地访问临界资源。为此，系统中的资源应不允许用户进程直接使用，而应由系统统一分配。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）相互合作关系。在某些进程之间还存在一种相互合作的关系，例如，如图3-3所示的程序并发执行前驱图中，在输入进程、计算进程和打印进程三者之间，就是一种相互合作的关系。此时进程同步的主要任务是保证相互合作的诸进程在执行次序上的协调，不会出现与时间有关的差错。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.临界资源</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>生产者-消费者问题（Producer-Consumer）是一个著名的进程同步问题。它描述的是：有一群生产者进程在生产产品，并将此产品提供给消费者进程去消费。为使生产者进程和消费者进程能并发执行，在它们之间设置一个具有n个缓冲区的缓冲池，生产者进程可将它所生产的产品放入一个缓冲区中，消费者进程可从一个缓冲区取得一个产品消费。尽管所有的生产者进程和消费者进程都是以异步方式运行的，但它们之间必须保持同步，即不允许消费者进程到一个空缓冲区去取产品，也不允许生产者进程向一个已装有产品且尚未被取走的缓冲区中投放产品。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]假设counter的当前值是5。如果生产者进程先执行左列的3条机器语言语句，然后消费者进程再执行右列的3条语句，则最后共享变量counter的值仍为5；反之，如果让消费者进程先执行右列的3条语句，然后生产者进程再执行左列的3条语句，counter的值也还是5，如果按下述方式执行：[插图]正确的答案（counter值）应当是5，但现在是4。倘若再将两段程序中各语句交叉执行的顺序改变，可以看到有可能得到counter==6的答案。这表明程序的执行不具有可再现性。这种一个时刻只允许一个进程使用的资源称为临界资源。为了预防产生这种错误，应对临界资源进行互斥访问，亦即，令生产者进程和消费者进程互斥地访问变量counter。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.临界区</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不论是硬件临界资源，还是软件临界资源，多个进程必须互斥地对它们进行访问。把在每个进程中访问临界资源的那段代码称为临界区（Critical Section）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>若能保证诸进程互斥地进入自己的临界区，便可实现它们对临界资源的互斥访问。为此，每个进程在进入临界区之前应先对欲访问的临界资源进行检查，看它是否正在被访问。如果此时临界资源未被访问，该进程便可进入临界区对该资源进行访问，并设置它正被访问的标志；如果此刻该临界资源正被某进程访问，则该进程不能进入临界区。因此，必须在临界区前面增加一段用于进行上述检查的代码。相应地，在临界区后面也要加上一段代码，用于将临界区正被访问的标志恢复为未被访问标志。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同步机制应遵循的准则</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为实现进程互斥，可利用软件方法在系统中设置专门的同步机制来协调诸进程，但所有的同步机制都应遵循下述4条准则：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）空闲让进。当无进程处于临界区时，相应的临界资源处于空闲状态。因而可允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）忙则等待。当已有进程进入自己的临界区时，意味着相应的临界资源正被访问，因而所有其他试图进入临界区的进程必须等待，以保证诸进程互斥地访问临界资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）有限等待。对要求访问临界资源的进程，应保证该进程能在有效的时间内进入自己的临界区，以免陷入“死等”状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-1-2-利用软件方法解决进程互斥问题" tabindex="-1"><a class="header-anchor" href="#◆-4-1-2-利用软件方法解决进程互斥问题" aria-hidden="true">#</a> ◆ 4.1.2 利用软件方法解决进程互斥问题</h4>
<blockquote>
<blockquote>
<p>利用软件方法解决进程互斥问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假如有两个进程P1和P2，它们共享一个临界资源R。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>设置一个公用整型变量turn，用于指示被允许进入临界区的进程的编号，即若turn==1，表示允许进程P1进入临界区。算法1对P1进程的描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]该算法可确保每次只允许一个进程进入临界区。但是强制两个进程轮流地进入临界区，很容易造成资源利用不充分。例如，当进程P1退出临界区后将turn置为2，以便允许P2进入临界区。但如果进程P2暂时并未要求访问该临界资源，而P1又想再次访问该资源，但它却无法进入临界区。可见，此算法不能保证实现“空闲让进”的准则。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>算法1的问题在于：它采取了强制的方法让P1和P2轮流访问临界资源，完全不考虑它们的实际需要。算法2的基本思想是：在每一个进程访问临界资源之前，先去查看一下临界资源是否正被访问。若正被访问，该进程需等待；否则进入自己的临界区。为此，设置一个数组，使其中每个元素的初值为0，表示所有进程都未进入临界区。若flag[0]==1时，表示进程P1正在临界区内执行；若flag[1]==1时，表示进程P2正在临界区内执行。算法2的描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>此算法虽然解决了空闲让进的问题，但又出现了新的问题。即当P1和P2都未进入临界区时，它们各自的访问标志都为0。如果P1和P2几乎是在同时都要求进入临界区，因而都发现对方的访问标志flag为0，于是两进程都先后进入临界区，这时就违背了“忙则等待”的准则。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>算法2的问题在于：当进程P1观察到进程P2的标志为0后，便将自己的标志由0改为1，这仅需一极短的时间，而正是在此期间，它仍然表现为0而被P2所观察到。为了解决这一问题，在算法3中仍然使用了数组flag[]，但令flag[0]==1表示进程P1希望进入临界区，然后再去查看P2的标志。若此时flag[1]==1，则P1等待；否则，P1进入临界区；对于进程P2亦然。换言之，算法3是使要进入临界区的进程先设置其要求进入的标志，然后，再去查看其他进程的标志。算法3描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]算法3可以有效地防止两个进程同时进入临界区。但仔细分析又可看出，该算法又会造成最终谁都不能进入临界区的后果。因而它既违背了“空闲让进”的准则1，又违背了“有限等待”的准则3。例如，当P1和P2几乎在同时要进入临界区，而分别把自己的标志flag置为1后，又都立即去检查对方的标志，因而都发现对方也要进入或已经在临界区，即对方的标志也为1，于是双方都在“谦让”，结果谁也进不了临界区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>算法4是组合了算法1和算法3中的关键概念而形成的。算法4为每个进程设置了相应的标志flag[]，当flag[0]==1（或flag[1]==1）时，表示进程P1（或P2）要求进入临界区或正在临界区中执行。此外，还设置了一个turn变量，用于指示允许进入临界区的进程编号。进程P1为了进入临界区先置flag[0]为1，并置turn为2，表示应轮到进程P2进入临界区。接下去再判别flag[1]&amp;&amp;turn==2的条件是否满足。若未满足，则可进入临界区；否则等待。或者说，当flag[1]==0或者turn==1时，进程P1可以进入临界区。前者表示P2未要求进入临界区，后者表示仅允许P1进入临界区。该算法描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假如进程P1和进程P2几乎同时要求进入临界区，它们将分别将标志flag[0]和flag[1]置为1。P1先将turn置为2，当它去执行while语句时，flag[1]&amp;&amp;turn==2条件成立，故P1等待；但立即P2又将turn置成1；这样，P1便可进入临界区，而进程P2执行while语句时，flag[0]&amp;&amp;turn==1条件成立，使P2等待；当P1退出临界区时，将flag[0]置为0后，将使flag[0]&amp;&amp;turn==1条件不再成立，从而使P2进入临界区。这样既保证了“忙则等待”，又实现了“空闲让进”。当进程无法进入临界区时，上述4种算法均为忙式等待。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-1-3-利用硬件方法解决进程互斥问题" tabindex="-1"><a class="header-anchor" href="#◆-4-1-3-利用硬件方法解决进程互斥问题" aria-hidden="true">#</a> ◆ 4.1.3 利用硬件方法解决进程互斥问题</h4>
<blockquote>
<blockquote>
<p>利用硬件方法解决进程互斥问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在许多计算机提供了一些特殊的硬件指令，这些指令允许对一个字中的内容进行检测和修正，或交换两个字的内容等。可利用这些特殊的指令来解决临界区问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.利用Test-and-Set指令实现互斥</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了实现诸进程对临界资源的互斥访问，可为每个临界资源设置一个全局变量lock并赋予其初值为0，表示资源空闲。用TS指令将变量lock的状态记录于变量TS中，并将1赋予lock，这等效于关闭了临界区，使任何进程都不能进入临界区</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当进程退出临界区时，设置变量lock为0，以允许其他进程进入临界区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.利用Swap指令实现进程互斥</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Swap指令称为交换指令。在微机中该指令又称XCHG指令，用于交换两个字的内容，可描述如下：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在利用Swap实现进程互斥时，可为临界资源设置一个全局变量lock。其初值为0，在每个进程中再利用一个局部变量key。利用Swap指令实现进程互斥的循环进程可描述如下：[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用硬件指令能有效地实现进程互斥，但它却不能满足“让权等待”的准则，造成处理机时间的浪费，而且也很难将它用于解决较复杂的进程同步问题。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-1-4-信号量机制" tabindex="-1"><a class="header-anchor" href="#◆-4-1-4-信号量机制" aria-hidden="true">#</a> ◆ 4.1.4 信号量机制</h4>
<blockquote>
<blockquote>
<p>4.1.4　信号量机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号量机制是一种卓有成效的进程同步工具</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在信号量机制已被大量地应用于单处理机和多处理机系统以及计算机网络。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.记录型信号量机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在记录型信号量机制中，除了需要一个用于代表资源数目的整型变量value外，还有一个进程链表L，用于链接所有等待该信号量代表资源的进程。记录型信号量是由于采用了记录型的数据结构而得名的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号量除初始化外，仅能通过两个标准的原子操作wait（s）和signal（s）来访问。这两个操作很长时间以来一直被分别称为P、V操作。wait（s）和signal（s）是两个原子操作，因此，它们在执行时是不可中断的。亦即，当一个进程在修改某信号量时，没有其他进程可同时对该信号量进行修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>wait（s）和signal（s）操作可描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在记录型信号量机制中，s.value的初值表示系统中某类资源的数目，因而又称资源信号量，每次的wait操作意味着进程请求一个单位的资源，因此描述为s.value--；当s.value＜0时，表示资源已分配完毕，因而进程调用block原语，进行自我阻塞，放弃处理机并插入到信号量链表s.L中。该机制遵循了让权等待准则。此时s.value--的绝对值表示在该信号量链表中已阻塞进程的数目。每次signal操作，表示执行进程释放一个单位资源，故s.value++操作表示资源数目加1。若加1后仍是s.value&lt;=0，则表示在该信号量链表中仍有等待该资源的进程被阻塞，故还应调用wakeup原语，唤醒进程访问临界资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为使多个进程能互斥地访问某临界资源，需为该资源设置一信号量mutex，并设其初始值为1，然后将各进程的临界区CS置于wait（mutex）和signal（mutex）操作之间即可。这样，每个欲访问该临界资源的进程在进入临界区之前，都要先对mutex执行wait操作，若该资源此刻未被访问，本次wait操作成功，进程便可进入自己的临界区。这时若再有其他进程欲进入自己的临界区，由于对mutex执行wait操作必然失败，因而阻塞，从而保证了该临界资源被互斥地访问。当访问临界资源的进程退出临界区后，又应对mutex执行signal操作，释放该临界资源。故把信号量初始值为1的信号量又称互斥信号量。利用信号量实现进程互斥的进程可描述如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在利用信号量机制实现进程互斥时需要注意，wait（mutex）和signal（mutex）必须成对地出现。缺少wait（mutex）将导致系统混乱，不能保证对临界资源的互斥访问；而缺少signal（mutex）将会使临界资源永远不被释放，从而使因等待该资源而阻塞的进程不再被唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.信号量集机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）AND型信号量集机制。上述的进程互斥问题是针对进程之间要共享一个临界资源而言的。在有些应用场合，一个进程需要先获得两个或更多的共享资源后方能执行其任务。假定现有两个进程P和Q，它们都要求访问共享数据A和B。共享数据都应作为临界资源，可为这两个数据分别设置用于互斥的信号量Amutex和Bmutex，并令它们的初值为1，相应地在两进程中都要包含两个对Amutex和Bmutex的操作，即[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>若进程P和Q按下述次序交替地执行wait操作：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程P和Q处于僵持状态，在无外力作用时，它们都无法从僵持状态中解脱出来。称此时的进程P和Q进入死锁状态。当进程同时要求的共享资源越多时，发生进程死锁的可能性也就越大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>AND同步机制的基本思想是：将进程在整个运行过程中所需要的所有临界资源一次性全部分配给进程，待该进程使用完后再一起释放。只要尚有一个资源未能分配给该进程，其他所有可能为之分配的资源也不分配给它。亦即，对若干个临界资源的分配采取原子操作方式，要么全部分配到进程，要么一个也不分配。由死锁理论可知，这样就可能避免上述死锁情况的发生。为此，在wait操作中增加了一个AND条件，称为AND同步，或称为同时wait操作，即Swait（Simultaneous Wait）。其定义如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）一般“信号量集”机制。在记录型信号量机制中，wait（s）或signal（s）操作仅能对信号量施以增1或减1的操作，即每次只能获得或释放一个单位的临界资源。当一次需要n个某类资源时，便需要进行n次wait（s）操作，显然这是低效的。此外，在某些情况下，当资源数量低于某一下限值时便不予分配。因而，在每次分配之前都必须测试该资源的数量是否大于测试值t。基于上述两点可以对AND信号量机制进行扩充，形成一般化的“信号量集”机制。Swait操作可描述如下：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面讨论一般“信号量集”的几种特殊情况。①Swait（s，d，d）。此时在信号量集中只有一个信号量，但它允许每次申请d个资源，当现有资源数少于d时，不予分配。②Swait（s，1，1）。此时的信号量集已退化为一般的记录型信号量（s＞1时）或互斥信号量（s==1时）。③Swait（s，1，0）。这是一种很特殊且很有用的信号量。当s≥1时，允许多个进程进入某特定区；当s变为0后，将阻止任何进程进入特定区。换言之，它相当于一个可控开关。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-1-5-经典进程同步问题" tabindex="-1"><a class="header-anchor" href="#◆-4-1-5-经典进程同步问题" aria-hidden="true">#</a> ◆ 4.1.5 经典进程同步问题</h4>
<blockquote>
<blockquote>
<p>经典进程同步问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一系列经典的进程同步问题，其中较有代表性的是“生产者-消费者问题”“读者-写者问题”“哲学家进餐问题”和“嗜睡的理发师问题”等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.生产者-消费者问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）利用记录型信号量解决生产者-消费者问题。假定在生产者和消费者之间的公用缓冲池中有n个缓冲区，可利用互斥信号量mutex使诸进程实现对缓冲池的互斥使用；利用资源信号量empty和full分别表示缓冲池中空缓冲区和满缓冲区的数量。进一步假定这些生产者和消费者相互等效，只要缓冲池未满，生产者便可将产品送入缓冲池；只要缓冲池未空，消费者便可从缓冲池中取走一个产品。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在生产者-消费者问题中应注意以下几点：①在每个程序中用于实现互斥的wait（mutex）和signal（mutex）必须成对出现。②对资源信号量empty和full的wait和signal操作，同样需要成对出现，但它们是分别处于不同的进程中。例如，wait（empty）在生产者进程中，而signal（empty）则在消费者进程中。生产者进程若因执行wait（empty）而阻塞，则以后将由消费者进程将它唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③在每个程序中的多个wait操作顺序不能颠倒。应先执行对资源信号量的wait操作，然后再执行对互斥信号量的wait操作，否则可能引起进程死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>只有在缓冲全满或缓冲全空的情况下，指针out和in才会指向同一缓冲，其他时候均指向不同的缓冲。而在缓冲全满的时候，由于没有缓冲生产者就不能放产品，而缓冲全空时，由于无产品消费者就不能取走产品，于是生产者放产品和消费者取产品必然针对不同的缓冲操作，因而生产者放产品和消费者取产品就无需互斥执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）利用AND信号量解决生产者-消费者问题。对生产者-消费者问题也可利用AND信号量来解决，即用Swait（empty，mutex1）来代替wait（empty）和wait（mutex1）；用Ssignal（mutex1，full）来代替signal（mutex1）和signal（full）；用Swait（full，mutex2）代替wait（full）和wait（mutex2），以及用Ssignal（mutex2，empty）代替signal（mutex2）和signal（empty）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.读者-写者问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个数据文件或记录（统称数据对象）可被多个进程共享。其中，有些进程要求读，而另一些进程对数据对象进行写或修改。把只要求读的进程称为“读者进程”，进行写或修改的进程称为“写者进程”。允许多个读者进程同时读一个共享对象，因为读操作不会使数据文件混乱，但决不允许一个写者进程和其他读者进程或写者进程同时访问共享对象。所谓读者-写者问题（The Reader-Writer Problem）是只保证一个写者进程必须与其他进程互斥地访问共享对象的同步问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>考虑到读者-写者问题的读者和写者争夺访问共享数据时可以具有不同的优先权，写者问题有两种变形：一种称为第一类读者-写者问题，此问题读者优先；另一种称为第二类读者-写者问题，此问题写者优先。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）在第一类读者-写者问题中，当读者和写者争夺访问共享数据时，读者具有较高的优先访问权。该问题的具体描述如下：①如果当前无人访问数据，无论读者或写者欲访问数据都可直接进行访问。②如果已有一个读者正在访问数据，那么其他欲访问数据的读者可以直接进行访问，而当前欲访问数据的写者则必须无条件等待。③若某个写者正在访问数据，则当前欲访问数据的读者和写者均须等待。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④当最后一个结束访问的读者发现有写者正在等待时，则将其中的一个唤醒。⑤当某个写者结束访问数据时发现存在等待着，那么若此时只有写者处于等待时，则唤醒某个写者，若此时有读者和写者同时处于等待，则按照FIFO或其他原则唤醒一个写者或唤醒所有读者。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在该问题中的“读者优先”主要表现在：除了某个写者正在访问数据之外，任何情况下读者欲访问数据均可以直接进行访问，即只要存在读者正在访问数据，后续到达的那些欲访问数据的读者就无须估计此时是否已存在等待访问数据的写者，均直接进行访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）第二类读者-写者问题则不同，它试图使得写者具有较高的访问优先权。“写者优先”表现在：写者欲访问数据时，将尽可能早得让它访问。只要存在一个写者正在等待访问数据，那么任何后续欲访问的读者均不能访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>上述两种方法均能解决读者-写者问题，但均可能导致进程被“饿死”的现象。在第一种情况下，写者可能因为连续不断地出现新的读者而长期不能访问数据被“饿死”；在第二种情况下，读者可能因为连续不断地出现新的写者而长期不能访问数据被“饿死”。基于这种原因，人们又提出了另一些关于读者-写者问题的解决方法，例如在第一类读者-写者问题（第二类读者-写者问题）中，设定某个数值N，当连续有N个读者（写者）读（写）之后，都要先检查有无写者（读者）等待，若有则唤醒一个写者（所有读者）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面是用信号量机制接触解决第一类读者-写者问题的实现方法。第二类读者-写者问题在本节将用管程方式解决。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）利用记录型信号量解决读者-写者问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为实现读者进程与写者进程读或写时的互斥，设置一个互斥信号量mutex。又设置一个整型变量readcount以表示正在读的进程的数目。由于只要有一个读者进程在读便不允许写者进程去写，因此，仅当readcount==0时，表示尚无读者进程在读时读者进程才需要执行wait（mutex）操作。若wait（mutex）操作成功，读者进程便可去读，相应地readcount++。同理，仅当读者进程在执行了readcount--操作后其值为0时，才需执行signal（mutex）操作，以便让写者进程写。又因为readcount是一个可被多个读者进程访问的临界资源，因此应为它设置一互斥信号量rmutex。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）利用信号量集机制解决读者-写者问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这里的读者-写者问题与前面的略有不同，它增加了一条限制，即最多只允许RN个读者同时读。为此，又引入一个信号量L并赋予其初值为RN，通过执行Swait（L，1，1）操作来控制读者的数目。每当有一个读者进入时，都要先执行Swait（L，1，1）操作，使L的值减1。当有RN个读者进入后，L便减为0，第RN+1个读者要进入时必然会因Swait（L，1，1）操作失败而阻塞。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.哲学家进餐问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>该问题的描述是：有5个哲学家，他们的生活方式是交替地进行思考和进餐；哲学家们共用一张圆桌，分别坐在周围的5张椅子上；在圆桌上有5个碗和5支筷子，平时哲学家进行思考，饥饿时便试图取用其左、右最靠近他的筷子，只有在他拿到两支筷子时才能进餐；进餐完毕后，放下筷子继续思考。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）利用记录型信号量解决哲学家进餐问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>经分析可知，筷子是临界资源，在一段时间内只允许一个哲学家使用。因此，可以用一个信号量表示一支筷子，由5个信号量构成信号量数组。其描述如下：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>经分析可知，筷子是临界资源，在一段时间内只允许一个哲学家使用。因此，可以用一个信号量表示一支筷子，由5个信号量构成信号量数组。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所有信号量被初始化为1，第i个哲学家的活动可描述如下：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>哲学家饥饿时总是先拿他左边的筷子，即执行wait（chopstick[i]），成功后再去拿他右边的筷子，即执行wait（chopstick[（i+1）mod 5]），再成功后便可进餐。进餐毕，又先放下他左边的筷子，然后放下他右边的筷子。虽然上述解法可保证不会有两个相邻的哲学家同时进餐，但引起死锁是可能的。假如5个哲学家同时饥饿而各自拿起左边的筷子时，就会使5个信号量chopstick均为0；当他们试图去拿起右边筷子时都将因无筷子拿而无限期地等待。对于这样的死锁问题可采取以下几种解决方法：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①仅当哲学家的左、右两支筷子均可用时才允许他拿起筷子进餐。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②至多只允许4个哲学家同时进餐，以保证至少有一个哲学家能够进餐，最终总会释放出他所使用过的两支筷子，从而可使更多的哲学家进餐。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③规定奇数号哲学家先拿他左边的筷子，然后再去拿他右边的筷子；而偶数号哲学家则相反。按此规定，将是1、2号哲学家竞争1号筷子；3、4号哲学家竞争3号筷子。即5个哲学家都先竞争奇数号筷子，获得后，再去竞争偶数号筷子，最后总会有一个哲学家能获得两支筷子而进餐。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用第二种解决方法，利用记录型信号量机制来解决哲学家进餐问题描述如下，信号量mutex用来表示可以进餐的哲学家的数量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）利用AND信号量机制解决哲学家进餐问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在哲学家进餐问题中，要求每个哲学家先获得两个临界资源（筷子）后方能进餐，这在本质上就是前面所介绍的AND同步问题，故用AND信号量机制可获得最简洁的解法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.嗜睡的理发师问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个理发店由一个有N张沙发的等候室和一个放有一张理发椅的理发室组成。没有顾客要理发时，理发师便去睡觉。当一个顾客走进理发店时，如果等候室的所有沙发都已经占用，便离开理发店；否则，如果理发师正在为其他顾客理发，则该顾客就找一张空沙发坐下等待。如果理发师因无顾客正在睡觉，则由新到的顾客唤醒理发师为其理发。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分析顾客进程和理发师进程并发具体情况如下：（1）只有在理发椅空闲时，顾客才能做到理发椅上等待理发师理发，否则顾客便必须等待；只有当理发椅上有顾客时，理发师才可以开始理发，否则他也必须等待；可通过信号量customers和barbers来控制。（2）设置一个整型变量waiting来对理发店中等待在沙发上的顾客进行计数（最大为沙发的数量N），该变量将被多个顾客进程互斥地访问并修改，可通过一个互斥信号量mutext来实现。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-1-6-管程机制" tabindex="-1"><a class="header-anchor" href="#◆-4-1-6-管程机制" aria-hidden="true">#</a> ◆ 4.1.6 管程机制</h4>
<blockquote>
<blockquote>
<p>虽然信号量机制是一种既方便又有效的进程同步机制，但每个要访问临界资源的进程都必须自备同步操作wait（s）和signal（s），这就使大量的同步操作分散在各个进程中。这不仅给系统的管理带来麻烦，而且还会因同步操作的使用不当而导致系统死锁。在解决上述问题的过程中，产生了一种新的同步工具——管程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>把所有进程对某一种临界资源的同步操作都集中起来，构成一个所谓的“秘书”进程。凡要访问该临界资源的进程，都需要先报告“秘书”，由秘书来实现诸进程的同步。1973年，Hansan和Hoare又把“秘书”进程思想发展为管程概念，把并发进程间的同步操作分别集中于相应的管程中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统中的各种硬件资源和软件资源，均可用数据结构加以抽象的描述，即用少量信息和对该资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。当共享资源用共享数据结构表示时，资源管理程序可用对该数据结构进行操作的一组过程来表示。如资源的请求和释放过程request和release。这样一组相关的数据结构和过程一并称为管程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个管程定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>管程由3部分组成：①局部于管程的共享变量说明。②对该数据结构进行操作的一组过程。③对局部于管程的数据设置初值的语句。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>局部于管程的数据结构，仅能被局部于管程的过程所访问，任何管程外的过程都不能访问；反之，局部于管程的过程也仅能访问管程内的数据结构。由此可见，管程相当于围墙。它把共享变量相对它进行操作的若干过程围了起来，所有进程要访问临界资源时，都必须经过管程（相当于通过围墙的门）才能进入，而管程每次只准许一个进程进入管程，从而实现了进程互斥。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在利用管程实现进程同步时，必须设置两个同步操作原语wait和signal。当某进程通过管程请求临界资源而未能满足时，管程便调用wait原语使该进程等待，并将它排在等待队列上。仅当另一进程访问完并释放之后，管程又调用signal原语唤醒等待队列中的队首进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>引入条件变量condition。管程中对每个条件变量都需予以说明，其形式为：“condition x，y；”。该变量应置于wait和signal之前，即可表示为x.wait和x.signal。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>x.signal操作的作用是重新启动一个被阻塞的进程，但如果没有进程被阻塞，则x.signal操作不产生任何后果，这与信号量机制中的signal操作不同。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果有进程Q处于阻塞状态，当进程P执行了x.signal操作后，怎样决定哪个进程执行哪个进程等待，可采用下述两种方式处理。（1）P等待，直至Q离开管程或等待另一条件。（2）Q等待，直至P离开管程或等待另一条件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.利用管程解决生产者-消费者问题在利用管程方法来解决生产者-消费者问题时，首先便是为它们建立一个管程，并命名为Producer_Consumer。其中包含两个过程：（1）put（item）过程。生产者利用该过程将自己生产的产品投放到缓冲池中，并用整型变量count来表示在缓冲池中已有的产品数目。当count=&gt;n时，表示缓冲池已满，生产者等待。（2）get（item）过程。消费者利用该过程从缓冲池中取得一个产品，当count&lt;=0时，表示缓冲池中已无可用消息，消费者应等待。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.利用管程解决哲学家进餐问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.管程方法解决第二类读者-写者问题</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-进程通信" tabindex="-1"><a class="header-anchor" href="#◆-4-2-进程通信" aria-hidden="true">#</a> ◆ 4.2 进程通信</h3>
<blockquote>
<blockquote>
<p>4.2　进程通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程通信是指进程之间的信息交换。其所交换的信息量少则是一个状态或数值，多则是成千上万个字节。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程的互斥和同步可归结为低级通信。在进程互斥中，进程通过修改信号量向其他进程表明临界资源是否可用。在生产者-消费者问题中，生产者通过缓冲池将所生产的产品送给消费产者。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号量机制作为通信工具是不够理想的，主要表现在效率低和通信对用户不透明。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>高级进程通信是指用户可直接利用操作系统所提供的一组通信命令高效地传送大量数据的一种通信方式。在高级进程通信方式中，操作系统隐藏了进程通信的实现细节，或者说通信过程对用户是透明的。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-2-1-进程通信的类型" tabindex="-1"><a class="header-anchor" href="#◆-4-2-1-进程通信的类型" aria-hidden="true">#</a> ◆ 4.2.1 进程通信的类型</h4>
<blockquote>
<blockquote>
<p>高级通信机制可归结为3大类：共享存储器系统、消息传递系统以及管道通信系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.共享存储器系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在共享存储器系统中，相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过它们进行通信。共享存储器又可进一步分成两种类型。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）基于共享数据结构的通信方式。在这种通信方式中，要求诸进程共用某些数据结构，进程通过它们交换信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种方式下，公用数据结构的设置及对进程间同步的处理都是程序员的职责。操作系统只需提供共享存储器，这增加了程序员的负担。因此，这种通信方式是低效的，只适于传递少量数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）基于共享存储区的通信方式。为了传输大量数据，在存储器中划出一块共享存储区，诸进程可通过对共享存储区中的数据进行读写来实现通信。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种通信方式属于高级通信。进程在通信前，向系统申请共享存储区中的一个分区，并指定该分区的关键字；若系统已经给其他进程分配了这样的分区，则将该分区的描述符返回给申请者。接着，申请者把获得的共享存储分区连接到本进程上。此后，便可像读、写普通存储器一样地读、写公用存储分区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.消息传递系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程间的数据交换以消息为单位。程序员直接利用系统提供的一组通信命令（原语）来实现通信。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>消息传递系统又可分为以下两种方式：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）直接通信方式。发送进程直接将消息发送给接收进程并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）间接通信方式。发送进程将消息发送到某种中间实体中，接收进程从中取得消息。这种中间实体一般称为信箱，故这种通信方式又称信箱通信方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.管道通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>管道是指用于连接一个读进程和一个写进程以实现它们之间通信的共享文件，又称pipe文件。向管道（共享文件）提供输入的发送进程（写进程）以字符流形式将大量的数据送入管道；而接收管道输出的进程（读进程）可从管道中接收数据。由于发送进程和接收进程是利用管道进行通信的，故又称管道通信。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了协调双方的通信，管道通信机制必须提供以下3方面的协调能力：（1）互斥。（2）同步。（3）判断对方是否存在。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-2-2-直接通信和间接通信" tabindex="-1"><a class="header-anchor" href="#◆-4-2-2-直接通信和间接通信" aria-hidden="true">#</a> ◆ 4.2.2 直接通信和间接通信</h4>
<blockquote>
<blockquote>
<p>1.直接通信方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>直接通信方式是指发送进程利用操作系统所提供的发送命令直接把消息发送给目标进程。此时，要求发送进程和接收进程都以显示的方式提供对方的标识符。通常系统提供下述两条通信原语。[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以利用直接进程通信原语来解决生产者-消费者问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.间接通信方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>是指进程之间的通信需要通过作为某种共享数据结构的实体，该实体用来暂存发送进程发送给目标进程的消息；接收进程则从该实体中取出对方发送给自己的消息。通常把这种中间实体称为信箱。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统为信箱通信提供了若干条原语，用于信箱的创建、撤销和消息的发送、接收等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信箱可由操作系统创建，也可由用户进程创建。可把信箱分为以下3类：（1）私有信箱。（2）公用信箱。（3）共享信箱。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在利用信箱通信时，在发送进程和接收进程之间存在着下述4种关系：（1）一对一关系。可以为发送进程和接收进程建立一条专用的通信链路，使它们之间的交互不受其他进程的影响。（2）多对一关系。允许提供服务的进程与多个用户进程之间进行交互，也称为客户/服务器交互。（3）一对多关系。允许一个发送进程与多个接收进程进行交互，使发送进程可用广播方式向接收者发送消息。（4）多对多关系。允许建立一个公用信箱，让多个进程都能向信箱中投递消息，也可从信箱中取走属于自己的消息。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-2-3-消息缓冲队列通信机制" tabindex="-1"><a class="header-anchor" href="#◆-4-2-3-消息缓冲队列通信机制" aria-hidden="true">#</a> ◆ 4.2.3 消息缓冲队列通信机制</h4>
<blockquote>
<blockquote>
<p>消息缓冲队列通信机制在消息缓冲队列通信机制中，发送进程利用send原语将消息直接发送给接收进程，接收进程则利用receive原语接收消息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>消息缓冲队列通信机制中的数据结构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）消息缓冲区。在消息缓冲队列通信方式中，主要利用的数据结构是消息缓冲区</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）PCB中有关通信的数据项。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>发送进程在利用发送原语发送消息之前应首先在自己的内存空间设置一发送区a，把待发送的消息正文、发送进程标识符、消息长度等信息填入其中，然后调用发送原语，把消息发送给目标（接收）进程。发送原语首先根据发送区a中所设置的消息长度a.size来申请一缓冲区i，接着把发送区a中的信息复制到消息缓冲区i中。为了能将i挂在接收进程的消息队列mq上，应先获得接收进程的内部标识符j，然后将i挂在j.mq上。由于该队列属于临界资源，故在执行insert操作的前后要分别执行wait和signal操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>接收原语进程调用接收原语receive（b）从自己的消息缓冲队列mq中摘下第一个消息缓冲区i，并将其中的数据复制到以b为首址的指定消息接收区内。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-3-死锁" tabindex="-1"><a class="header-anchor" href="#◆-4-3-死锁" aria-hidden="true">#</a> ◆ 4.3 死锁</h3>
<blockquote>
<blockquote>
<p>4.3　死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>死锁。这是因为进程在运行时要使用资源，在一个进程申请与释放资源的过程中，其他进程也不断地申请资源与释放资源。由于资源总是有限的，因而异步前进的诸进程会因申请与释放资源顺序安排不当，造成一种僵局。另外，在进程使用某种同步或通信工具发送、接收时次序安排不当，也会造成类似现象。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-3-1-产生死锁的原因和必要条件" tabindex="-1"><a class="header-anchor" href="#◆-4-3-1-产生死锁的原因和必要条件" aria-hidden="true">#</a> ◆ 4.3.1 产生死锁的原因和必要条件</h4>
<blockquote>
<blockquote>
<p>1.死锁的定义</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现有P1、P2两个进程竞争R1、R2两个资源，每个进程都要独占使用这两个资源一段时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓死锁是指在多道程序系统中，一组进程中的每一个进程均无限期地等待被该组进程中的另一个进程所占有且永远不会释放的资源。出现这种现象则称系统处于死锁状态，简称死锁。处于死锁状态的进程称为死锁进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当死锁发生后，死锁进程将一直等待下去，除非有来自死锁进程之外的某种干预。系统发生死锁时，死锁进程的个数至少为两个；所有死锁进程都在等待资源，并且其中至少有两个进程已占有资源。系统发生死锁不仅浪费了大量的系统资源，甚至会导致整个系统崩溃，带来灾难性的后果。因为系统中一旦有一组进程陷入死锁，那么要求使用被这些死锁进程所占用的资源或者需要它们进行某种合作的其他进程就会相继陷入死锁，最终可能导致整个系统处于瘫痪状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.产生死锁的原因</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>产生死锁的原因可归结为两点：一是竞争资源，多个进程所共享的资源不足，引起它们对资源的竞争而产生死锁；二是进程推进顺序不当，进程运行过程中，请求和释放资源的顺序不当，而导致进程死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）竞争资源引起死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①可剥夺和非剥夺性资源。系统中有些资源是可剥夺的。例如处理机，可由优先权高的进程剥夺低优先级进程的处理机。又如内存区，可由存储器管理程序把一个进程从一个存储区移至另外一个存储区，即剥夺了该进程原来占有的存储区；甚至可将一进程从内存调出到外存上。可见，CPU和内存属于可剥夺资源。另一类资源是不可剥夺的，如磁带机、打印机等，当系统把某资源分配给某进程后，再不能强行收回，只能在进程用完后自动释放。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②竞争非剥夺性资源。若系统中只有一台打印机R1和一台读卡机R2，可供进程P1和P2共享。假定P1已占用了打印机R1，P2占用了读卡机R2，此时若P2继续要求打印机，P1继续要求读卡机，则P1与P2间便会形成僵局，两个进程都在等待着对方释放出自己所需的资源，但因它们都不能获得所需资源而不能继续推进，从而也不能释放出已占有的资源，以致进入死锁状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③竞争临时性资源。上述的打印机等资源是可顺序重复使用的资源，称为永久性资源。还有一种所谓的临时性资源，是指由一个进程产生，被另一个进程使用一短暂时间后便无用的资源，故也称之为消耗性资源。它同样也可能引起死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）进程推进顺序不当引起死锁。由于进程具有异步特性，这就使进程按下述两种顺序向前推进。①进程推进顺序合法。在进程P1和P2并发执行时，如果按照下述顺序推进：P1Request（R1），P1Request（R2），P1Release（R1），P1Release（R2），P2Request（R2），P2Request（R1），P2Release（R2），P2Release（R1）。两个进程可顺利完成。②进程推进顺序非法。若并发进程Pl和P2按P1Request（R1），P2Request（R2），P1Request（R2）的顺序推进，它们将进入不安全区内，此时P1保持了资源R1，P2保持了资源R2，系统处于不安全状态。因为，两进程再向前推进，便可能产生死锁。例如：当P1运行到PlRequest（R2）时，将因R2已被P2占用而阻塞；当P2运行到P2Request（R1）时，也将因Rl已被Pl占用而阻塞，于是产生了进程死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>产生死锁的4个必要条件是：（1）互斥条件。进程要求对所分配的资源进行排他性控制，即在一段时间内某资源仅为一进程所占有。（2）请求和保持条件。当进程因请求资源而阻塞时，对已获得的资源保持不放。（3）不剥夺条件。进程已获得的资源在未使用完之前，不能被剥夺，只能在使用完时由自己释放。（4）环路等待条件。在发生死锁时，必然存在一个进程-资源的环形链，即进程集合{P1，P2，…，Pn}中的P1正在等待一个P2占用的资源，P2正在等待一个P3占用的资源，……，Pn正在等待一个P1占用的资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前用于解决死锁的办法有以下4种：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）预防死锁。通过设置某些限制条件，以破坏产生死锁的4个必要条件中的一个或几个，防止发生死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）避免死锁。不需预先采取各种限制措施去破坏产生死锁的必要条件，而是在资源的动态分配过程中，使用某种方法去防止系统进入不安全状态，从而避免了死锁的发生。这种办法只须预先加以较弱的限制条件，这样可获得较高的资源利用率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）检测死锁。检测死锁方法允许系统运行过程中发生死锁。但通过系统所设置的检测机构，可以及时检测出死锁的发生，并精确地确定与死锁有关的进程和资源，然后采取适当措施，从系统中消除所发生的死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）解除死锁。解除死锁是与检测死锁相配套的一种设施，用于将进程从死锁状态下解脱出来。常用的方法是撤销或挂起一些进程，以便释放出一些资源，再将它们分配给已处于阻塞状态的进程，使之转为就绪状态可以继续运行。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-3-2-预防死锁" tabindex="-1"><a class="header-anchor" href="#◆-4-3-2-预防死锁" aria-hidden="true">#</a> ◆ 4.3.2 预防死锁</h4>
<blockquote>
<blockquote>
<p>预防死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.摒弃“请求和保持”条件为了摒弃这一条件，系统要求所有进程一次性地申请其所需的全部资源。若系统有足够的资源分配给一进程时，便一次把所有其所需的资源分配给该进程。这样，该进程在整个运行期间，便不会再提出任何资源要求，从而使请求条件不成立。但在分配时只要有一种资源要求不能满足，则已有的其他资源也全部不分配给该进程，该进程只能等待。由于等待期间的进程不占有任何资源，破坏了保持条件，从而可以避免发生死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.摒弃“不剥夺”条件</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>该策略规定：对于一个已保持了某些资源的进程，若新的资源要求不能立即得到满足，它必须释放已保持的所有资源，以后再需要时重新申请。这意味着：一个进程已占有的资源在运行过程中可能暂时地释放，或者说被剥夺，从而摒弃了“不剥夺条件”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种防止死锁的策略实现起来比较复杂，而且要付出很大代价。这是因为一个资源在使用一段时间后被释放，可能会造成前阶段工作的失效，即使采取某些防范措施，也还会使前后两次运行的信息不连续。此外，该策略还可能由于反复地申请和释放资源，使进程的执行无限推迟。这不仅延长了进程的周转时间，还增加了系统开销，又降低了系统吞吐量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.摒弃“环路等待”条件</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在该策略中，将所有的资源按类型进行线性排队，并赋予不同的序号。例如，令输入机的序号为1、打印机为2、穿孔机为3、磁带机为4、磁盘为5。所有进程对资源的请求，必须严格按资源序号递增的次序提出，这样在所形成的资源分配图中不可能再出现环路，因而也就摒弃了“环路等待”条件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种防止死锁的策略较之前两种策略，不论是资源利用率还是系统吞吐量都有显著的改善。但也存在下述严重问题：（1）为系统中各种资源类型分配的序号必须相对稳定，这就限制了新设备类型的增加。（2）尽管在为资源类型分配序号时，已考虑到大多数程序实际使用这些资源的顺序，但也经常会发生程序使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费，如某进程先用磁带机，后用打印机，但按系统规定，它应先申请打印机，后申请磁带机，致使打印机长期闲置（分到进程后）。（3）为方便用户，系统对用户编程所施加的限制条件应尽量少些，然而这种按规定次序申请资源的方法必然会限制用户简单、自由地编程。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-3-3-避免死锁" tabindex="-1"><a class="header-anchor" href="#◆-4-3-3-避免死锁" aria-hidden="true">#</a> ◆ 4.3.3 避免死锁</h4>
<blockquote>
<blockquote>
<p>4.3.3　避免死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.安全与不安全状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在避免死锁的方法中，允许进程动态地申请资源，系统在进行资源分配之前，先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，进程等待。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓安全状态，是指系统能按某种进程顺序，如&lt;P1，P2，…，Pn&gt;（称&lt;P1，P2，…，Pn&gt;序列为安全序列），来为每个进程分配其所需资源，直至最大需求，使每个进程都可顺利完成。若系统不存在这样一个安全序列，则称系统处于不安全状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.银行家算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最有代表性的避免死锁的算法是Dijkstra的银行家算法。这个得名是由于该算法能用于银行系统现金贷款的发放。为实现银行家算法，系统中必须设置若干个数据结构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）可利用资源向量Available。它是一个具有m个元素的数组，其中的每一个元素代表一类可利用的资源数目，其初始值为系统中所配置的该类全部可用资源的数目。其数值随该类资源的分配与回收而动态改变。如果Available[j]=k，表示系统中现有R</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）最大需求矩阵Max。它是一个n×m的矩阵，定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max（i，j）=k，表示进程i需要Rj类资源的最大数目为k。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）分配矩阵Allocation。它是一个n×m的矩阵，定义了系统中每一类资源当前已分配给每一个进程的资源数。如果Allocation（i，j）=k，表示进程i当前已分得Rj类资源的数目为k。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）需求矩阵Need。它是一个n×m的矩阵，用以表示每一个进程尚需的各类资源数，如果Need[i，j]=k，表示进程i还需要Rj类资源k个，方能完成其任务。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-3-4-检测死锁" tabindex="-1"><a class="header-anchor" href="#◆-4-3-4-检测死锁" aria-hidden="true">#</a> ◆ 4.3.4 检测死锁</h4>
<blockquote>
<blockquote>
<p>检测死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.资源分配图</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.死锁定理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.死锁检测算法</p>
</blockquote>
</blockquote>
<h4 id="◆-4-3-5-解除死锁" tabindex="-1"><a class="header-anchor" href="#◆-4-3-5-解除死锁" aria-hidden="true">#</a> ◆ 4.3.5 解除死锁</h4>
<blockquote>
<blockquote>
<p>4.3.5　解除死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的两种方法是：（1）剥夺资源。从其他进程剥夺足够数量的资源给死锁进程，以解除死锁状态。（2）撤销进程。最简单的撤销进程的方法是使全部死锁进程都被清除掉；稍为温和一点的方法是按照某种顺序逐个地撤销进程，直至有足够的资源可用，死锁状态消除为止。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-4-linux进程间通信" tabindex="-1"><a class="header-anchor" href="#◆-4-4-linux进程间通信" aria-hidden="true">#</a> ◆ 4.4 Linux进程间通信</h3>
<blockquote>
<blockquote>
<p>4.4　Linux进程间通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般情况下，系统运行时，系统中都有大量的进程，各个进程之间并不是相互独立的，在一些进程之间常常要传递信息。但是，每个进程都有自己的地址空间，不允许其他进程随意进入。因此，就必须有一种机制既能保证进程之间的通信，又能保证系统的安全。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-4-1-linux进程通信的基本概念" tabindex="-1"><a class="header-anchor" href="#◆-4-4-1-linux进程通信的基本概念" aria-hidden="true">#</a> ◆ 4.4.1 Linux进程通信的基本概念</h4>
<blockquote>
<blockquote>
<p>在Linux中，整个内存空间有用户空间和系统空间之分。在系统空间中由于各个线程的地址空间都是共享的，即一个线程能够随意访问kernel中的任意地址，所以无须进程通信机制的保护。而在用户空间中，每个进程都有自己的进程空间，一个进程为了与其他进程通信，必须陷入到有足够权限访问其他进程空间的kernel中，从而与其他进程进行通信。此时就用到了进程通信机制。在Linux系统中进程间通信主要有3种手段：消息队列、共享内存和信号量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程通信的一些基本概念</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.进程通信对象标识符</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在kernel中，对每一类IPC对象都有一个非负整数来索引。每类IPC结构的具体实例的标识符是由kernel中的一个变量xxx_seq（xxx为msg、shm或sem）来确定的。具体的确定方法如下：首先在系统初始化时，将变量xxx_seq置为0，然后当生成一个新的IPC对象时，就将xxx_seq的值赋给IPC对象中的seq域；当释放一个IPC对象时，就将变量xxx_seq的值不断加1，直到达到最大值，然后又置为0。而IPC对象的标识符，是该对象的seq值乘以该类对象的最大数量，再加上该对象在kernel中数组中的下标。这样的好处是：当一个进程试图访问—个已经被释放的IPC对象时，由于该对象的seq值已递增了1，所以按上面的方法计算出的对象标识符肯定与输入的对象标识符不同，同时，它也不可能是该类对象数组中的下一个对象，这样就保证了进程通信的安全。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.进程通信对象的码</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.Permission Struct</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.函数ipcperms</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>函数功能：检查访问IPC对象的进程是否有足够的权限，参数*IPCp是IPC对象所允许的权限，而flag中的各个位表示了进程所需要的权限。当权限检查被通过时，返回0，否则返回-1。在进程通信的许多地方都用到了这个函数，通过这个函数的权限检查，可以有效地防止越权操作，从而保证了进程通信的安全。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.命令ipcs</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux中一个重要的命令为ipcs，通过它可以观察系统中的IPC对象。输入ipcs命令，会看见如下输出信息：[插图]在这里可以看见系统中有一个共享内存段和一个消息队列，没有信号量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.命令iperm</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux中另一个重要的命令是iperm，这个命令用来从kernel中删除IPC对象。例如输入ipcs命令会看见上一页中的输出结果，如果接着再输入命令“iperm msg 0”，系统会删除资源。这时再输入ipcs，输出结果如下：[插图]在这里可以看见，一个消息队列确实被删除了。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-4-2-linux消息队列" tabindex="-1"><a class="header-anchor" href="#◆-4-4-2-linux消息队列" aria-hidden="true">#</a> ◆ 4.4.2 Linux消息队列</h4>
<blockquote>
<blockquote>
<p>在进程通信机制中，如果两个进程想通过消息队列来通信，那么发送消息的进程就将待发送的消息挂到某个消息队列上，而接收消息的进程则从该队列上取出它想要的消息。这样两个进程就能够通信了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>消息队列是存储在kernel中的链表，它的结点是消息。每个消息队列都由一个消息队列标识符来确定。创建或打开一个消息队列可以通过系统调用msgget（…）来完成。在kernel中有一个消息队列的数组，系统中消息队列的最大数目不能超过数组的容量，数组的大小定义在宏MSGMNI中。当一个进程想发送消息时，它通过系统调用msgsnd向数组中的某个消息队列中添加一个消息；而当一个进程想接收消息时，它通过系统调用msgrcv从数组的某个消息队列中取出满足它要求的消息。一个进程所能发送的消息的大小是有限制的，这定义在宏MSGMAX中。一个消息队列所能存放的消息也是有限的，这定义在宏MSGMNB中。当进程从消息队列中取消息时，不必遵循先入先出的顺序。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-4-3-linux的信号量" tabindex="-1"><a class="header-anchor" href="#◆-4-4-3-linux的信号量" aria-hidden="true">#</a> ◆ 4.4.3 Linux的信号量</h4>
<blockquote>
<blockquote>
<p>Linux的信号量</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号量可以看作共享资源的计数器，它控制多个进程对共享资源的访问，常常被当作锁来用，防止一个进程访问另一个进程正在使用的资源。一个进程为了获取共享资源，必须完成以下3步：（1）测试控制共享资源的信号量。（2）如果信号量的值大于0，那么这个进程就能使用共享资源。信号量的值要被减1，表明它已经使用了一个共享资源。（3）如果信号量的值小于0，那么这个进程就要进入睡眠状态。一直等到该信号量的值大于0，即当该进程被唤醒时，它返回第—步。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当一个进程使用完一个共享资源后，控制该共享资源的信号量要加1。如果此时有处于睡眠状态的进程正在等待此共享资源，那么这些进程将被唤醒。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了正确实施对信号量的操作，对信号量值的测试和对信号量值的减运算都必须是一个原子操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号量的一个常见形式称为二进制信号量。它控制一个单一的资源，它的初始值为1。但是，一个信号量的初始值可以是任意正整数，这个正整数表示可用的共享资源有多少个。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Linux系统的信号量要比上面所说的信号量复杂。它有3个不同于上述信号量的特点：（1）在Linux系统中信号量总是成组使用的，也就是说，为信号量赋值时，要对这一组信号量中的每一个赋值。当创建一个信号量组时，要指定信号量的数量。（2）信号量的创建（semget）和信号量的初始化（semctl）是相互独立的。这是个致命的弱点，因为不能用一个原子操作来同时完成创建一个信号量组并为其赋初值的工作。（3）必须考虑到一个进程在没有释放分配给它的信号量时就结束了这样一种情况。在这种情况下，使用了undo结构。此结构将在后面具体讲述。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-4-4-共享内存" tabindex="-1"><a class="header-anchor" href="#◆-4-4-4-共享内存" aria-hidden="true">#</a> ◆ 4.4.4 共享内存</h4>
<blockquote>
<blockquote>
<p>共享内存可以看作对一段内存区域的映射，它将一段内存区域映射到多个进程的地址空间，从而使得这些进程能够共享这一内存区域。共享内存是进程通信中最快的一种方法，因为数据不需要在进程间复制，而可以直接映射到各个进程的地址空间中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在共享内存中要注意的一个问题是：当多个进程对共享内存区域进行访问时，要注意这些进程之间的同步问题。例如，如果server正在向共享内存区域中写数据，那么client进程就不能访问这些数据，直到server全部写完之后，client才可以访问。为了实现进程间的同步问题，通常使用前面介绍过的信号量来实现这一目标。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个共享内存段可以由一个进程创建，然后由任意共享这一内存段的进程对它进行读写。当进程间需要通信时，一个进程可以创建一个共享内存段，然后需要通信的各个进程就可以在信号量的控制下保持同步，在这里交换数据，完成通信。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-4-5-linux系统调用与进程通信" tabindex="-1"><a class="header-anchor" href="#◆-4-4-5-linux系统调用与进程通信" aria-hidden="true">#</a> ◆ 4.4.5 Linux系统调用与进程通信</h4>
<blockquote>
<blockquote>
<p>Linux系统调用与进程通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>介绍了进程通信的3种方法，用户进程是怎样使用这3种方法的呢？前面介绍的一些关键函数在它的原型中，在函数名的开始处都有“sys_”这样的字符串前缀，它表示这个函数是一个系统调用。由此可以看出进程通信是通过系统调用来完成的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>介绍系统调用与进程通信的关系。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当用户进程想进行进程通信时，它调用系统调用函数sys_IPC，同时传入必要的参数。当系统调用执行时，一个0x80的中断首先被执行，此时用户进程进入了kernel。在kernel中，有一个系统调用表，表的内容是各个系统调用程序的入口地址，而进程通信系统调用函数sys_IPC在表中是第116个表项。当用户进程进入kernel后，首先，一些与进行系统调用进程有关的环境变量被压栈保存起来，然后，系统从系统调用表的r第116个元素中取出进程通信函数的入口地址，跳转到函数sys_IPC的起始处。函数sys_IPC根据用户传入的参数，用若干case语句决定具体调用前面介绍的哪个关键函数。当调用的函数执行完成后，系统将前面保存的环境变量恢复，然后将函数的返回值返回给进行系统调用的函数。这样用户进程就完成了进程通信。</p>
</blockquote>
</blockquote>
<h4 id="◆-4-4-6-进程通信信号" tabindex="-1"><a class="header-anchor" href="#◆-4-4-6-进程通信信号" aria-hidden="true">#</a> ◆ 4.4.6 进程通信信号</h4>
<blockquote>
<blockquote>
<p>进程通信信号</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>信号是UNIX系统中最古老的进程间通信机制之一，它主要用来向进程发送异步的事件信号。键盘中断可能产生信号，而浮点运算溢出或者内存访问错误等也可产生信号，shell通常利用信号向子进程发送作业控制命令。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有几个常用到的概念需要在此进行解释：（1）产生信号。当一个能导致该信号的事件发生时，就可以说该信号被产生了。（2）发送信号。每个信号都有其处理函数，当一个信号的处理函数被执行时，就说这个信号被发送到一个执行处理函数的进程。（3）挂起信号。在信号产生和信号发送之间的这段时间内，称信号处于挂起状态。（4）阻塞信号。有时候，有的进程并不想对发送给它的信号做出处理，那么这个信号将保持在挂起状态，这时，称这个进程阻塞了这个信号。如果对这个信号的处理不是将其忽略，那么阻塞状态将一直保持下去，除非发生了下面两个事件之一——解除了对该信号的阻塞或将对该信号的处理过程改为忽略该信号。</p>
</blockquote>
</blockquote>
<h3 id="◆-习题-3" tabindex="-1"><a class="header-anchor" href="#◆-习题-3" aria-hidden="true">#</a> ◆ 习题</h3>
<blockquote>
<blockquote>
<p>习题1.什么叫临界资源？什么叫临界区？对临界区的使用应符合哪些准则？2.并发执行的进程在系统中通常表现为几种关系？各是在什么情况下发生的？3.当进程对信号量s执行wait、signal操作时，s的值发生变化，当s&gt;0、s=0和s&lt;0时，其物理意义是什么？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.若信号量s表示某一类资源，则对s执行wait、signal操作的直观含义是什么？5.在用wait、signal操作实现进程通信时，应根据什么原则对信号量赋初值？6.假设一条河上有一座由若干个桥墩组成的桥，若一个桥墩一次只能站一个人，想要过河的人总是沿着自己过河的方向前进而不后退，且没有规定河两岸的人应该谁先过河。显然，如果有两个人P1和P2同时从两岸沿此桥过河，就会发生死锁。请给出解决死锁的各种可能的方法，并阐述理由。7.有一容量为100的循环缓冲区，有多个并发执行进程通过该缓冲区进行通信。为了正确地管理缓冲区，系统设置了两个读写指针分别为IN、OUT。IN和OUT的值如何反映缓冲区为空还是满的情况？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>8.有一阅览室，共有100个座位。为了很好地利用它，读者进入时必须先在登记表上进行登记。该表表目设有座位号和读者姓名，离开时再将其登记项摒除。试问：（1）为描述读者的动作，应编写几个程序？应设几个进程？它们之间的关系是什么？（2）试用信号量机制描述进程之间的同步算法。9.什么是死锁？10.死锁产生的4个必要条件是什么？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>11.死锁的4个必要条件是彼此独立的吗？试给出最少的必要条件。12.什么是银行家算法？13.假定系统有4个同类资源和3个进程，进程每次只申请或释放一个资源。每个进程最大资源需求量为2。请问，这个系统为什么不会发生死锁？14.假定系统有N个进程共享M个单位资源。进程每次只申请或释放一个资源。每个进程的最大需求不超过M。所有进程的需求总和小于M+N。为什么这种情况下绝不会发生死锁？试证明。15.一个计算机系统有6个磁带驱动器和n个进程。每个进程最多需要两个磁带驱动器。当n为什么值时，系统不会发生死锁？16.考虑某一系统，它有4类资源R1、R2、R3、R4，有5个并发进程P0、P1、P2、P3、P4。请按照银行家算法回答下列问题：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）当前资源剩余向量、各进程的最大资源请求和已分配的资源矩阵如表4-6和表4-7所示，计算各进程的需求向量组成的矩阵。（2）系统当前是处于安全状态吗？（3）当进程P2申请的资源分别为（0，3，2，0）时，系统能立即满足吗？表4-6　当前资源剩余向量[插图]表4-7　资源矩阵[插图]17.考虑这样一种资源分配策略：对资源的申请和释放可以在任何时刻进行。如果一个进程的资源得不到满足，则考查所有由于等待资源而被阻塞的进程，如果它们有申请进程所需要的资源，则把这些资源取出分给申请进程。例如，考虑一个有3类资源的系统，Available=（4，2，2）。进程A申请（2，2，1），可以满足；进程B申请（1，0，1），可以满足；若进程A再申请（0，0，1），则被阻塞（无资源可分）。此时，若进程C申请（2，0，0），它可以分得剩余资源（1，0，0），并从进程A已分得的资源中获得一个资源，于是，进程A的分配向量变成：Available=（1，2，1），而需求向量变成：Need=（1，0，1）。（1）这种分配方式会导致死锁吗？若会，举一个例子；若不会，说明死锁的哪一个必要条件不成立。（2）这种分配方式会导致某些进程的无限等待吗？18.设系统中每类资源的资源数为1，写出时间复杂度为O（n2）的死锁检测算法（n是进程个数）。19.有3个进程P1、P2和P3并发执行。进程P1需使用资源R3和R1，进程P2需使用资源R1和R2，进程P3需使用资源R2和R3。（1）若对资源分配不加限制，会发生什么情况，为什么？（2）为保证进程能执行到结束，应采用怎样的资源分配策略？</p>
</blockquote>
</blockquote>
<h4 id="◆-5-1-1-存储体系" tabindex="-1"><a class="header-anchor" href="#◆-5-1-1-存储体系" aria-hidden="true">#</a> ◆ 5.1.1 存储体系</h4>
<blockquote>
<blockquote>
<p>计算机系统中存储器一般分为主存储器和辅助存储器两级。主存储器简称主存，又称内存，它由顺序编址的单元（通常为字或字节）所组成，是处理机直接存取指令和数据的存储器。它速度快，但容量有限。辅助存储器简称辅存，又称外存，它由顺序编址的“块”所组成，每块包含若干个单元，寻址与交换均以块为单位进行，处理机不能直接访问它，须经过专门的启动I/O过程与内存交换信息。它存取速度较慢，但容量远大于内存。实际上，现代计算机系统中用户的数据（或信息）都是保存在外存中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储管理主要是对内存的管理，同时也涉及对内存和外存交换信息的管理。内存可以分成系统区和用户区两部分，系统区用来存储操作系统等系统软件，用户区用于分配给用户程序使用，存储管理实际上是对用户区的管理。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-1-2-存储管理的目的" tabindex="-1"><a class="header-anchor" href="#◆-5-1-2-存储管理的目的" aria-hidden="true">#</a> ◆ 5.1.2 存储管理的目的</h4>
<blockquote>
<blockquote>
<p>存储管理要实现的目的是为用户提供方便、安全和充分大的存储空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>方便是指将逻辑地址和物理地址分开，用户只在各自的逻辑地址空间编写程序，不必过问物理空间和物理地址的细节，地址的转换由操作系统自动完成；安全是指同时驻留在内存的多个用户进程相互之间不会发生干扰，也不会访问操作系统所占有的空间；充分大的存储空间是指利用虚拟存储技术，从逻辑上对内存空间进行扩充，从而可以使用户在较小的内存里运行较大的程序。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-1-3-存储管理的任务" tabindex="-1"><a class="header-anchor" href="#◆-5-1-3-存储管理的任务" aria-hidden="true">#</a> ◆ 5.1.3 存储管理的任务</h4>
<blockquote>
<blockquote>
<p>存储管理是计算机操作系统的一部分，它负责完成逻辑地址到物理地址的转换，对内存进行分配与回收，实现内存的共享和保护，通过软件手段实现对内存容量的扩充。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.地址转换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）逻辑地址。用户源程序经过编译或汇编后形成的目标代码中出现的地址，通常为相对地址形式，即规定目标程序的首地址为零，而其他指令中的地址部分都是相对于首地址而定的，这里的地址通常称为逻辑地址，也称相对地址。就用户程序而言，其逻辑地址构成的空间称为逻辑地址空间，或简称地址空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）物理地址。内存中各存储单元的编号称为物理地址，物理地址也称绝对地址。就系统而言，内存的全部物理单元的集合称为内存空间，也称物理空间或绝对空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机执行指令时是按物理地址进行的。因此，在程序调度选中某一用户程序，将该程序装入内存并为之创建进程，在进程运行之前必须把该进程指令中的逻辑地址转换成内存中的物理地址，才能得到信息在内存中的真实存放位置，这个过程称为地址转换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.内存的分配和回收</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当用户程序要装入内存创建进程时，需向操作系统提出申请，操作系统按一定策略分配存储空间。操作系统必须随时掌握内存空间的使用情况，譬如可以设计一张内存分配表记录各内存区域的分配情况。当用户提出存储申请时，操作系统按一定策略从表中选出符合申请者要求的空闲区进行分配，并修改表内有关项，称为内存的分配；若某进程执行完毕，需归还内存空间时，操作系统负责及时收回相关存储空间，并修改表中有关项，称为内存的回收。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.内存的地址保护</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在多道程序环境下，内存中不仅有多个用户进程，而且还有系统进程。为避免内存中若干个进程相互干扰，尤其是防止用户进程侵犯系统进程所在的内存区域，必须对内存采取保护措施，以保证各个进程都在自己所属的内存空间中或在公共区域中工作，互不发生干扰。内存的地址保护功能一般由硬件和软件配合实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当要访问内存的某一单元时，首先由硬件检查是否允许访问。若允许，则执行；否则产生中断，转由操作系统进行相应的处理。重要的是：对于不同结构的存储器，所采用的保护方法各不相同。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.内存的共享</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）共享内存资源。在多道程序环境下，多个程序同时装入内存的不同区域，共同占用一个存储器。（2）共享内存的某些区域。在同一内存中的若干进程有共同的程序段或数据段时，将这些共同的部分存放于同一内存区域中，该区域可同时被若干进程访问，从而可节省大量内存空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.内存的扩充</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>内存容量是有限的，当内存资源不能满足用户程序需求时，例如当有一个比内存容量还要大的程序要运行时，或为使多个用户程序在内存中并发运行时，就需要由操作系统利用外存对内存容量进行扩充。这个过程对用户是透明的（用户感知不到）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这里所说内存的扩充不是硬件设备上的扩充，而是用虚拟技术来实现的逻辑上的扩充，即虚拟存储概念。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-1-4-程序的连接和装入" tabindex="-1"><a class="header-anchor" href="#◆-5-1-4-程序的连接和装入" aria-hidden="true">#</a> ◆ 5.1.4 程序的连接和装入</h4>
<blockquote>
<blockquote>
<p>在多道程序环境下，程序要运行必须为之创建进程，而创建进程首先要将程序和数据装入内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将一个用户源程序变为一个可在内存中执行的程序，通常需要经过以下几个步骤：首先是编译，由编译程序将用户源代码编译成若干个目标模块；其次是连接，由连接程序将编译后形成的目标模块以及它们所需要的库函数连接在一起，形成一个装入模块；最后是装入，由装入程序将装入模块装入内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>源程序经过编译后，得到一个或多个目标模块。对于某些无须连接的单个目标模块，该目标模块也就是装入模块，可以直接装入内存；对于其他情况来说，则需要利用连接程序将目标模块和它们所需要的库函数连接，形成装入模块。根据连接时间的不同，可把连接分成3种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）静态连接方式。在程序运行以前，将各个目标模块及它们所需要的库函数，连接成一个完整的装入模块，又称可执行文件，通常不再拆开。这种事先进行连接以后不再拆开的连接方式称为静态连接方式。静态连接方式需要解决两个问题：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①对目标模块中相对地址进行修改。在由编译程序所产生的所有目标模块中，使用的都是相对于本模块起始地址0的相对地址。在连接成一个装入模块后，需要把地址更改为相对于装入模块起始地址0的新的相对地址。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②变换目标模块中外部调用符号。将每个目标模块中所用的外部调用符号也都变换为相对于装入模块起始地址0的相对地址</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）装入时动态连接。用户源程序经编译后所得的目标模块在装入内存时，边装入边连接，即在装入一个目标模块时，如果发生一个外部模块调用事件，将引起装入程序去找出相应的外部目标模块，并将它装入内存，进行连接。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>装入时动态连接方式有两个优点：①便于修改和更新。对于静态连接装配在一起的装入模块，如果需要修改或者更新其中的某一个模块，则需要重新将装入模块打开。这样不仅效率很低，而且有时是做不到的。如果采用装入时动态连接方式，由于各个目标模块是分开存放的，所以修改或者更新某个目标模块是一件非常容易的事情。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②便于实现对目标模块的共享。在采用静态连接方式时，每个应用模块必须含有该目标模块的备份，而无法实现共享。但采用装入时动态连接方式时，操作系统则很容易将一个目标模块连接到几个应用模块上，实现多个应用程序对该目标模块的共享。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）运行时动态连接。在许多情况下，应用程序在运行时，每次要运行的模块可能是不相同的。但由于事先无法知道本次要运行哪些模块，故只能将所有可能要运行的模块全部装入内存，并在装入时连接在一起。这样做显然是低效的，因为有些目标模块往往不运行。比如，用作错误处理的目标模块，如果在整个程序运行过程中都不出现错误，则显然就不会用到该模块。另外，程序中存在着大量的分支结构，所以在程序的一次运行中，肯定有些目标模块是运行不到的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对上述装入时连接方式进行改进，即得运行时动态连接方式。这种连接方式是将对某些模块的连接推迟到执行时才进行。在执行过程中，当发现一个被调用模块尚未调入内存时，立即由操作系统去找到该模块并装入内存，再把它连接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被连接到装入模块上，这样不仅可以提高装入的速度，而且可以节省大量的内存空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将一个装入模块装入内存时，需要进行地址转换。程序的装入可以有绝对装入方式、可重定位装入方式和动态运行时装入方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）绝对装入方式。在绝对装入方式中，逻辑地址转换成物理地址的过程发生在程序编译或汇编时。将程序装入内存时，按照程序模块中的地址将程序装入，也就是说，程序必须装入内存的固定位置。装入后，由于程序中的逻辑地址与实际物理地址完全相同，故不需对程序和数据的地址进行修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>程序中使用的物理地址可以在编译或汇编时给出，也可以由程序员直接给出，但由程序员直接给出绝对地址时，不仅要求程序员熟悉内存的使用情况，而且一旦程序或数据被修改后，如插入新的或删除老的程序或数据，可能要改变程序中的所有地址。因此，通常是宁可在程序中采用符号地址，然后在编译或汇编时，将这些符号地址再转换为物理地址。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）可重定位装入方式。在重定位装入方式中，逻辑地址转换成物理地址的过程发生在程序装入内存时进行。这样就可以根据内存的使用情况，将程序装入内存的适当位置，解决了绝对装入方式只能将目标模块装入到内存中事先指定位置的缺点，适用于多道程序环境。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）动态运行时装入方式。在动态运行时装入方式中，逻辑地址转换成物理地址的过程推迟到程序真正执行时。可重定位装入方式可以将装入模块装入内存中的任何位置，但不允许程序在内存中移动位置。因为程序若在内存中移动，意味着它的物理位置发生了变化，这时必须对程序和数据的物理地址进行修改后方能运行。然而，在程序运行过程中，实际的情况是，它在内存中的位置可能经常要改变，此时就应采用动态运行时装入方式。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-1-5-存储管理方式的分类" tabindex="-1"><a class="header-anchor" href="#◆-5-1-5-存储管理方式的分类" aria-hidden="true">#</a> ◆ 5.1.5 存储管理方式的分类</h4>
<blockquote>
<blockquote>
<p>存储管理方式可以分为连续分配方式和离散分配方式两大类。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>连续分配方式可以分为单一连续分配方式和分区分配方式，分区分配方式又可分为固定分区和可变分区两种方式。离散分配方式有分页存储器管理方式、分段存储器管理方式和段页式存储管理方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储管理方式还包括覆盖技术、交换技术和虚拟存储器管理，虚拟存储器管理包括请求分页存储管理方式和请求分段存储管理方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-3　存储管理方式层次关系图</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-连续存储管理方式" tabindex="-1"><a class="header-anchor" href="#◆-5-2-连续存储管理方式" aria-hidden="true">#</a> ◆ 5.2 连续存储管理方式</h3>
<blockquote>
<blockquote>
<p>连续分配方式就是用户程序装入内存时系统分配一块连续的内存区域。连续分配方式可以分为单一连续分配方式和分区分配方式，分区分配方式又可分为固定分区和可变分区两种方式。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-2-1-单一连续分配" tabindex="-1"><a class="header-anchor" href="#◆-5-2-1-单一连续分配" aria-hidden="true">#</a> ◆ 5.2.1 单一连续分配</h4>
<blockquote>
<blockquote>
<p>单一连续分配是最简单的一种存储管理方式，但只能用于单用户、单任务的操作系统中。采用这种存储管理方式时，内存的用户区一次只分配给一个用户程序使用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种管理方式的分配、回收算法非常简单。一般情况下，一个程序实际只占用该区的一部分，剩余的部分只能空闲未被利用，所以这种存储管理方式内存的利用率很低。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在早期的单用户、单任务操作系统中，大多配置了存储器保护机构，用于防止用户程序对操作系统的破坏。主要是采用设置基址寄存器和界限寄存器的方法实现。但在常见的几种单用户操作系统中，例如CP/M、MS-DOS以及RT-11等，都未设置存储器保护设施。这一方面是为了节省硬件，另一方面也因为这是可行的。其根据是由于机器由用户独占，不可能存在受其他用户程序干扰的问题；其可能出现的破坏行为，也只是由用户程序自己去破坏操作系统，其后果也并不严重，只是影响该用户程序的运行；且操作系统也很容易通过系统的再启动而重新装入内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-4　单一连续分配示意图</p>
</blockquote>
</blockquote>
<h4 id="◆-5-2-2-分区分配" tabindex="-1"><a class="header-anchor" href="#◆-5-2-2-分区分配" aria-hidden="true">#</a> ◆ 5.2.2 分区分配</h4>
<blockquote>
<blockquote>
<p>分区分配的存储管理是为了适应多道程序设计技术而产生的最简单的存储管理。它把内存划分成若干个连续的区域，每个用户程序占有一个。根据分区情况，它又分为固定分区和可变分区（动态分区）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.固定分区</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>固定分区方法是指系统预先把内存中的用户区分成若干个连续的区域，每个区域称为一个“分区”。各分区的大小可以相同，也可以不相同，但为了满足存储要求，能较好地利用内存空间，通常都把各分区划分为大小不等的连续区域。程序装入时，根据它对内存大小的需求量，系统将按照一定的策略把能满足它要求的一个分区分配给该程序。采用固定分区存储管理时，进入内存的每一个程序都占据一个连续的分区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了能对内存各分区的划分和使用情况加以有效地管理，系统设有一张固定分区分配表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>固定分区分配表的内容包括分区号、起始地址、长度、占用标志等。“占用标志”记录分区的使用状态，例如约定占用标志为0则表明该分区为空闲，可以进行分配；若“占用标志”非0，譬如填入程序名称，则意味该分区已分配给某一程序使用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>固定分区方法的分配、回收工作通过固定分区分配表很容易进行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-5　固定分区分配表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在单一连续分配中，存储保护机构是设置基址寄存器和界限地址寄存器。在固定分区中，有两种保护机构：设置上、下限寄存器或设置基址、长度寄存器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>固定式分区的主要优点是简单易行，特别是对于程序的大小预先可以知道的专用系统比较实用。其缺点是内存利用不充分，程序的大小受到分区大小的限制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.可变分区</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可变分区管理与固定分区的主要区别是系统并不预先划分内存空间，而是在程序装入时根据程序的实际需要动态地划分内存空间。若无空闲的存储空间或无足够大的空闲存储空间供分配时，则拒绝为该程序分配内存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了实现分区分配，系统中必须配置相应的数据结构，用来记录内存的使用情况，为内存的分配、回收提供依据。常用的数据结构有已分分区表和空闲分区表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>已分分区表中记录当前已经分配给用户程序的内存分区，包括分区序号、分区大小、起始地址等信息。空闲分区表记录了当前内存中空闲分区的情况，包括分区序号、分区大小、起始地址等。由于分区数目不固定，因而这些表格不一定要填满，所以用状态描述相应的表目是否使用，不用的表目即为空表目。空闲分区也可以组织成链表的形式，叫空闲分区链。为了实现对空闲分区的分配和连接，在每个分区的起始部分，设置一些用于控制分区分配的信息，以及用于连接各分区的前向指针，在分区尾部则设置一后向指针；然后，通过前、后向指针将所有的分区连接成一个双向链</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分区分配算法。为把一个新程序装入内存，须按照一定的分配算法，从空闲分区表或空闲分区链中选出一分区分配给该程序。目前常用以下4种分配算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①首次适应算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首次适应算法要求空闲分区链以地址递增的次序连接，在进行内存分配时，从链首开始顺序查找，直至找到一个能满足程序大小要求的空闲分区为止。然后，再按照程序的大小，从该分区中划出一块内存空间分配给请求者，余下的空闲分区仍留在空闲链中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>该算法倾向于优先利用内存中低址部分的空闲分区，在高址部分的空闲分区很少被利用，从而保留了高址部分的大空闲区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其缺点是低址部分不断被划分，致使留下许多难以利用的、很小的空闲分区，称为内存碎片。其每次查找都从低址部分开始，这无疑会增加查找可用空闲分区的开销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②循环首次适应算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在为程序分配内存空间时，不再每次从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找。直至找到第一个能满足要求的空闲分区，并从中划出一块与请求的大小相等的内存空间分配给程序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为实现该算法，应设置一起始查寻指针，以指示下一次起始查寻的空闲分区，并采用循环查找方式。即如果最后一个（链尾）空闲分区大小仍不能满足要求，应返回到第一个空闲分区，继续查找。找到后，应立即调整起始查寻指针。该算法能使内存中的空闲分区分布得更均匀，减少查找空闲分区的开销，但这会导致缺乏大的空闲分区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>③最佳适应算法。“最佳”的含义是指每次为程序分配内存时，总是把既能满足要求、又是最小的空闲分区分配给程序，避免“大材小用”。为了加速寻找，该算法要求将所有的空闲区，按其分区大小以递增的顺序形成一空闲分区链。这样，第一个找到的满足要求的空闲区，必然是最佳的。孤立地看，最佳适应算法似乎是最佳的，其实却不一定。因为每次分配后所切割下的剩余部分总是最小的，最容易形成内存碎片。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>④最差适应算法。“最差”的含义是指每次为程序分配内存时，总是找到一个满足程序长度要求的最大空闲分区进行分配，以便使剩下的空闲区不至于太小而形成内存碎片。这种算法适合于中、小程序运行，但对大程序的运行来讲是不利的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）内存分区分配操作。在可变分区存储管理方式中，主要的操作是分配和回收内存。内存分配的操作步骤是：首先，系统要利用某种分配算法，从空闲分区链（表）中找到所需的适合分区；设请求的分区大小为u.size，表中每个空闲分区的大小为m.size，若m.size-u.size小于系统规定的不再切割的剩余分区的大小size值，则将整个分区分配给请求者；否则从该分区中划分出与请求的大小相等的内存空间分配出去，余下的部分仍留在空闲分区表或空闲分区链中；最后，将分配区的首址返回给申请者</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-8　内存分配流程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）分区回收操作。当进程运行完毕释放内存时，系统根据回收区的首址从空闲分区表（链）中找到相应的插入点，进行回收</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可变分区分配的主要优点：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>①有助于多道程序设计，提高了内存的利用率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>②要求硬件支持少，代价低。因为存储保护只需上、下限寄存器越界检查机构，或者是基址、长度寄存器，动态地址变换机构。③管理算法简单，实现容易。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可变分区分配的缺点：①必须给程序分配一个连续的内存区域。有时虽然内存中所有空闲区的总和可以容纳一个程序，但没有一个空闲区可容纳这个程序。②碎片问题严重，内存仍不能得到充分利用。③不能实现对内存的扩充。分区的大小受到存储器容量的限制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了解决内存碎片问题，可采用的一种方法是将内存中的所有进程进行移动，使它们相邻接。原来分散的多个小分区便拼接成一个大分区，从而就可以把程序装入运行。这种通过移动，把多个分散的小分区拼接成大分区的方法称为“紧凑”或“拼接”</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>紧凑的开销是很大的，因为它不仅要修改被移动进程的地址信息，而且要复制进程空间，所以如不必要，尽量不做紧凑。通常仅在系统接收到程序所发出的申请命令，且每个空闲区域单独均不能满足，但所有空闲区域之和能够满足请求时才进行一次紧凑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于经过紧凑后，进程在内存中的位置发生了变化，若不对程序和数据的地址进行修改（变换），则进程将无法执行。为使之能够执行，必须进行重定位，即用新的开始地址替换重定位寄存器中原来的地址。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-覆盖技术与交换技术" tabindex="-1"><a class="header-anchor" href="#◆-5-3-覆盖技术与交换技术" aria-hidden="true">#</a> ◆ 5.3 覆盖技术与交换技术</h3>
<blockquote>
<blockquote>
<p>单一连续分配和分区管理对程序大小都有严格的限制。当程序要求运行时，系统将程序的全部信息一次装入内存并一直驻留内存直至运行结束。当程序的大小大于内存可用空间时，该程序就无法运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>覆盖与交换是解决大程序与小内存矛盾的两种存储管理技术，它们实质上对内存进行了逻辑扩充。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-3-1-覆盖技术" tabindex="-1"><a class="header-anchor" href="#◆-5-3-1-覆盖技术" aria-hidden="true">#</a> ◆ 5.3.1 覆盖技术</h4>
<blockquote>
<blockquote>
<p>覆盖是指同一内存区可以被不同的程序段重复使用。通常一个程序由若干个功能上相互独立的程序段组成，程序在一次运行时，也只用到其中的几段，利用这样一个事实，就可以让那些不会同时执行的程序段共用同一个内存区。把可以相互覆盖的程序段称为覆盖，而把可共享的内存区称为覆盖区。把程序执行时并不要求同时装入内存的覆盖组成一组，称为覆盖段，并分配同一个内存区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>覆盖技术的关键是提供正确的覆盖结构。通常，一个程序的覆盖结构要求编程人员事先给出，对于一个规模较大或比较复杂的程序来说是难以分析和建立它的覆盖结构的。因此，通常覆盖技术主要用于系统程序的内存管理。例如，磁盘操作系统分为两部分：一部分是操作系统中经常用到的基本部分，它们常驻内存已占有固定区域；另一部分是不经常用的部分，它们放在磁盘上，当调用时才被装入内存覆盖区中运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-11　覆盖示例</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>覆盖技术的主要特点是打破了必须将一个程序的全部信息装入内存后才能运行的限制，在一定程度上解决了小内存运行大程序的矛盾。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-3-2-交换技术" tabindex="-1"><a class="header-anchor" href="#◆-5-3-2-交换技术" aria-hidden="true">#</a> ◆ 5.3.2 交换技术</h4>
<blockquote>
<blockquote>
<p>交换技术被广泛地运用于早期的小型分时系统的存储管理中。其目的是：一方面解决内存容量不够大的矛盾，另一方面使各分时用户能保证合理的响应时间。所谓交换（又称对换）就是系统根据需要把内存中暂时不运行的某个（或某些）进程部分或全部移到外存，以便腾出足够的内存空间，再把外存中的某个（或某些）已具备运行条件的程序移到相应的内存区，创建进程，并使其投入运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>交换的时机通常在以下情况发生：（1）进程用完时间片或等待输入/输出。（2）进程要求扩充存储而得不到满足时。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用这种反复的进程换进换出，既可以实现小容量内存运行多个用户程序，也可以使各用户程序在有限的时间内得到及时响应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具有交换功能的操作系统，通常把外存分为文件区和交换区。文件区用于存放文件，交换区用于存放从内存中换出的程序（进程）。由于通常文件都是较长时间存放在外存中，所以对文件区管理的主要目的是提高存储空间（磁盘）的利用率，故对文件区采用离散分配方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对交换区管理的主要目的是提高程序的换入换出速度，故对交换区采用连续分配方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>交换技术的关键是设法减少每次交换的信息量，以提高速度。为此，常将程序的副本保留在外存，每次换出时，仅换出那些修改过的信息即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同覆盖技术一样，交换技术也是利用外存来逻辑地扩充内存。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-分页存储管理方式" tabindex="-1"><a class="header-anchor" href="#◆-5-4-分页存储管理方式" aria-hidden="true">#</a> ◆ 5.4 分页存储管理方式</h3>
<blockquote>
<blockquote>
<p>分区管理有可能造成大量的内存碎片，这是由于一个程序必须装入在一片连续的内存空间引起的。为了减少内存碎片，提高内存空间的利用率，提出了分页存储管理技术。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-4-1-基本思想-工作原理" tabindex="-1"><a class="header-anchor" href="#◆-5-4-1-基本思想-工作原理" aria-hidden="true">#</a> ◆ 5.4.1 基本思想（工作原理）</h4>
<blockquote>
<blockquote>
<p>在分页存储管理中将程序的逻辑地址空间和内存空间按相同长度为单位进行等量划分。把进程的逻辑空间分成一些大小相同的片段称为页面或页（Page）。把内存空间也分成大小与页面相同的片段，称为物理块或页框（Frame）。在分配存储空间时，总是以块为单位按照进程的页数分配物理块。分配的物理块可以连续也可以不连续</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于进程的最后一页经常装不满一块而形成不可利用的碎片，称为“页内碎片”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分页系统中页面的大小是由计算机的地址结构所决定的，亦即由硬件决定。对于某一种计算机只能采用一种大小的页面。例如，Intel 80386规定的页面大小为4096B。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在确定页面大小时，若选择的页面较小，一方面可使页内碎片小，并减少了页内碎片的总空间，有利于提高内存的利用率。但另一方面，也会使每个进程有较多的页面，从而导致页表过长，占用大量内存空间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在虚拟存储器中还会降低页面换进换出的效率。若选择的页面较大，虽然可以减少页表长度，提高换进换出效率，但又会使页内碎片增大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>页面的大小要选择适中。通常页面的大小是2的幂，且常在29～212之间，即在512B～4KB之间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分页系统中，允许将进程的每一页离散地存储在内存的任一物理块中。但系统应能保证进程的正确运行，即能在内存中找到每个页面所对应的物理块。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统又为每个进程建立了一张页面映射表，简称页表。在进程逻辑地址空间内的所有页，依次在页表中占据一个表项，其中记录了相应页在内存中对应的物理块号</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在配置了页表后，进程执行时，通过查找页表找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射。系统在内存空间设置一片区域作为页表区，系统为每个进程提供一个页表。进程页表的起始地址存放在进程PCB中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-12　分页管理示意图</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-13　页表示意图</p>
</blockquote>
</blockquote>
<h4 id="◆-5-4-2-动态地址变换" tabindex="-1"><a class="header-anchor" href="#◆-5-4-2-动态地址变换" aria-hidden="true">#</a> ◆ 5.4.2 动态地址变换</h4>
<blockquote>
<blockquote>
<p>在分页系统中，逻辑地址和物理地址可以分解成两部分。逻辑地址可以分解成：页号、页内位移量（页内地址），分别记为p、d；物理地址可以分解成：物理块号、物理块内位移量（物理块内地址），记为f、d。例如，页面大小为512B，逻辑地址1153属于第2号页，页内位移为129，即p=逻辑地址/页面大小d=逻辑地址-p×页面大小</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了能将进程逻辑地址空间中的逻辑地址变换为内存空间中的物理地址，在系统中必须设置地址变换机构。该机构的基本任务是实现逻辑地址到物理地址的转换。由于页内地址和物理块内地址是一一对应的，例如，对于页面大小是1K的页内地址是从0～1023，其相应的物理块内的地址也是从0～1023，无须再进行转换。因此，地址变换机构的任务，实际上只是将逻辑地址中的页号转换为内存中的物理块号。又因为页表的作用就是用于实现页号到物理块号的变换，因此地址变换任务是借助于页表来完成的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统设置了一个页表寄存器（Page-Table Register，PTR），其中存放页表在内存的始址和页表的长度。进程未执行时，页表的始址和长度存放在对应进程的PCB中。当调度程序调度到某进程时，才将它们装入到页表寄存器中。因此，在单处机理系统中，虽然系统中可以运行多个进程，但只需一个页表寄存器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当进程要访问某个逻辑地址中的数据时，分页地址变换机构会自动将逻辑地址分为页号和页内地址两部分，再以页号为索引去检索页表。查找操作由硬件执行。在执行检索之前，先将页号与页表寄存器中的页表长度进行比较，如果页号大于或等于页表长度，则表示本次所访问的地址已超越进程的地址空间。于是，这一错误将被系统发现并产生一地址越界中断。若没有出现越界错误，则将页表始址与页号和页表项长度的乘积相加，便得到该表项在页表中的位置，于是可从中得到该页的物理块号，将之装入物理地址寄存器中，与此同时，再将逻辑地址寄存器中的页内地址直接送入物理地址寄存器的块内地址字段中。这样便完成了从逻辑地址到物理地址的转换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-15　分页系统中的地址变换机构</p>
</blockquote>
</blockquote>
<h4 id="◆-5-4-3-快表" tabindex="-1"><a class="header-anchor" href="#◆-5-4-3-快表" aria-hidden="true">#</a> ◆ 5.4.3 快表</h4>
<blockquote>
<blockquote>
<p>由于页表存储在内存中，所以当要按照给定的逻辑地址取得一条指令或数据时，需要两次访问内存，一次是根据页号访问页表，读出页表相应栏中的块号以便形成物理地址；第二次是根据物理地址进行读/写操作。这样比通常执行指令的速度慢一半。为了提高存取速度，在地址变换机构中增设了一个具有并行查寻能力的特殊高速缓冲存储器，又称“联想存储器”或“快表”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>联想存储器的造价较高，因此一般快表中只能存放8～16个页表内容，所以在快表中存储了正在运行程序的当前最常用的页号和它的相应的物理块号。利用快表进行读/写操作的过程是，首先按逻辑地址中的页号先查快表，若该页在快表中，则立即能得到相应的物理块号并与页内地址形成物理地址；若该页不在快表中，则再查内存中的页表找到相应的块号，形成物理地址，同时将该页的对应项写入快表。若快表已满，则按照一定策略淘汰一个旧项。最简单的策略是“先进先出”原则，即淘汰最先进入快表的那一项。采用快表后，使得指令执行速度大大加快</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-16　利用快表的地址变换机构</p>
</blockquote>
</blockquote>
<h4 id="◆-5-4-4-两级和多级页表" tabindex="-1"><a class="header-anchor" href="#◆-5-4-4-两级和多级页表" aria-hidden="true">#</a> ◆ 5.4.4 两级和多级页表</h4>
<blockquote>
<blockquote>
<p>现代的大多数计算机系统都支持非常大的逻辑地址空间，页表就变得非常大，要为它分配一大段连续的内存空间将变得十分困难。例如，对于一个具有32位逻辑地址空间的分页系统，规定页面大小为4KB，则在每个进程中页表的页表项有1M个，又因为每个页表项占用4B，故每个进程仅页表就需要占用4MB的内存空间，而且还要求是连续的。显然这是不现实的，可以采用两个办法来解决这个问题：（1）采用离散分配方式来解决难以找到一块连续的内存空间问题。（2）只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>采用离散分配方式需将页表进行分页，并将各个页表页分别存放到不同的内存块中。此时，必须为离散分配的页表再建立一张页表，称为外层页表，用来记录存放各页表页的内存块号，从而形成了两级页表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在使用两级页表的分页系统中，每次访问一个数据或指令需要访问3次内存，故同样需要增设快表来有效地提高访问速度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对页表进行离散存储的方法虽然解决了页表需要连续内存空间的问题，但并未解决用较小的内存去存放大页表的问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>只用离散分配的办法并没有减少页表所占用的内存空间。唯一的解决方法是把当前所需要的一批页表项调入内存，以后再根据需要陆续调入。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-5-分段存储管理方式" tabindex="-1"><a class="header-anchor" href="#◆-5-5-分段存储管理方式" aria-hidden="true">#</a> ◆ 5.5 分段存储管理方式</h3>
<blockquote>
<blockquote>
<p>如果说分页存储器管理方式引入的目的是提高内存的利用率，那么分段存储器管理方式的引入便是为了方便用户的使用。引入分段存储器管理方式主要是为了满足用户方便编程、分段共享和分段保护等要求。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-5-1-基本思想-工作原理" tabindex="-1"><a class="header-anchor" href="#◆-5-5-1-基本思想-工作原理" aria-hidden="true">#</a> ◆ 5.5.1 基本思想（工作原理）</h4>
<blockquote>
<blockquote>
<p>分段存储管理方式要求每个程序的地址空间按照自身的逻辑关系划分成若干段，比如主程序段、子程序段、数据段、堆栈段等，每个段都有自己的名字。为了简单，通常可用一个段号来代替段名，每个段都从0开始独立编址，段内地址连续。段的长度由相应的逻辑信息组的长度决定，因而各段的长度不等。分配内存时，为每个段分配一连续的存储空间，段间地址空间可以不连续。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分段存储管理系统中，为每一个段分配一个连续的存储空间，而段和段之间可以不连续，离散地分配到内存的不同区域。为了使程序能够正常执行，亦即能从内存中找到每个逻辑段所存储的位置，系统为每个进程建立了一张段映射表，简称“段表”。进程的每个段在段表中占有一个表项，其中记录了该段在内存中的起始地址（基址）和段的长度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>段表一般情况下存储在内存中，在配置了段表以后，执行中的进程可以通过查找段表，找到每个段在内存中存储的位置。段表实现了从逻辑段到物理内存区的映射。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-5-3-存储保护" tabindex="-1"><a class="header-anchor" href="#◆-5-5-3-存储保护" aria-hidden="true">#</a> ◆ 5.5.3 存储保护</h4>
<blockquote>
<blockquote>
<p>由于在分段存储管理方式中，用户各分段是信息的逻辑单位，因此容易对各段实现保护。保护可分为越界保护和越权保护两种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.越界保护在地址变换过程中，需要进行段号和段表长度的比较，以及段内地址和段长的比较。若段号小于段表长度并且段内地址小于段长，才能进行地址变换。否则，产生越界中断，终止程序运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.越权保护和分页存储管理方式一样，通过在段表中设置存取控制字段来对各段进行保护。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-5-4-分页和分段的主要区别" tabindex="-1"><a class="header-anchor" href="#◆-5-5-4-分页和分段的主要区别" aria-hidden="true">#</a> ◆ 5.5.4 分页和分段的主要区别</h4>
<blockquote>
<blockquote>
<p>分页和分段有许多相似之处，但是在概念上两者完全不同，主要表现在以下3点：（1）页是信息的物理单位，分页是为了系统管理内存的方便而进行的，故对用户而言，分页是不可见的，是透明的；段是信息的逻辑单位，分段是程序逻辑上的要求，对用户而言，分段是可见的。（2）页的大小是固定的，由系统决定；段的大小是不固定的，由用户程序本身决定。（3）从用户角度看，分页的地址空间是一维的，而段的地址空间是二维的。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-段页式存储管理方式" tabindex="-1"><a class="header-anchor" href="#◆-5-6-段页式存储管理方式" aria-hidden="true">#</a> ◆ 5.6 段页式存储管理方式</h3>
<blockquote>
<blockquote>
<p>分页存储管理方式提高了内存的利用率，分段存储管理方式方便了用户的使用。结合两者的优点，将分页存储管理方式和分段存储管理方式组合在一起，形成了段页式存储管理方式。</p>
</blockquote>
</blockquote>
<h4 id="◆-5-6-2-地址变换" tabindex="-1"><a class="header-anchor" href="#◆-5-6-2-地址变换" aria-hidden="true">#</a> ◆ 5.6.2 地址变换</h4>
<blockquote>
<blockquote>
<p>在段页式存储管理方式中，执行一条指令需要3次访问内存。第一次访问段表，从中得到页表的位置；第二次访问页表，得出该页所对应的物理块号；第三次按照得到的物理地址访问内存。为了提高地址变换速度，同样可以和分页存储管理方式、分段存储管理方式一样，设置一个高速缓冲寄存器，利用段号和页号去检索该寄存器，得到相应的物理块号。</p>
</blockquote>
</blockquote>
<h3 id="◆-习题-4" tabindex="-1"><a class="header-anchor" href="#◆-习题-4" aria-hidden="true">#</a> ◆ 习题</h3>
<blockquote>
<blockquote>
<p>习题1.计算机系统中存储器一般分为哪两级？各有什么特点？2.存储管理的目的是什么？存储管理的任务是什么？3.地址转换可分为哪3种方式？比较这3种方式的优缺点。4.可变分区常用的分区算法有哪几种？它们各自的特点是什么？5.用类C++语言写出首次适应分配算法的分配过程。6.什么叫紧凑？为什么要进行紧凑？7.什么是覆盖？什么是交换？覆盖和交换的区别是什么？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>8.简述分页存储管理方式的基本思想和页表的作用。9.缺页中断和一般中断有哪些不同？10.简述快表的作用。11.简述段和页的区别。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>无论是单一连续分配、分区分配还是分页存取管理方式和分段存储管理方式，都有一个共同的特点：需要将程序一次性装入内存。这样如果程序很大，其所要求的内存空间超过当前内存空间总和，则程序不能被一次性的装入内存，会致使程序无法执行。另外，当要运行的程序很多，而内存空间不足，则只能让一部分程序先运行，大量程序只能在外存中等待。为了解决这些内存不足的情况，可以从物理上和逻辑上两方面扩充内存容量。虚拟存储器就是使用虚拟技术从逻辑上对存储器进行扩充。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-1-1-分布式系统的概念" tabindex="-1"><a class="header-anchor" href="#◆-10-1-1-分布式系统的概念" aria-hidden="true">#</a> ◆ 10.1.1 分布式系统的概念</h4>
<blockquote>
<blockquote>
<p>分布式计算机系统是多机系统的一种新形式，涉及资源、任务、功能和控制的全面分布。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式能力包括以下几个方面：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）通信结构。通信结构是支持各个独立计算机联网的软件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）网络操作系统。它是为计算机网络配置的操作系统，网络中的各台计算机配置各自的操作系统，而网络操作系统把它们有机地联系起来。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）分布式操作系统。它是为分布式计算机系统配置的操作系统，是网络中计算机共享使用的一个公共的操作系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式计算机系统与计算机网络既有类似之处又有不同点，其主要的异同如下：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）在计算机网络中，每个用户或任务通常只使用一台计算机，若要利用网络中的另一台计算机，则需要远程注册。在分布式计算机系统中，用户进程在系统内各个计算机上动态调度，并根据运行情况由分布式操作系统动态地、透明地将机器分配给用户进程或任务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）在计算机网络中，用户知道它们的文件存放在何处，并用显示的文件传输命令在机器之间传送文件。在分布式计算机系统中，文件的放置由操作系统管理，用户可用相同方式访问系统中的所有文件而不管它们位于何处。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）在计算机网络中，各结点计算机均有自己的操作系统，资源归局部所有并被局部控制，网络内的进程调度是通过进程迁移和数据迁移实现的。在分布式计算机系统中，每个场点上运行一个局部操作系统，执行的任务可以是独立的，可以是某任务的一个部分，也可以是其他场点上的（部分）任务，且各场点相互协同，合作平衡系统内的负载。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）在计算机网络中，系统几乎无容错能力。在分布式计算机系统中有系统自动重构、适度降级使用及错误恢复功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）两者透明性的程度和级别不同。（6）就资源共享而言，计算机网络和分布式计算机系统是类似的。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-1-2-通信结构" tabindex="-1"><a class="header-anchor" href="#◆-10-1-2-通信结构" aria-hidden="true">#</a> ◆ 10.1.2 通信结构</h4>
<blockquote>
<blockquote>
<p>联网的两台计算机之间进行文件传输为例，说明实现时需要完成的几个任务：（1）源系统必须告诉网络目标系统的标识。（2）源系统必须测定目标系统是否已做好接收数据的准备。（3）源系统上的文件传输应用必须判明目标系统上的文件管理程序是否准备接收并存储这个特定用户的文件。（4）如果两个系统的文件格式不一致，其中之一必须实现文件格式的转换功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>要实现文件传输，两个计算机之间必须密切配合。在实际实现时，不是把这种合作逻辑用一个模块实现，而是将这个任务划分成几个子任务，每个子任务实现其中的一个独立功能。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-1-3-开放式系统互连通信结构" tabindex="-1"><a class="header-anchor" href="#◆-10-1-3-开放式系统互连通信结构" aria-hidden="true">#</a> ◆ 10.1.3 开放式系统互连通信结构</h4>
<blockquote>
<blockquote>
<p>1.物理层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>国际标准化组织为开放式系统互连的七层参考模型中的物理层的定义如下：“物理层为启动、维护和释放数据链路实体之间二进制位而进行的物理连接提供机械的、电气的、功能的和规程的特性，这种物理连接允许进行全双工或半双工的二进制位流传输。”</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）机械特性。它规定了数据传输设备和传输介质之间连接时所采用的可接插连接器的规格尺寸、连接器的引脚数以及信号线的排列情况等。（2）电气特性。它规定了在物理连接器上传输比特流时线路上信号1和0电压的大小、信号维持的时间、传输速率和脱离限制等。（3）功能特性。它规定了物理接口上各条信号线的功能分配和确切定义。物理接口上的信号线通常有数据线、控制线、同步线和地线等。（4）规程特性。它定义了利用信号线进行比特流传输时使用的一组操作过程，即各信号线工作的规则和各信号时序的先后顺序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.数据链路层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据链路层协议的主要功能是：在相邻的两个计算机之间建立、维持和释放一条或多条数据链路。其主要工作是将数据按规定的格式（帧）组织起来，进行传输，保证数据传输无差错，按顺序到达目的地。在链路上实现帧的同步，以及进行差错控制、流量控制和顺序控制等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.网络层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络层提供了计算机之间通过某类通信网进行信息传输，它的任务是选择合适的网间路由和交换结点，确保数据及时传送。它接收来自数据链路层的服务，并向传输层提供服务，使得较高层摆脱了了解基本数据传输和用于连接系统需要的交换技术。是网络服务负责建立、维护和终止网络连接手段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络中任意两台主机的通信都是由通信子网完成的。网络层则是通信子网的最高层。它最能体现网络的概念，所以称之为网络层。网络层直接为主机服务，这种服务分为两大类：虚拟电路和分组数据报文交换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>虚拟电路服务是指两个主机通信之前，网络层负责建立一条通路，称为虚拟电路。它由若干个逻辑信道串联而成，能保证分组报文按顺序正确地到达目的地。虚拟电路一经建立，就为某一对主计算机服务。数据传输结束时，拆除该电路。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分组报文服务是指网络层直接从传输层接收报文并负责传送。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在这类服务中，每个报文分组都要附有目的地址、源地址、顺序号等足够信息，才能使目的主机接收。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络层应负责为传送的报文选择路由，以便使各分组报文能正确到达目的地。如果子网使用数据报文服务，则对每一个到达的报文分组都需做一次路由选择。但对子网采用虚拟电路服务时，只有当一条新的虚拟电路建立时才做一次路由选择。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络层还应负责对死锁和拥挤的控制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网络层另外还应提供网际互联的服务。当源端主机与目的端主机不在同一网络中时，存在一个路由选择问题，应该找出一条通过一个或多个中间网络的路径。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.传输层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>传输层在OSI七层协议中是位于第4层。如将OSI七层协议按用户功能与网络功能来划分，则它应属于用户功能。网络功能仅包括网络层、数据链路层和物理层。它们的任务是如何实现通信，提供通信的方法，又称通信子网。通信子网的功能由IMP（接口信息处理机）来完成，而构成传输层的程序则是在主机上运行的。如将OSI七层协议按面向信息处理与面向通信来划分，则它属于面向通信的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>传输层的功能是在通信用户之间提供点到点的可靠的通信服务。当通信子网所提供的服务与用户要求之间存在一些差别时，可以由传输层的协议加以补充，如果通信子网的服务达到了用户要求，则传输层可省略。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>传输层提供的服务主要有：传输连接管理和数据传输。所谓传输连接管理就是在两个传输用户之间建立和维护一条畅通的传输通道。而数据传输服务则要求在一对传输用户之间提供相互交换数据的方法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了保证用户进程之间的可靠的点到点传输通信，传输层必须具备以下主要功能：（1）将传输层所给的传输地址映射到网络层的网络地址。（2）将多路的点到点的传输连接变成一路网络连接。（3）传输连接的建立或释放。（4）差错检测和恢复。（5）对传输的信息进行分块。（6）对传输的数据进行缓冲和流量控制。（7）完成给定的传输服务数据单元的传送。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.会话层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>会话层接收从传输层来的任务，同时又为表示层服务。会话层的主要任务是提供一种有效方法，以便组织并协调两个表示实体进程之间的对话，并管理它们之间的数据交换，建立各种应用程序所需的通用传输控制。会话层的功能包括：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）在两个表示实体之间建立会话连接，以进行正常的数据传输。（2）控制两个表示实体之间的数据交换，限制和同步数据操作的会话服务。（3）恢复功能。会话层可以提供一个同步检查点机制，以便两个检查点之间产生某类错误时，会话实体可以重新发送自上一检查点以来的全部数据。一个表示层实体同另一个表示层实体之间建立会话连接时必须满足下列两个条件：（1）它能主动发起一个会话连接。（2）能接收对方提出的会话连接。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.表示层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表示层向上为应用层提供服务，向下接收来自会话层的服务。表示层的目的是对应用层送来的命令和数据内容加以解释说明，并对各种语法赋予应有的含义，以便使从应用层送入的各种信息具有明确的表示意义。每种计算机都有自身的描述数据的方法，所以不同类型的计算机之间必须进行数据转换才能相互了解。表示层的任务就是对发送方内部格式的数据结构进行编码，使形成的比特串适合传输。然后在目的地接收方进行解码，转换成所要求的格式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>表示层有4个主要功能：（1）提供执行会话层原语的方法。（2）提供说明复杂数据结构的方法。（3）管理所需要的数据结构的集合。（4）数据转换工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由此可见，表示层是为用户进程提供服务的。这些服务项目包括密码技术（加密和解密），以及文本压缩（减少通信传输的信息量）等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>7.应用层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这一层包含了支持分布式应用的各种管理功能和公用的机制，如虚拟终端、文件传输、电子邮件传输的服务和协议等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓虚拟终端是指把各种实际的不同类型的终端映射成一个标准终端，而这种标准终端是抽象的、虚拟的。计算机网络要能支持这种虚拟终端。用户只能看到一个称为虚拟终端的实体，由这个虚拟终端进行服务，使这样两个相关的实体根据一定的协议相互配合工作，这就是虚拟终端协议。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓文件传输是指将一个文件从一个开放系统传送到另一个开放系统时，利用下面6层提供的服务，在两个交换文件的系统之间建立一条逻辑通路，以便实现文件的存取、访问和管理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓电子邮件传输是指把电子邮件从邮件客户端发送到邮件服务器，或从邮件服务器发送到另一个邮件服务器，电子邮件的发送和接收按规定的协议来完成。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-2-网络服务器" tabindex="-1"><a class="header-anchor" href="#◆-10-2-网络服务器" aria-hidden="true">#</a> ◆ 10.2 网络服务器</h3>
<blockquote>
<blockquote>
<p>网络服务器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>局域网的优点之一是能够共享价格昂贵的资源，例如外存设备和高质量的打印机。通常的方法是在局域网上提供一个或多个服务器。局域网上有许多个人计算机，它们是用户访问网络共享资源的操作台。用户在工作站上通过输入网络命令或调用网络菜单实用程序，向文件服务器申请网络服务。例如，使用服务器硬盘中的各种应用程序，使用共享的网络打印机。通过异步通信接口连接调制解调器（Modem），并接入电话网，与远距离的其他工作站接通。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-2-3-文件高速缓冲存储器的一致性问题" tabindex="-1"><a class="header-anchor" href="#◆-10-2-3-文件高速缓冲存储器的一致性问题" aria-hidden="true">#</a> ◆ 10.2.3 文件高速缓冲存储器的一致性问题</h4>
<blockquote>
<blockquote>
<p>文件高速缓冲存储器的一致性问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当使用文件服务器时，网络传输的延迟使得文件I/O的性能相对于本地文件的存取可能显著地下降。为了减少这个性能损失，各个独立的用户系统可以使用文件高速缓冲存储器保留最近存取的文件记录。由于局部性原理，使用本地的文件高速缓冲存储器将大大减少对远程服务器必须进行的存取次数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当高速缓存总是包含了远程数据的精确副本时，高速缓存是一致的。当远程数据已被修改，相应的本地的已过时的副本还没有废弃时，高速缓存就变为不一致的。当一个客户机修改了由其他客户机高速缓冲的文件时，这种情况也可能发生。这时的困难实际出在两级上。如果客户机采用将对文件修改立即写回到服务器的策略，那么具有这个文件有关部分的高速缓冲副本的任何客户机将有作废的数据。如果客户机对文件修改推迟写回到服务器，这将使情况变得更糟。这样，文件服务器本身就包含了过时的文件版本，若此时有一个对文件服务器上该文件的新请求，获得的将是作废数据。使本地高速缓存中的副本保持远程数据的最新修改的问题称为高速缓存的一致性问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>解决一致性问题的最简单的方法是对文件采用加锁技术，以防止多个客户机同时存取一个文件。这是以牺牲性能和灵活性为代价而保证数据一致性的方法。更有效的方法是允许任意多的进程同时打开一个文件读并创建各自的客户机高速缓存。但当有一个对服务器的请求是打开文件的写请求，而其他进程打开文件是读存取时，文件服务器采取两个活动。首先，它通知写进程，它可以保持一个高速缓存，但当它修改完时应立即将所有修改块写回到服务器。至多允许有一个这样的客户机。其次，服务器通知所有读进程正在打开的文件不再允许高速缓存。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-2-4-打印机服务器" tabindex="-1"><a class="header-anchor" href="#◆-10-2-4-打印机服务器" aria-hidden="true">#</a> ◆ 10.2.4 打印机服务器</h4>
<blockquote>
<blockquote>
<p>打印机服务器使用的是操作系统技术中最早使用的技术之一——Spooling技术。Spooling是将相对慢的打印机请求重定向到快速磁盘上的软、硬件结合的一种技术。当有打印请求时，先将每个数据文档或文件假脱机到磁盘，并将这些文件按先进先出的方法组织成队列。服务器从磁盘上一次一个地检索文件并进行打印。Spooling技术克服了直接使用打印机时存在的两个问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）被打印的资料可以比内存的可用空间大得多，它可以存储在磁盘上，并一次读入一块地进行打印。（2）当打印机正在打印一个文件时，多个用户仍可以发送打印请求。这些请求可以排队等待打印机的服务。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-3-分布式进程管理" tabindex="-1"><a class="header-anchor" href="#◆-10-3-分布式进程管理" aria-hidden="true">#</a> ◆ 10.3 分布式进程管理</h3>
<blockquote>
<blockquote>
<p>分布式进程是能够真正在多个处理机上同时运行的诸进程。显然，一般的并发进程利用的是多个虚拟处理机的概念，而分布式进程利用的是多个真正的物理处理机。前者只不过是实现了逻辑上的并行性，而后者实现了物理上的并行性，两者的运行在时间、空间上都有较大差异。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-3-1-分布式进程的状态及其转换" tabindex="-1"><a class="header-anchor" href="#◆-10-3-1-分布式进程的状态及其转换" aria-hidden="true">#</a> ◆ 10.3.1 分布式进程的状态及其转换</h4>
<blockquote>
<blockquote>
<p>分布式进程的状态及其转换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式环境下，进程的状态有运行态、等待态、挂起态和就绪态4种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）运行态。当进程占有处理机正在执行指令的状态称为运行态。但进程在整个运行周期不一定都是在同一个处理机上运行。例如，某一进程很可能在运行过程中被打断一段时间后，又被分配到另一空闲或者轻负载的处理机上去运行，这是多机环境下运行进程的一个特点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）等待态。进程运行过程中，因等待某种事件的发生所处的一种状态称为等待态。此状态是为了在进程被挂起之前对其占用的系统资源情况进行检查，并为其可能正要进行的访问内存操作保留一定时间而设置的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）挂起态。进程进入等待态只不过是一个暂时的过渡，此后必须进入挂起态，暂时停止执行。此时，进程必须释放它占用的资源。为了防止死锁，有些系统还要求挂起的进程释放占用的内存和设备。当该进程再次运行的条件满足时，进程由挂起态转换为就绪态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）就绪态。当进程已符合运行要求，只是因为系统中当前的进程个数已超过了处理机的个数而不能进入运行时，进入就绪态；或者是当进程运行的时间超过了系统预先分配的时间时，系统就强制其进入就绪态，排队等待下次运行机会。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式进程的状态转换也是在原语的控制下实现的，操作原语是调度程序的重要组成部分。应强调的是：分布式系统是以任务级并行为特征的。分布式操作系统的基本调度单位不再是单机上的进程，而是在各处理机上运行着的并行进程所组成的任务队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同一任务队列的诸并发进程可分配到不同处理机上并行运行；同一处理机也可执行多个不同的任务队列中的进程。这就使得在单机系统中许多行之有效的调度算法，如优先数法、时间片法等，都不完全适用于分布式系统。寻求合理、高效的进程调度算法仍是目前分布式系统的主要研究的课题之一。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-3-2-处理机管理" tabindex="-1"><a class="header-anchor" href="#◆-10-3-2-处理机管理" aria-hidden="true">#</a> ◆ 10.3.2 处理机管理</h4>
<blockquote>
<blockquote>
<p>在单机操作系统中，处理机管理归结为进程管理。在分布式系统中，处理机作为进程的执行者，对其管理上的许多问题尽管也在进程管理上得到了一些反映和解决，但处理机本身的一些问题，如处理机的状态及其转换、处理机通信和处理机分配等，仍需要专门讨论和解决。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.处理机的状态及其转换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机的状态与进程的状态不完全一样，通常处理机只有空闲、等待和运行3种状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）空闲态。系统开始工作之后，尚未分到任务的处理机状态，或虽分配到任务但已完成的处理机状态，均认为是空闲状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）等待态。处理机在执行任务期间，所运行的进程由于某种原因被挂起但又没有新的进程运行时的状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）运行态。处理机接受任务后且正在执行进程时的状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3种状态的转换可通过操作原语进行控制。例如，可用wait原语控制进入“等待”状态，用continue原语控制进入“运行”态，而当处理机完成任务后，便回到了“空闲”态。当然，最理想的情况是，设法使所有处理机都经常保持忙碌状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.处理机通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式系统中各处理机的通信一方面表现在进程运行期间的诸进程之间的通信上；另一方面还表现在无进程运行或进程运行已经结束时的信息交换上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通信时，处理机执行的是操作系统的内核模块。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机通信一般有“点-点”方式和“广播”方式两种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.处理机的分配和调度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>处理机的分配和调度一般是通过处理机间的通信来实现的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一种可供选择的方法如下：（1）当某台处理机在执行任务的过程中要求启动一并行任务时，它就把“需要一台可供使用的处理机”的请求消息连同自己的地址广播出去。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）这一消息被存入所有接收到请求消息的处理机的消息缓冲区中，直到发出请求消息的处理机自动撤销为止。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）当接收处理机可接受任务时，就在其局部操作系统控制下，在消息缓冲区中找到发出请求消息的处理机地址，并向发出请求消息的处理机发送应答消息及自己的地址。发出请求消息的处理机收到应答消息后，立即转入本机局部操作系统，并向对方发出任务分配消息，让它执行任务，然后回到原来的应用程序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任务分配信息有一特别标志位，当该位为1时表示任务是其他机上的；当该位为0时表示此任务是本机上的。任务的最后语句总是return（p），执行到此语句且特别标志位为1时，就产生局部操作系统的内部中断，然后把“任务已完成”的信号传送给发出请求消息的处理机，同时该接收处理机返回到空闲态。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-4-进程迁移" tabindex="-1"><a class="header-anchor" href="#◆-10-4-进程迁移" aria-hidden="true">#</a> ◆ 10.4 进程迁移</h3>
<blockquote>
<blockquote>
<p>进程迁移</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程迁移是指为了使进程在另一台计算机上执行，源计算机向目标传送足够数量的进程的状态信息。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-5-分布式进程通信" tabindex="-1"><a class="header-anchor" href="#◆-10-5-分布式进程通信" aria-hidden="true">#</a> ◆ 10.5 分布式进程通信</h3>
<blockquote>
<blockquote>
<p>分布式进程通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在真正的分布式处理系统中，通常各计算机没有公共的存储器，每一个都是独立的计算机系统。因此，依赖于共享存储器的交互处理机技术（如信号量和公共存储域）将不起作用，取而代之的是使用信息传递技术。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最普遍的两个方法：第一个是与在单机系统中使用相同的简单信息应用；第二个是以信息传递作为基本功能的一个独立技术即远程过程调用。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-5-1-信息传送机制" tabindex="-1"><a class="header-anchor" href="#◆-10-5-1-信息传送机制" aria-hidden="true">#</a> ◆ 10.5.1 信息传送机制</h4>
<blockquote>
<blockquote>
<p>信息传送机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程利用信息传送模块的服务（它是操作系统的一部分）来实现信息的相互传送。这些服务请求可以用命令和参数的形式表示，命令说明要实现的功能，参数用来说明要传递的数据和控制信息。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-5-2-远程过程调用" tabindex="-1"><a class="header-anchor" href="#◆-10-5-2-远程过程调用" aria-hidden="true">#</a> ◆ 10.5.2 远程过程调用</h4>
<blockquote>
<blockquote>
<p>远程过程调用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>远程过程调用是对信息传送基本模型的修改，它现在正被广泛地应用到分布式系统中，而且是封闭式通信普遍采用的方法。它允许不同计算机上的程序使用简单的过程调用和返回方式进行交互对话。这个过程调用是用来访问远程服务的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>程过程调用的一般结构，调用程序在它的计算机上进行正常的带参数的过程调用，其命令格式如下：[插图]这里P是过程名字，x为传送的变量，y是返回值参数。[插图]图10-11　远程过程调用机制</p>
</blockquote>
</blockquote>
<h4 id="◆-10-5-3-确定分布式系统的全局状态" tabindex="-1"><a class="header-anchor" href="#◆-10-5-3-确定分布式系统的全局状态" aria-hidden="true">#</a> ◆ 10.5.3 确定分布式系统的全局状态</h4>
<blockquote>
<blockquote>
<p>确定分布式系统的全局状态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.全局状态和分布式瞬态</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在紧耦合系统中所有的并发问题，如互斥、死锁和饿死等，在分布式系统中也会遇到。在这些领域的设计策略由于没有一个系统全局状态而变得复杂化。因为操作系统或任何进程不可能知道分布式系统中所有进程的当前状态。一个进程通过访问存储器中的各个进程控制块可以知道在本地系统上所有进程的当前状态。对于远程进程，一个进程只可能通过接收到的信息来了解它的状态信息，这个信息记录了该远程进程过去某个时间的状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）通道。如果两个进程要交换数据，在它们之间就存在一个通道。可以把通道看成信息传输的路径或手段。为了方便起见，通道被认为是单方向的。因此，如果两个进程交换信息，就需要两个通道，每个信息的传送方向有一个。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）状态。一个进程的状态是与该进程相关联的通道上发送和接收的信息序列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）瞬态。一个瞬态记录了一个进程的状态。每个瞬态包括了自上一个瞬态以来在所有通道上发送和接收的所有信息的记录。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（4）全局状态。所有进程的组合状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（5）分布式瞬态。所谓分布式瞬态是指每个进程有一组状态的收集。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于信息传送引起的时间差，不能确定一个真正的全局瞬态，但可以设法通过收集来自所有进程的瞬态定义一个全局状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.分布式瞬态算法所谓分布式瞬态算法是指记录一致性全局状态在分布式系统中采用的方法。该算法假定：信息应按照其发送的顺序传送，并且在传输过程中没有被丢失。OSI模型第4层的可靠传输协议满足了这些要求。算法用了一个专用的控制信息marker。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这个分布式瞬态算法是一个功能很强的灵活的工具。它可以使任何集中式算法适应于分布式环境，因为任何集中式算法的基础是了解全局状态。还有一些具体的例子，它包括了检测死锁和检测进程终止。它也可用来提供分布式算法的检查点，以便当检测到一个故障时，允许滚回和恢复。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-6-分布式进程同步与互斥" tabindex="-1"><a class="header-anchor" href="#◆-10-6-分布式进程同步与互斥" aria-hidden="true">#</a> ◆ 10.6 分布式进程同步与互斥</h3>
<blockquote>
<blockquote>
<p>分布式进程同步与互斥</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>进程同步主要是指彼此合作的进程在共享资源上协调其操作顺序。进程互斥则主要是指彼此竞争的进程严格按照次序（排他性的）使用资源。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-6-1-事件定序法" tabindex="-1"><a class="header-anchor" href="#◆-10-6-1-事件定序法" aria-hidden="true">#</a> ◆ 10.6.1 事件定序法</h4>
<blockquote>
<blockquote>
<p>事件定序法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在单机系统中，诸进程运行于同一个处理机和内存环境中，使用同一个时钟，进程通信十分简单。进程之间可以借助于“共享存储器”进行直接通信。而在分布式系统中，相互合作的进程可能在不同的处理机上运行，进程间是通过消息进行通信的。在分布式系统中，为了实现进程的同步，首先要对系统发生的事件进行排序。这里“事件”是不能分割的一个行为，例如发送或者接收一个消息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于分布式系统中没有一个公共时钟，各计算机时钟之间存在时钟差异，所以难以确定两个事件发生的先后次序，而且消息传递的通信延迟使得分布式系统开发同步与互斥机制和集中式相比更加困难。为了研究分布式同步与互斥算法，首先讨论克服时钟同步困难所采用的一个常见的方法——分布式系统中的事件定序法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同步和互斥的分布式算法的基本操作是事件的时间定序。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-6-2-分布式互斥" tabindex="-1"><a class="header-anchor" href="#◆-10-6-2-分布式互斥" aria-hidden="true">#</a> ◆ 10.6.2 分布式互斥</h4>
<blockquote>
<blockquote>
<p>分布式互斥</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>互斥是在多个进程竞争临界资源和要求进入临界区时引入的机制。支持互斥的任何设施或能力应满足下面的要求：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）必须强调互斥。对于同一资源或共享目标的临界区，所有要求进入的进程中，一次仅允许一个进程进入该设施的临界区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）在非临界段阻塞的进程不应干扰其他进程。（3）请求访问临界段的进程不应该无限期地被推迟，即不能存在死锁和（或）饿死现象。（4）当没有进程在临界段时，任何请求进入临界段的进程必须允许立即进入。（5）有关进程的相对速度或处理机的数量不进行假定和限制。（6）一个进程在临界段的时间是有限的，不允许无限期地停留在临界段之内。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当一个用户进程要求存取一个临界资源时，它向它的本地资源控制进程（RP）发送一个请求。这个控制进程向控制结点发送一个请求信息，当共享目标可用时，它返回一个“许可”应答信息。当资源使用完时，进程向控制结点发送一个释放信息。这个集中式算法有两个关键性质：（1）只有控制结点才能对资源分配进行决策。（2）控制结点中集中了所有必要的信息，包括所有资源的标识和位置，以及每个资源的分配状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集中式互斥算法比较简单，容易实现。当资源正被使用时，控制结点就不满足进程对资源的请求。然而它也存在几个缺点：（1）如果控制结点失败了，互斥机制就无法实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）每个资源的分配和回收要求与控制结点交换信息，因此控制结点可能变为瓶颈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于集中式算法存在的问题，人们以更大的兴趣开发研究分布式算法。一个完全分布的算法具有下面一些特征：（1）平均来讲，所有结点有着等量的信息。（2）每个结点只有整个系统的一部分描述，且必须基于这个信息进行决策。（3）所有结点对于系统的最后决策有着完全相等的作用。（4）一个结点失败了，一般不会导致整个系统崩溃。（5）不存在系统范围的公共时钟来协调与时间有关的事件。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-6-3-分布式算法" tabindex="-1"><a class="header-anchor" href="#◆-10-6-3-分布式算法" aria-hidden="true">#</a> ◆ 10.6.3 分布式算法</h4>
<blockquote>
<blockquote>
<p>1.Lamport分布式算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.令牌传递法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>令牌（token）是进程在任何时间持有的一个实体，持有令牌的进程不必请求许可权就可以进入它的临界区。当进程离开它的临界区时，再将令牌传递给另一个进程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这个算法需要两个数据结构，一个是被传递的令牌，另一个是请求数组。令牌实际上也是一个数组，命名为token，它的第k个元素记录令牌最近访问进程Pk的时标。请求数组是每个进程一个，命名为request，它的第j个元素记录了自Pj以来最以来近接收的请求时标。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-7-分布式进程死锁问题" tabindex="-1"><a class="header-anchor" href="#◆-10-7-分布式进程死锁问题" aria-hidden="true">#</a> ◆ 10.7 分布式进程死锁问题</h3>
<blockquote>
<blockquote>
<p>分布式进程死锁问题</p>
</blockquote>
</blockquote>
<h4 id="◆-10-7-1-资源分配中的死锁" tabindex="-1"><a class="header-anchor" href="#◆-10-7-1-资源分配中的死锁" aria-hidden="true">#</a> ◆ 10.7.1 资源分配中的死锁</h4>
<blockquote>
<blockquote>
<p>解决死锁的办法是防止形成环路等待，或检测到实际或隐含的死锁存在时才实际解除。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式死锁管理中面临的困难是存在假死锁的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.死锁的预防</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）破坏环路等待条件，它是通过为资源类定义一个线性顺序来实现的。（2）破坏请求和保持条件，它是通过为运行进程分配所需全部资源，若不能同时满足所需的资源，则让其等待。这个方法的效率相对比较低：一方面，为满足资源请求，进程需长期等待；另一方面，进程在实际运行时可能只需要少量资源就可以前进，而绝大部分资源长时间不用，从而推迟了使用这些资源的其他进程的执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这两个方法都要求进程预先决定它的资源需求，这一般是不可能的。数据库应用中的很多例子说明了这个问题。在数据库应用中，绝大多数的数据新项都是动态加入数据库中的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在数据库应用中，每个事务（通常不用进程）在其整个生命期内都携带它创建时的时标，各事务严格按顺序建立。如果事务T2请求的是已经被事务T1使用的一个资源R，解决这个冲突是通过比较它们的时标来实现的，其目的在于防止形成环路等待条件。这里使用的两个方法，一个称为wait-die（等死）法，另一个叫wound-wait（损伤等待）法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.死锁的检测</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>采用死锁检测法，当进程请求资源时，只要有空闲未用的资源就立即满足其要求，之后才决定是否存在死锁。如果检测到一个死锁，则从涉及死锁的进程中选择一个进程，要求它释放必要的资源，以解除死锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式死锁检测的困难是每个结点仅知道它自己拥有的资源，而一个死锁可能涉及各个分布的资源。为此，可根据系统控制的方式是集中式、分层式还是分布式，采取不同的方法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果系统是集中式的控制，即有一个结点负责死锁检测。所有请求和释放资源的信息都发送给中心进程以及控制特定资源的进程。由于中心进程有一个完整的图形描述，它负责死锁的检测。这个方法需要很多的通信信息，而且一旦中心结点故障，算法将不起作用。另外，可能检测到假死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于分层控制，所有结点组成一个树形结构，一个结点充当树根。除叶结点外，所有结点都要收集所有相关结点的有关资源分配的信息。它允许在比根结点低的各级上进行死锁检测。尤其对于涉及一组资源的死锁进程，死锁的检测是由它们的公共祖先结点进行的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于分布式控制，系统中的所有进程合作实现死锁的检测。为此，相互之间必须交换相当多的时标信息，因此系统开销很大。</p>
</blockquote>
</blockquote>
<h4 id="◆-10-7-2-消息通信中的死锁" tabindex="-1"><a class="header-anchor" href="#◆-10-7-2-消息通信中的死锁" aria-hidden="true">#</a> ◆ 10.7.2 消息通信中的死锁</h4>
<blockquote>
<blockquote>
<p>消息通信中的死锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在消息通信中，当一组进程中的每一个进程都正等待该组的另一个成员进程发送消息，而又没有消息正在传输时，死锁发生。</p>
</blockquote>
</blockquote>
<h3 id="◆-习题-5" tabindex="-1"><a class="header-anchor" href="#◆-习题-5" aria-hidden="true">#</a> ◆ 习题</h3>
<blockquote>
<blockquote>
<p>习题1.举出分布式系统相对于集中式系统的优点和缺点。2.说明分布式系统的不同结构特点。3.集中式系统是否自动具有并发透明性这种特性？4.在设计分布式系统时，应该注意什么问题，努力实现哪些功能？5.一个试验型文件服务器在3/4的时间内能正常工作，而其他1/4时间不能正常工作，如果要达到99％的可用性，需要再复制几台这样的文件服务器？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>6.在OSI模型中网络协议分为7个层次，每个网络协议层各有何作用？7.在OSI模型的七层网络协议中，哪几个层是实现网络互联所必不可少的？为什么？8.在分层协议中，每一层都加有自己的信息头。显然只加上一个信息头效率会更高，可在该信息头包含所有的控制信息，而不用分散到各层里去。为什么不这样做？9.什么是客户机/服务器模型？客户机/服务器模型有哪些好处？10.要实现客户机和服务器之间的通信，需要有哪些通信协议？为什么？11.客户机/服务器模型致命的弱点是什么？如何去克服它？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>12.在许多系统中，在调用send时会启动一个计时器，以防止当服务器崩溃时，客户方永远地等待下去。假设有一个容错系统，客户机和服务器是用多处理机实现的，所以在这个系统中客户机或服务器崩溃的可能性基本上等于0。从这样的系统中去掉计时器是安全的吗？13.一般执行一个RPC包括哪些步骤？14.分布式系统中也可模拟单处理机中的死锁算法，应该如何模拟呢？15.怎样避免在分布式系统中检测出虚假的死锁呢？16.分布式文件系统的主要功能有哪些？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>17.在分布式系统中，一般采用什么方法保护文件？18.分布式文件系统中的目录有些什么功能？</p>
</blockquote>
</blockquote>
</div></template>


