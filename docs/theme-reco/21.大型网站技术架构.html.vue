<template><div><h3 id="大型网站技术架构" tabindex="-1"><a class="header-anchor" href="#大型网站技术架构" aria-hidden="true">#</a> 大型网站技术架构</h3>
<p>李智慧</p>
<h6 id="◆-1-1-大型网站软件系统的特点" tabindex="-1"><a class="header-anchor" href="#◆-1-1-大型网站软件系统的特点" aria-hidden="true">#</a> ◆ 1.1 大型网站软件系统的特点</h6>
<blockquote>
<blockquote>
<p>与传统企业应用系统相比，大型互联网应用系统有以下特点。高并发，大流量：需要面对高并发用户，大流量访问。Google日均PV数35亿，日均IP访问数3亿；腾讯QQ的最大在线用户数1.4亿（2011年数据）；淘宝2012年“双十一”活动一天交易额超过191亿，活动开始第一分钟独立访问用户达1000万。高可用：系统7×24小时不间断服务。大型互联网站的宕机事件通常会成为新闻焦点，例如2010年百度域名被黑客劫持导致不能访问，成为重大新闻热点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>海量数据：需要存储、管理海量数据，需要使用大量服务器。Facebook每周上传的照片数目接近10亿，百度收录的网页数目有数百亿，Google有近百万台服务器为全球用户提供服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户分布广泛，网络情况复杂</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在国内，还有各个运营商网络互通难的问题。而中美光缆的数次故障，也让一些对国外用户依赖较大的网站不得不考虑在海外建立数据中心。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>安全环境恶劣</p>
</blockquote>
</blockquote>
<h6 id="◆-1-2-大型网站架构演化发展历程" tabindex="-1"><a class="header-anchor" href="#◆-1-2-大型网站架构演化发展历程" aria-hidden="true">#</a> ◆ 1.2 大型网站架构演化发展历程</h6>
<blockquote>
<blockquote>
<p>随着网站业务的发展，一台服务器逐渐不能满足需求：越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足。这时就需要将应用和数据分离。应用和数据分离后整个网站使用三台服务器：应用服务器、文件服务器和数据库服务器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU；数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的硬盘和更大的内存；文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用缓存改善网站性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站访问特点和现实世界的财富分配一样遵循二八定律：80%的业务访问集中在20%的数据上。淘宝买家浏览的商品集中在少部分成交数多、评价良好的商品上；百度搜索关键词集中在少部分热门词汇上；只有经常登录的用户才会发微博、看微博，而这部分用户也只占总用户数目的一小部分。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>既然大部分的业务访问集中在一小部分数据上，那么如果把这一小部分数据缓存在内存中，是不是就可以减少数据库的访问压力，提高整个网站的数据访问速度，改善数据库的写入性能了呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站使用的缓存可以分为两种：缓存在应用服务器上的本地缓存和缓存在专门的分布式缓存服务器上的远程缓存。本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况。远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务，</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用缓存后，数据访问压力得到有效缓解，但是单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器成为整个网站的瓶颈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用应用服务器集群改善网站的并发处理能力</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力、存储空间不足时，不要企图去换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用服务器实现集群是网站可伸缩集群架构设计中较为简单成熟的一种</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站在使用缓存后，使绝大部分数据读操作访问都可以不通过数据库就能完成，但是仍有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作需要访问数据库，在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站利用数据库的这一功能，实现数据库读写分离，从而改善数据库负载压力，</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站需要加速网站访问速度。主要手段有使用CDN和反向代理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CDN和反向代理的基本原理都是缓存，区别在于CDN部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据；而反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户。使用CDN和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.7 使用分布式文件和分布式数据库系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据库部署在不同的物理服务器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>业务拆分</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段将整个网站业务分成不同的产品线，如大型购物交易网站就会将首页、商铺、订单、买家、卖家等拆分成不同的产品线，分归不同的业务团队负责。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将一个网站拆分成许多不同的应用，每个应用独立部署维护。应用之间可以通过一个超链接建立关系（在首页上的导航链接每个都指向不同的应用地址），也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1.9 应用拆分</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>既然每一个应用系统都需要执行许多相同的业务操作，比如用户管理、商品管理等，那么可以将这些共用的业务提取出来，独立部署。由这些可复用的业务连接数据库，提供共用业务服务，而应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作</p>
</blockquote>
</blockquote>
<h6 id="◆-1-3-大型网站架构演化的价值观" tabindex="-1"><a class="header-anchor" href="#◆-1-3-大型网站架构演化的价值观" aria-hidden="true">#</a> ◆ 1.3 大型网站架构演化的价值观</h6>
<blockquote>
<blockquote>
<p>大型网站架构技术的核心价值不是从无到有搭建一个大型网站，而是能够伴随小型网站业务的逐步发展，慢慢地演化成一个大型网站。在这个漫长的技术演化过程中，不需要放弃什么，不需要推翻什么，不需要剧烈的革命，就那么润物细无声地把一个只有一台服务器，几百个用户的小网站演化成一个几十万台服务器，数十亿用户的大网站。今天我们看到的大型网站，Google，Facebook，Taobao，Baidu莫不遵循这样的技术演化路线。</p>
</blockquote>
</blockquote>
<h6 id="◆-1-4-网站架构设计误区" tabindex="-1"><a class="header-anchor" href="#◆-1-4-网站架构设计误区" aria-hidden="true">#</a> ◆ 1.4 网站架构设计误区</h6>
<blockquote>
<blockquote>
<p>12306真正的问题其实不在于它的技术架构，而在于它的业务架构：12306根本就不应该在几亿中国人一票难求的情况下以窗口售票的模式在网上售票（零点开始出售若干天后的车票）。12306需要重构的不仅是它的技术架构，更重要的是它的业务架构：调整业务需求，换一种方式卖票，而不要去搞促销秒杀这种噱头式的游戏。后来证明12306确实是朝这个方向发展的：在售票方式上引入了排队机制、整点售票调整为分时段售票。其实如果能控制住并发访问的量，很多棘手的技术问题也就不是什么问题了。</p>
</blockquote>
</blockquote>
<h3 id="◆-2-大型网站架构模式" tabindex="-1"><a class="header-anchor" href="#◆-2-大型网站架构模式" aria-hidden="true">#</a> ◆ 2 大型网站架构模式</h3>
<blockquote>
<blockquote>
<p>我们的现实生活中充斥着几乎千篇一律的人生架构模式：读重点学校，选热门专业，进稳定高收入的政府部门和企业，找门当户对的配偶，生一个听话的孩子继续这个模式……但是人生不同于软件，精彩的人生绝不会来自于复制。</p>
</blockquote>
</blockquote>
<h6 id="◆-2-1-网站架构模式" tabindex="-1"><a class="header-anchor" href="#◆-2-1-网站架构模式" aria-hidden="true">#</a> ◆ 2.1 网站架构模式</h6>
<blockquote>
<blockquote>
<p>以实现网站高性能、高可用、易伸缩、可扩展、安全等各种技术架构目标。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分层是企业应用系统中最常见的一种架构模式，将系统在横向维度上切分成几个部分，每个部分负责一部分相对比较单一的职责，然后通过上层对下层的依赖和调用组成一个完整的系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分层结构在计算机世界中无处不在，网络的7层通信协议是一种分层结构；计算机硬件、操作系统、应用软件也可以看作是一种分层结构。在大型网站架构中也采用分层结构，将网站软件系统分为应用层、服务层、数据层</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实践中，大的分层结构内部还可以继续分层，如应用层可以再细分为视图层（美工负责）和业务逻辑层（工程师负责）；服务层也可以细分为数据接口层（适配各种输入和输出的数据格式）和逻辑处理层。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分层架构是逻辑上的，在物理部署上，三层结构可以部署在同一个物理机器上，但是随着网站业务的发展，必然需要对已经分层的模块分离部署，即三层结构分别部署在不同的服务器上，使网站拥有更多的计算资源以应对越来越多的用户访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分层是将软件在横向方面进行切分，那么分割就是在纵向方面对软件进行切分。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将这些不同的功能和服务分割开来，包装成高内聚低耦合的模块单元，一方面有助于软件的开发和维护；另一方面，便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站分割的粒度可能会很小。比如在应用层，将不同业务进行分割，例如将购物、论坛、搜索、广告分割成不同的应用，由独立的团队负责，部署在不同的服务器上；在同一个应用内部，如果规模庞大业务复杂，会继续进行分割，比如购物业务，可以进一步分割成机票酒店业务、3C业务，小商品业务等更细小的粒度。而即使在这个粒度上，还是可以继续分割成首页、搜索列表、商品详情等模块，这些模块不管在逻辑上还是物理部署上，都可以是独立的。同样在服务层也可以根据需要将服务分割成合适的模块。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于大型网站，分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。分布式意味着可以使用更多的计算机完成同样的功能，计算机越多，CPU、内存、存储资源也就越多，能够处理的并发访问和数据量就越大，进而能够为更多的用户提供服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式意味着服务调用必须通过网络，这可能会对性能造成比较严重的影响；其次，服务器越多，服务器宕机的概率也就越大，一台服务器宕机造成的服务不可用可能会导致很多应用不可访问，使网站可用性降低；</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据在分布式的环境中保持数据一致性也非常困难，分布式事务也难以保证，这对网站业务正确性和业务流程有可能造成很大影响；分布式还导致网站依赖错综复杂，开发管理维护困难。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在网站应用中，常用的分布式方案有以下几种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式应用和服务：将分层和分割后的应用和服务模块分布式部署，除了可以改善网站性能和并发性、加快开发和发布速度、减少数据库连接资源消耗外；还可以使不同应用复用共同的服务，便于业务功能扩展。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式静态资源</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站的静态资源如JS，CSS，Logo图片等资源独立分布式部署，并采用独立的域名，即人们常说的动静分离。静态资源分布式部署可以减轻应用服务器的负载压力；通过使用独立域名加快浏览器并发加载的速度；由负责用户体验的团队进行开发维护有利于网站分工合作，使不同技术工种术业有专攻。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式数据和存储</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式计算</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>包括搜索引擎的索引构建、数据仓库的数据分析统计等。这些业务的计算规模非常庞大，目前网站普遍使用Hadoop及其MapReduce分布式计算框架进行此类批处理计算，其特点是移动计算而不是移动数据，将计算程序分发到数据所在的位置以加速计算和分布式计算。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>还有可以支持网站线上服务器配置实时更新的分布式配置；分布式环境下实现并发和协同的分布式锁；支持云存储的分布式文件系统等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用分布式虽然已经将分层和分割后的模块独立部署，但是对于用户访问集中的模块（比如网站的首页），还需要将独立部署的服务器集群化，即多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同时因为一个应用由多台服务器提供，当某台服务器发生故障时，负载均衡设备或者系统的失效转移机制会将请求转发到集群中其他服务器上，使服务器故障不影响用户使用。所以在网站应用中，即使是访问量很小的分布式应用和服务，也至少要部署两台服务器构成一个小的集群，目的就是提高系统的可用性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓存就是将数据存放在距离计算最近的位置以加快处理速度。缓存是改善软件性能的第一手段，现代CPU越来越快的一个重要因素就是使用了更多的缓存，在复杂的软件设计中，缓存几乎无处不在。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CDN：即内容分发网络，部署在距离终端用户最近的网络服务商，用户的网络请求总是先到达他的网络服务商那里，在这里缓存网站的一些静态资源（较少变化的数据），可以就近以最快速度返回给用户，如视频网站和门户网站会将用户访问量大的热点内容缓存在CDN。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>反向代理：反向代理属于网站前端架构的一部分，部署在网站的前端，当用户请求到达网站的数据中心时，最先访问到的就是反向代理服务器，这里缓存网站的静态资源，无需将请求继续转发给应用服务器就能返回给用户。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本地缓存：在应用服务器本地缓存着热点数据，应用程序可以在本机内存中直接访问数据，而无需访问数据库。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式缓存：大型网站的数据量非常庞大，即使只缓存一小部分，需要的内存空间也不是单机能承受的，所以除了本地缓存，还需要分布式缓存，将数据缓存在一个专门的分布式缓存集群中，应用程序通过网络通信访问缓存数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用缓存有两个前提条件，一是数据访问热点不均衡，某些数据会被更频繁的访问，这些数据应该放在缓存中；二是数据在某个时间段内有效，不会很快过期，否则缓存的数据就会因已经失效而产生脏读，影响结果的正确性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>事物之间直接关系越少，就越少被彼此影响，越可以独立发展。大型网站架构中，系统解耦合的手段除了前面提到的分层、分割、分布等，还有一个重要手段是异步，业务之间的消息传递不是同步调用，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方式异步执行进行协作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在单一服务器内部可通过多线程共享内存队列的方式实现异步，处在业务操作前面的线程将输出写入到队列，后面的线程从队列中读取数据进行处理；在分布式系统中，多个服务器集群通过分布式消息队列实现异步，分布式消息队列可以看作内存队列的分布式部署。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用异步消息队列还有如下特性。提高系统可用性。消费者服务器发生故障，数据会在消息队列服务器中存储堆积，生产者服务器可以继续处理业务请求，系统整体表现无故障。消费者服务器恢复正常后，继续处理消息队列中的数据。加快网站响应速度。处在业务处理前端的生产者服务器在处理完业务请求后，将数据写入消息队列，不需要等待消费者服务器处理就可以返回，响应延迟减少。消除并发访问高峰。用户访问网站是随机的，存在访问高峰和低谷，即使网站按照一般访问高峰进行规划和部署，也依然会出现突发事件，比如购物网站的促销活动，微博上的热点事件，都会造成网站并发访问突然增大，这可能会造成整个网站负载过重，响应延迟，严重时甚至会出现服务宕机的情况。使用消息队列将突然增加的访问请求数据放入消息队列中，等待消费者服务器依次处理，就不会对整个网站负载造成太大压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>访问和负载很小的服务也必须部署至少两台服务器构成一个集群，其目的就是通过冗余实现服务高可用。数据库除了定期备份，存档保存，实现冷备份外，为了保证在线业务高可用，还需要对数据库进行主从分离，实时同步实现热备份。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了抵御地震、海啸等不可抗力导致的网站完全瘫痪，某些大型网站会对整个数据中心进行备份，全球范围内部署灾备数据中心。网站程序和数据实时同步到多个灾备数据中心。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前大型网站的自动化架构设计主要集中在发布运维方面。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过减少人为干预，使发布过程自动化可有效减少故障。发布过程包括诸多环节。自动化代码管理，代码版本控制、代码分支创建合并等过程自动化，开发工程师只要提交自己参与开发的产品代号，系统就会自动为其创建开发分支，后期会自动进行代码合并；自动化测试，代码开发完成，提交测试后，系统自动将代码部署到测试环境，启动自动化测试用例进行测试，向相关人员发送测试报告，向系统反馈测试结果；自动化安全检测，安全检测工具通过对代码进行静态安全扫描及部署到安全测试环境进行安全攻击测试，评估其安全性；最后进行自动化部署，将工程代码自动部署到线上生产环境。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站在运行过程中可能会遇到各种问题：服务器宕机、程序Bug、存储空间不足、突然爆发的访问高峰。网站需要对线上生产环境进行自动化监控，对服务器进行心跳检测，并监控其各项性能指标和应用程序的关键数据指标。如果发现异常、超出预设的阈值，就进行自动化报警，向相关人员发送报警信息，警告故障可能会发生。在检测到故障发生后，系统会进行自动化失效转移，将失效的服务器从集群中隔离出去，不再处理系统中的应用请求。待故障消除后，系统进行自动化失效恢复，重新启动服务，同步数据保证数据的一致性。在网站遇到访问高峰，超出网站最大处理能力时，为了保证整个网站的安全可用，还会进行自动化降级，通过拒绝部分请求及关闭部分不重要的服务将系统负载降至一个安全的水平，必要时，还需要自动化分配资源，将空闲资源分配给重要的服务，扩大其部署规模。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站在安全架构方面也积累了许多模式：通过密码和手机校验码进行身份认证；登录、交易等操作需要对网络通信进行加密，网站服务器上存储的敏感数据如用户信息等也进行加密处理；为了防止机器人程序滥用网络资源攻击网站，网站使用验证码进行识别；对于常见的用于攻击网站的XSS攻击、SQL注入、进行编码转换等相应处理；对于垃圾信息、敏感信息进行过滤；对交易转账等重要操作根据交易模式和交易信息进行风险控制。</p>
</blockquote>
</blockquote>
<h6 id="◆-2-2-架构模式在新浪微博的应用" tabindex="-1"><a class="header-anchor" href="#◆-2-2-架构模式在新浪微博的应用" aria-hidden="true">#</a> ◆ 2.2 架构模式在新浪微博的应用</h6>
<blockquote>
<blockquote>
<p>[插图]图2.1 新浪微博的系统架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统分为三个层次，最下层是基础服务层，提供数据库、缓存、存储、搜索等数据服务，以及其他一些基础技术服务，这些服务支撑了新浪微博的海量数据和高并发访问，是整个系统的技术基础。中间层是平台服务和应用服务层，新浪微博的核心服务是微博、关系和用户，它们是新浪微博业务大厦的支柱。这些服务被分割为独立的服务模块，通过依赖调用和共享基础数据构成新浪微博的业务基础。最上层是API和新浪微博的业务层，各种客户端（包括Web网站）和第三方应用，通过调用API集成到新浪微博的系统中，共同组成一个生态系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在新浪微博的早期架构中，微博发布使用同步推模式，用户发表微博后系统会立即将这条微博插入到数据库所有粉丝的订阅列表中，当用户量比较大时，特别是明星用户发布微博时，会引起大量的数据库写操作，超出数据库负载，系统性能急剧下降，用户响应延迟加剧。后来新浪微博改用异步推拉结合的模式，用户发表微博后系统将微博写入消息队列后立即返回，用户响应迅速，消息队列消费者任务将微博推送给所有当前在线粉丝的订阅列表中，非在线用户登录后再根据关注列表拉取微博订阅列表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于微博频繁刷新，新浪微博使用多级缓存策略，热门微博和明星用户的微博缓存在所有的微博服务器上，在线用户的微博和近期微博缓存在分布式缓存集群中，对于微博操作中最常见的“刷微博”操作，几乎全部都是缓存访问操作，可以获得很好的系统性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了提高系统的整体可用性和性能，新浪微博启用了多个数据中心。这些数据中心既是地区用户访问中心，用户可以就近访问最近的数据中心以加快访问速度，改善系统性能；同时也是数据冗余复制的灾备中心，所有的用户和微博数据通过远程消息系统在不同的数据中心之间同步，提高系统可用性。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-性能" tabindex="-1"><a class="header-anchor" href="#◆-3-1-性能" aria-hidden="true">#</a> ◆ 3.1 性能</h3>
<blockquote>
<blockquote>
<p>在浏览器端，可以通过浏览器缓存、使用页面压缩、合理布局页面、减少Cookie传输等手段改善性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>还可以使用CDN，将网站静态内容分发至离用户最近的网络服务商机房，使用户通过最短访问路径获取数据。可以在网站机房部署反向代理服务器，缓存热点文件，加快请求响应速度，减轻应用服务器负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在应用服务器端，可以使用服务器本地缓存和分布式缓存，通过缓存在内存中的热点数据处理用户请求，加快请求处理过程，减轻数据库负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>也可以通过异步操作将用户请求发送至消息队列等待后续任务处理，而当前请求直接返回响应给用户。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在网站有很多用户高并发请求的情况下，可以将多台应用服务器组成一个集群共同对外服务，提高整体处理能力，改善性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在代码层面，也可以通过使用多线程、改善内存管理等手段优化性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>衡量网站性能有一系列指标，重要的有响应时间、TPS、系统性能计数器等，通过测试这些指标以确定系统设计是否达到目标。这些指标也是网站监控的重要参数，通过监控这些指标可以分析系统瓶颈，预测网站容量，并对异常指标进行报警，保障系统可用性。</p>
</blockquote>
</blockquote>
<h6 id="◆-3-2-可用性" tabindex="-1"><a class="header-anchor" href="#◆-3-2-可用性" aria-hidden="true">#</a> ◆ 3.2 可用性</h6>
<blockquote>
<blockquote>
<p>对于应用服务器而言，多台应用服务器通过负载均衡设备组成一个集群共同对外提供服务，任何一台服务器宕机，只需把请求切换到其他服务器就可实现应用的高可用，但是一个前提条件是应用服务器上不能保存请求的会话信息。否则服务器宕机，会话丢失，即使将用户请求转发到其他服务器上也无法完成业务处理。对于存储服务器，由于其上存储着数据，需要对数据进行实时备份，当服务器宕机时需要将数据访问转移到可用的服务器上，并进行数据恢复以保证继续有服务器宕机的时候数据依然可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了运行环境，网站的高可用还需要软件开发过程的质量保证。通过预发布验证、自动化测试、自动化发布、灰度发布等手段，减少将故障引入线上环境的可能，避免故障范围扩大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>衡量一个系统架构设计是否满足高可用的目标，就是假设系统中任何一台或者多台服务器宕机时，以及出现各种不可预期的问题时，系统整体是否依然可用。</p>
</blockquote>
</blockquote>
<h6 id="◆-3-3-伸缩性" tabindex="-1"><a class="header-anchor" href="#◆-3-3-伸缩性" aria-hidden="true">#</a> ◆ 3.3 伸缩性</h6>
<blockquote>
<blockquote>
<p>所谓伸缩性是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>衡量架构伸缩性的主要标准就是是否可以用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来的服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于应用服务器集群，只要服务器上不保存数据，所有服务器都是对等的，通过使用合适的负载均衡设备就可以向集群中不断加入服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于缓存服务器集群，加入新的服务器可能会导致缓存路由失效，进而导致集群中大部分缓存数据都无法访问。虽然缓存的数据可以通过数据库重新加载，但是如果应用已经严重依赖缓存，可能会导致整个网站崩溃。需要改进缓存路由算法保证缓存数据的可访问性。</p>
</blockquote>
</blockquote>
<h6 id="◆-3-4-扩展性" tabindex="-1"><a class="header-anchor" href="#◆-3-4-扩展性" aria-hidden="true">#</a> ◆ 3.4 扩展性</h6>
<blockquote>
<blockquote>
<p>网站快速发展，功能不断扩展，如何设计网站的架构使其能够快速响应需求变化，是网站可扩展架构主要的目的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>衡量网站架构扩展性好坏的主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站可伸缩架构的主要手段是事件驱动架构和分布式服务。</p>
</blockquote>
</blockquote>
<h6 id="◆-3-5-安全性" tabindex="-1"><a class="header-anchor" href="#◆-3-5-安全性" aria-hidden="true">#</a> ◆ 3.5 安全性</h6>
<blockquote>
<blockquote>
<p>衡量网站安全架构的标准就是针对现存和潜在的各种攻击与窃密手段，是否有可靠的应对策略。</p>
</blockquote>
</blockquote>
<h3 id="◆-第2篇-架构" tabindex="-1"><a class="header-anchor" href="#◆-第2篇-架构" aria-hidden="true">#</a> ◆ 第2篇 架构</h3>
<blockquote>
<blockquote>
<p>什么叫高性能的网站？两个网站性能架构设计方案：A方案和B方案，A方案在小于100个并发用户访问时，每个请求的响应时间是1秒，当并发请求达到200的时候，请求的响应时间将骤增到10秒。B方案不管是100个并发用户访问还是200个并发用户访问，每个请求的响应时间都差不多是1.5秒。哪个方案的性能好？如果老板说“我们要改善网站的性能”，他指的是什么？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同类型的两个网站，X网站服务器平均每个请求的处理时间是500毫秒，Y网站服务器平均每个请求的处理时间是1000毫秒，为什么用户却反映Y网站的速度快呢？</p>
</blockquote>
</blockquote>
<h6 id="◆-4-1-网站性能测试" tabindex="-1"><a class="header-anchor" href="#◆-4-1-网站性能测试" aria-hidden="true">#</a> ◆ 4.1 网站性能测试</h6>
<blockquote>
<blockquote>
<p>在实践中，使用一些前端架构优化手段，通过优化页面HTML式样、利用浏览器端的并发和异步特性、调整浏览器缓存策略、使用CDN服务、反向代理等手段，使浏览器尽快地显示用户感兴趣的内容、尽可能近地获取页面内容，即使不优化应用程序和架构，也可以很大程度地改善用户视角下的网站性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>开发人员关注的主要是应用程序本身及其相关子系统的性能，包括响应延迟、系统吞吐量、并发处理能力、系统稳定性等技术指标。主要的优化手段有使用缓存加速数据读取，使用集群提高吞吐能力，使用异步消息加快请求响应及实现削峰，使用代码优化手段改善程序性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>运维人员更关注基础设施性能和资源利用率，如网络运营商的带宽能力、服务器硬件的配置、数据中心网络架构、服务器和网络带宽的资源利用率等。主要优化手段有建设优化骨干网、使用高性价比定制服务器、利用虚拟化技术优化资源利用等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>测试程序通过模拟应用程序，记录收到响应和发出请求之间的时间差来计算系统响应时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>测试程序通过多线程模拟并发用户的办法来测试系统的并发处理能力，为了真实模拟用户行为，测试程序并不是启动多线程然后不停地发送请求，而是在两次请求之间加入一个随机等待时间，这个时间被称作思考时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>指单位时间内系统处理的请求数量</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于网站，可以用“请求数/秒”或是“页面数/秒”来衡量，也可以用“访问人数/天”或是“处理的业务数/小时”等来衡量。TPS（每秒事务数）是吞吐量的一个常用量化指标，此外还有HPS（每秒HTTP请求数）、QPS（每秒查询数）等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>性能测试是一个总称，具体可细分为性能测试、负载测试、压力测试、稳定性测试。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>排查一个网站的性能瓶颈和排查一个程序的性能瓶颈的手法基本相同：检查请求处理的各个环节的日志，分析哪个环节响应时间不合理、超过预期；然后检查监控数据，分析影响性能的主要因素是内存、磁盘、网络、还是CPU，是代码问题还是架构设计不合理，或者系统资源确实不足。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>定位产生性能问题的具体原因后，就需要进行性能优化，根据网站分层架构，可分为Web前端性能优化、应用服务器性能优化、存储服务器性能优化3大类。</p>
</blockquote>
</blockquote>
<h6 id="◆-4-2-web前端性能优化" tabindex="-1"><a class="header-anchor" href="#◆-4-2-web前端性能优化" aria-hidden="true">#</a> ◆ 4.2 Web前端性能优化</h6>
<blockquote>
<blockquote>
<p>一般说来Web前端指网站业务逻辑之前的部分，包括浏览器加载、网站视图模型、图片服务、CDN服务等，主要优化手段有优化浏览器访问、使用反向代理、CDN等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.减少http请求</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>减少HTTP的主要手段是合并CSS、合并JavaScript、合并图片。将浏览器一次访问需要的JavaScript、CSS合并成一个文件，这样浏览器就只需要一次请求。图片也可以合并，多张图片合并成一张，如果每张图片都有不同的超链接，可通过CSS偏移响应鼠标点击操作，构造不同的URL。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CDN能够缓存的一般是静态资源，如图片、文件、CSS、Script脚本、静态网页等，但是这些文件访问频度很高，将其缓存在CDN可极大改善网页的打开速度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>传统代理服务器位于浏览器一侧，代理浏览器将HTTP请求发送到互联网上，而反向代理服务器位于网站机房一侧，代理网站Web服务器接收HTTP请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>和传统代理服务器可以保护浏览器安全一样，反向代理服务器也具有保护网站安全的作用，来自互联网的访问请求必须经过代理服务器，相当于在Web服务器和可能的网络攻击之间建立了一个屏障。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了安全功能，代理服务器也可以通过配置缓存功能加速Web请求。当用户第一次访问静态内容的时候，静态内容就被缓存在反向代理服务器上，这样当其他用户访问该静态内容的时候，就可以直接从反向代理服务器返回，加速Web请求响应速度，减轻Web服务器负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>反向代理也可以实现负载均衡的功能，而通过负载均衡构建的应用集群可以提高系统总体处理能力，进而改善网站高并发情况下的性能。</p>
</blockquote>
</blockquote>
<h6 id="◆-4-3-应用服务器性能优化" tabindex="-1"><a class="header-anchor" href="#◆-4-3-应用服务器性能优化" aria-hidden="true">#</a> ◆ 4.3 应用服务器性能优化</h6>
<blockquote>
<blockquote>
<p>网站性能优化第一定律：优先考虑使用缓存优化性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓存指将数据存储在相对较高访问速度的存储介质中，以供系统处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓存的本质是一个内存Hash表，网站应用中，数据缓存以一对Key、Value的形式存储在内存Hash表中。Hash表数据读写的时间复杂度为O（1）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>计算KV对中Key的HashCode对应的Hash表索引，可快速访问Hash表中的数据。许多语言支持获得任意对象的HashCode，可以把HashCode理解为对象的唯一标示符，Java语言中Hashcode方法包含在根对象Object中，其返回值是一个Int。然后通过Hashcode计算Hash表的索引下标，最简单的是余数法，使用Hash表数组长度对Hashcode求余，余数即为Hash表索引，使用该索引可直接访问得到Hash表中存储的KV对。Hash表是软件开发中常用到的一种数据结构，其设计思想在很多场景下都可以应用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站数据访问通常遵循二八定律，即80%的访问落在20%的数据上，因此利用Hash表和内存的高速访问特性，将这20%的数据缓存起来，可很好地改善系统性能，提高数据读取速度，降低存储访问压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实践中，有的网站通过缓存热备等手段提高缓存可用性：当某台缓存服务器宕机时，将缓存访问切换到热备服务器上。但是这种设计显然有违缓存的初衷，缓存根本就不应该被当做一个可靠的数据源来使用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。当一台缓存服务器宕机的时候，只有部分缓存数据丢失，重新从数据库加载这部分数据不会对数据库产生很大影响。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓存中存放的是热点数据，热点数据又是缓存系统利用LRU（最近最久未用算法）对不断访问的数据筛选淘汰出来的，这个过程需要花费较长的时间。新启动的缓存系统如果没有任何数据，在重建缓存数据的过程中，系统的性能和数据库负载都不太好，那么最好在缓存系统启动时就把热点数据加载好，这个缓存预加载手段叫作缓存预热（warm up）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果因为不恰当的业务、或者恶意攻击持续高并发地请求某个不存在的数据，由于缓存没有保存该数据，所有的请求都会落到数据库上，会对数据库造成很大压力，甚至崩溃。一个简单的对策是将不存在的数据也缓存起来（其value值为null）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Memcached采用一种集中式的缓存集群管理，也被称作互不通信的分布式架构方式。缓存与应用分离部署，缓存系统部署在一组专门的服务器上，应用程序通过一致性Hash等路由算法选择缓存服务器远程访问缓存数据，缓存服务器之间不通信，缓存集群的规模可以很容易地实现扩容，具有良好的可伸缩性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Memcached曾一度是网站分布式缓存的代名词，被大量网站使用。其简单的设计、优异的性能、互不通信的服务器集群、海量数据可伸缩的架构令网站架构师们趋之若鹜。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>远程通信设计需要考虑两方面的要素，一是通信协议，即选择TCP协议还是UDP协议，抑或HTTP协议；一是通信序列化协议，数据传输的两端，必须使用彼此可识别的数据序列化方式才能使通信得以完成，如XML、JSON等文本序列化协议，或者Google Protobuffer等二进制序列化协议。Memcached使用TCP协议（UDP也支持）通信，其序列化协议则是一套基于文本的自定义协议，非常简单，以一个命令关键字开头，后面是一组命令操作数。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Memcached服务端通信模块基于Libevent，一个支持事件触发的网络通信程序库。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>内存管理中一个令人头痛的问题就是内存碎片管理。操作系统、虚拟机垃圾回收在这方面想了许多办法：压缩、复制等。Memcached使用了一个非常简单的办法——固定空间分配。Memcached将内存空间分为一组slab，每个slab里又包含一组chunk，同一个slab里的每个chunk的大小是固定的，拥有相同大小chunk的slab被组织在一起，叫作slab_class，</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储数据时根据数据的Size大小，寻找一个大于Size的最小chunk将数据写入。这种内存管理方式避免了内存碎片管理的问题，内存的分配和释放都是以chunk为单位的。和其他缓存一样，Memcached采用LRU算法释放最近最久未被访问的数据占用的空间，释放的chunk被标记为未用，等待下一个合适大小数据的写入。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4.11 Memcached内存管理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当然这种方式也会带来内存浪费的问题。数据只能存入一个比它大的chunk里，而一个chunk只能存一个数据，其他空间被浪费了。如果启动参数配置不合理，浪费会更加惊人，发现没有缓存多少数据，内存空间就用尽了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>而其客户端路由算法一致性Hash更成为数据存储伸缩性架构设计的经典范式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>正是集群内服务器互不通信使得集群可以做到几乎无限制的线性伸缩，这也正是目前流行的许多大数据技术的基本架构特点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用消息队列将调用异步化，可改善网站的扩展性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用消息队列还可改善网站系统的性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4.12 不使用消息队列服务器[插图]图4.13 使用消息队列服务器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于消息队列服务器处理速度远快于数据库（消息队列服务器也比数据库具有更好的伸缩性），因此用户的响应延迟可得到有效改善。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>需要注意的是，由于数据写入消息队列后立即返回给用户，数据在后续的业务校验、写数据库等操作可能失败，因此在使用消息队列进行业务异步处理后，需要适当修改业务流程进行配合，如订单提交后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单，甚至商品出库后，再通过电子邮件或SMS消息通知用户订单成功，以免交易纠纷。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任何可以晚点做的事情都应该晚点再做。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在网站高并发访问的场景下，使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发访问请求分发到多台服务器上处理，避免单一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性，</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>三台Web服务器共同处理来自用户浏览器的访问请求，这样每台Web服务器需要处理的http请求只有总并发请求数的三分之一，根据性能测试曲线，使服务器的并发请求数目控制在最佳运行区间，获得最佳的访问请求延迟。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>多用户并发访问是网站的基本需求，大型网站的并发用户数会达到数万，单台服务器的并发用户也会达到数百。CGI编程时代，每个用户请求都会创建一个独立的系统进程去处理。由于线程比进程更轻量，更少占有系统资源，切换代价更小，所以目前主要的Web应用服务器都采用多线程的方式响应并发用户请求，因此网站开发天然就是多线程编程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从资源利用的角度看，使用多线程的原因主要有两个：IO阻塞与多CPU。当前线程进行IO处理的时候，会被阻塞释放CPU以等待IO操作完成，由于IO操作（不管是磁盘IO还是网络IO）通常都需要较长的时间，这时CPU可以调度其他的线程进行处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>理想的系统Load是既没有进程（线程）等待也没有CPU空闲，利用多线程IO阻塞与执行交替进行，可最大限度地利用CPU资源。使用多线程的另一个原因是服务器有多个CPU，在这个连手机都有四核CPU的时代，除了最低配置的虚拟机，一般数据中心的服务器至少16核CPU，要想最大限度地使用这些CPU，必须启动多线程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一台服务器上启动多少线程合适呢？假设服务器上执行的都是相同类型任务，针对该类任务启动的线程数有个简化的估算公式可供参考：启动线程数=[任务执行时间/（任务执行时间-IO等待时间）]×CPU内核数</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最佳启动线程数和CPU内核数量成正比，和IO阻塞时间成反比。如果任务都是CPU计算型任务，那么线程数最多不超过CPU内核数，因为启动再多线程，CPU也来不及调度；相反如果是任务需要等待磁盘操作，网络响应，那么多启动线程有助于提高任务并发度，提高系统吞吐能力，改善系统性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>多线程编程一个需要注意的问题是线程安全问题，即多线程并发对某个资源进行修改，导致数据混乱。这也是缺乏经验的网站工程师最容易犯错的地方，而线程安全Bug又难以测试和重现，网站故障中，许多所谓偶然发生的“灵异事件”都和多线程并发问题有关。对网站而言，不管有没有进行多线程编程，工程师写的每一行代码都会被多线程执行，因为用户请求是并发提交的，也就是说，所有的资源——对象、内存、文件、数据库，乃至另一个线程都可能被多线程并发访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>解决线程安全的主要手段有如下几点。将对象设计为无状态对象</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Java Web开发中常用的Servlet对象就设计为无状态对象，可以被应用服务器多线程并发调用处理用户请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用局部对象：即在方法内部创建对象，这些对象会被每个进入该方法的线程创建，除非程序有意识地将这些对象传递给其他线程，否则不会出现对象被多线程并发访问的情形。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>并发访问资源时使用锁：即多线程访问资源的时候，通过锁的方式使多线程并发操作转化为顺序操作，从而避免资源被并发修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>各种轻量级锁，使得运行期线程获取锁和释放锁的代价都变得更小，但是锁导致线程同步顺序执行，可能会对系统性能产生严重影响。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统运行时，要尽量减少那些开销很大的系统资源的创建和销毁，比如数据库连接、网络通信连接、线程、复杂对象等。从编程角度，资源复用主要有两种模式：单例（Singleton）和对象池（Object Pool）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>单例虽然是GoF经典设计模式中较多被诟病的一个模式，但由于目前Web开发中主要使用贫血模式，从Service到Dao都是些无状态对象，无需重复创建，使用单例模式也就自然而然了。事实上，Java开发常用的对象容器Spring默认构造的对象都是单例（需要注意的是Spring的单例是Spring容器管理的单例，而不是用单例模式构造的单例）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对象池模式通过复用对象实例，减少对象创建和资源消耗。对于数据库连接对象，每次创建连接，数据库服务端都需要创建专门的资源以应对，因此频繁创建关闭数据库连接，对数据库服务器而言是灾难性的，同时频繁创建关闭连接也需要花费较长的时间。因此在实践中，应用程序的数据库连接基本都使用连接池（ConnectionPool）的方式。数据库连接对象创建好以后，将连接对象放入对象池容器中，应用程序要连接的时候，就从对象池中获取一个空闲的连接使用，使用完毕再将该对象归还到对象池中即可，不需要创建新的连接。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于每个Web请求（HTTP Request），Web应用服务器都需要创建一个独立的线程去处理，这方面，应用服务器也采用线程池（Thread Pool）的方式。这些所谓的连接池、线程池，本质上都是对象池，即连接、线程都是对象，池管理方式也基本相同。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>前面缓存部分已经描述过Hash表的基本原理，Hash表的读写性能在很大程度上依赖HashCode的随机性，即HashCode越随机散列，Hash表的冲突就越少，读写性能也就越高，目前比较好的字符串Hash散列算法有Time33算法，即对字符串逐字符迭代乘以33，求得Hash值，算法原型为：hash(i) = hash(i-1) * 33 + str[i]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果Web应用运行在JVM等具有垃圾回收功能的环境中，那么垃圾回收可能会对系统的性能特性产生巨大影响。理解垃圾回收机制有助于程序优化和参数调优，以及编写内存安全的代码。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以JVM为例，其内存主要可划分为堆（heap）和堆栈（stack）。堆栈用于存储线程上下文信息，如方法参数、局部变量等。堆则是存储对象的内存空间，对象的创建和释放、垃圾回收就在这里进行。通过对对象生命周期的观察，发现大部分对象的生命周期都极其短暂，这部分对象产生的垃圾应该被更快地收集，以释放内存，这就是JVM分代垃圾回收，其基本原理如图4.17所示。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在JVM分代垃圾回收机制中，将应用程序可用的堆空间分为年轻代（YoungGeneration）和年老代（Old Generation），又将年轻代分为Eden区（EdenSpace）、From区和To区，新建对象总是在Eden区中被创建，当Eden区空间已满，就触发一次Young GC（Garbage Collection，垃圾回收），将还被使用的对象复制到From区，这样整个Eden区都是未被使用的空间，可供继续创建对象，当Eden区再次用完，再触发一次Young GC，将Eden区和From区还在被使用的对象复制到To区，下一次Young GC则是将Eden区和To区还被使用的对象复制到From区。因此，经过多次Young GC，某些对象会在From区和To区多次复制，如果超过某个阈值对象还未被释放，则将该对象复制到Old Generation。如果OldGeneration空间也已用完，那么就会触发Full GC，即所谓的全量回收，全量回收会对系统性能产生较大影响，因此应根据系统业务特点和对象生命周期，合理设置Young Generation和Old Generation大小，尽量减少Full GC。事实上，某些Web应用在整个运行期间可以做到从不进行Full GC。</p>
</blockquote>
</blockquote>
<h6 id="◆-4-4-存储性能优化" tabindex="-1"><a class="header-anchor" href="#◆-4-4-存储性能优化" aria-hidden="true">#</a> ◆ 4.4 存储性能优化</h6>
<blockquote>
<blockquote>
<p>机械硬盘是目前最常用的一种硬盘，通过马达驱动磁头臂，带动磁头到指定的磁盘位置访问数据，由于每次访问数据都需要移动磁头臂，因此机械硬盘在数据连续访问（要访问的数据存储在连续的磁盘空间上）和随机访问（要访问的数据存储在不连续的磁盘空间）时，由于移动磁头臂的次数相差巨大，性能表现差别也非常大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>固态硬盘又称作SSD或Flash硬盘，这种硬盘没有机械装置，数据存储在可持久记忆的硅晶体上，因此可以像内存一样快速随机访问。而且SSD具有更小的功耗和更少的磁盘震动与噪声。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在网站应用中，大部分应用访问数据都是随机的，这种情况下SSD具有更好的性能表现。但是目前SSD硬盘还不太成熟，可靠性、性价比有待提升，因此SSD的使用还在摸索阶段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于传统的机械磁盘具有快速顺序读写、慢速随机读写的访问特性，这个特性对磁盘存储结构和算法的选择影响甚大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了改善数据访问特性，文件系统或数据库系统通常会对数据排序后存储，加快数据检索速度，这就需要保证数据在不断更新、插入、删除后依然有序，传统关系数据库的做法是使用B+树</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4.20 B+树原理示意图B+树是一种专门针对磁盘存储而优化的N叉排序树，以树节点为单位存储在磁盘中，从根开始查找所需数据所在的节点编号和磁盘位置，将其加载到内存中然后继续查找，直到找到所需的数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前数据库多采用两级索引的B+树，树的层次最多三层。因此可能需要5次磁盘访问才能更新一条记录（三次磁盘访问获得数据索引及行ID，然后再进行一次数据文件读操作及一次数据文件写操作）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>但是由于每次磁盘访问都是随机的，而传统机械硬盘在数据随机访问时性能较差，每次数据访问都需要多次访问磁盘影响数据访问性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前许多NoSQL产品采用LSM树作为主要数据结构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>LSM树可以看作是一个N阶合并树。数据写操作（包括插入、修改、删除）都在内存中进行，并且都会创建一个新记录（修改会记录新的数据值，而删除会记录一个删除标志），这些数据在内存中仍然还是一棵排序树，当数据量超过设定的内存阈值后，会将这棵排序树和磁盘上最新的排序树合并。当这棵排序树的数据量也超过设定阈值后，和磁盘上下一级的排序树合并。合并过程中，会用最新更新的数据覆盖旧的数据（或者记录为不同版本）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作为存储结构，B+树不是关系数据库所独有的，NoSQL数据库也可以使用B+树。同理，关系数据库也可以使用LSM，而且随着SSD硬盘的日趋成熟及大容量持久存储的内存技术的出现，相信B+树这一“古老”的存储结构会再次焕发青春。</p>
</blockquote>
</blockquote>
<h6 id="◆-4-5-小结" tabindex="-1"><a class="header-anchor" href="#◆-4-5-小结" aria-hidden="true">#</a> ◆ 4.5 小结</h6>
<blockquote>
<blockquote>
<p>网站性能优化的主要工作是改善高并发用户访问情况下的网站响应速度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当老板说“我们要改善网站性能”的时候，他期望的是在A方案的基础上，不管是100个并发访问还是200个并发访问，响应时间都能达到1秒。而架构师能做到的，则是利用分布式的方案改善网站并发特性，由于分布式不可避免地会带来架构复杂、网络通信延迟等问题，所以最终设计出来的可能是B方案：缩短高并发访问响应延迟的同时，却延长了原来低并发访问时的响应延迟。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>即使在技术层面，性能优化也需要全面考虑，综合权衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以Google为首的互联网企业领跑IT前沿技术潮流，是因为互联网企业的业务发展远超传统IT企业领域，面临更多挑战，对IT系统提出了更高的要求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>新技术的出现又会驱动企业开展新的业务。亚马逊等互联网公司利用自己的技术优势进军企业级市场，以技术驱动业务，开展云计算、SaaS等新兴IT业务，逐步蚕食IBM、HP、Oracle、微软等传统软件巨头的市场。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-万无一失-网站的高可用架构" tabindex="-1"><a class="header-anchor" href="#◆-5-万无一失-网站的高可用架构" aria-hidden="true">#</a> ◆ 5 万无一失：网站的高可用架构</h3>
<blockquote>
<blockquote>
<p>网站的可用性（Availability）描述网站可有效访问的特性（不同于另一个网站运营指标：Usability，通常也被译作可用性，但是后者强调的是网站的有用性，即对最终用户的使用价值），相比于网站的其他非功能特性，网站的可用性更牵动人们的神经，大型网站的不可用事故直接影响公司形象和利益，许多互联网公司都将网站可用性列入工程师的绩效考核，与奖金升迁等利益挂钩。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-1-网站可用性的度量与考核" tabindex="-1"><a class="header-anchor" href="#◆-5-1-网站可用性的度量与考核" aria-hidden="true">#</a> ◆ 5.1 网站可用性的度量与考核</h6>
<blockquote>
<blockquote>
<p>表5.1 网站故障分类权重表示例[插图]故障分的计算公式为：故障分=故障时间（分钟）× 故障权重</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在年初或者考核季度的开始，会根据网站产品的可用性指标计算总的故障分，然后根据团队和个人的职责角色分摊故障分，这个可用性指标和故障分是管理预期。在实际发生故障的时候，根据故障分类和责任划分将故障产生的故障分分配给责任者承担。等年末或者考核季度末的时候，个人及团队实际承担的故障分如果超过了年初分摊的故障分，绩效考核就会受到影响。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-2-高可用的网站架构" tabindex="-1"><a class="header-anchor" href="#◆-5-2-高可用的网站架构" aria-hidden="true">#</a> ◆ 5.2 高可用的网站架构</h6>
<blockquote>
<blockquote>
<p>网站的高可用架构设计的主要目的就是保证服务器硬件故障时服务依然可用、数据依然保存并能够被访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实现上述高可用架构的主要手段是数据和服务的冗余备份及失效转移，一旦某些服务器宕机，就将服务切换到其他可用的服务器上，如果磁盘损坏，则从备份的磁盘读取数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个典型的网站设计通常遵循如图5.2所示的基本分层架构模型。[插图]图5.2 网站架构基本分层模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>典型的分层模型是三层，即应用层、服务层、数据层；各层之间具有相对独立性，应用层主要负责具体业务逻辑处理；服务层负责提供可复用的服务；数据层负责数据的存储与访问。中小型网站在具体部署时，通常将应用层和服务层部署在一起，而数据层则另外部署</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5.4 分层后按模块分割的网站架构模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>位于应用层的服务器通常为了应对高并发的访问请求，会通过负载均衡设备将一组服务器组成一个集群共同对外提供服务，当负载均衡设备通过心跳检测等手段监控到某台应用服务器不可用时，就将其从集群列表中剔除，并将请求分发到集群中其他可用的服务器上，使整个集群保持可用，从而实现应用高可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>位于数据层的服务器情况比较特殊，数据服务器上存储着数据，为了保证服务器宕机时数据不丢失，数据访问服务不中断，需要在数据写入时进行数据同步复制，将数据写入多台服务器上，实现数据冗余备份。当数据服务器宕机时，应用程序将访问切换到有备份数据的服务器上。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-3-高可用的应用" tabindex="-1"><a class="header-anchor" href="#◆-5-3-高可用的应用" aria-hidden="true">#</a> ◆ 5.3 高可用的应用</h6>
<blockquote>
<blockquote>
<p>不保存状态的应用给高可用的架构设计带来了巨大便利，既然服务器不保存请求的状态，那么所有的服务器完全对等，当任意一台或多台服务器宕机，请求提交给集群中其他任意一台可用机器处理，这样对终端用户而言，请求总是能够成功的，整个系统依然可用。对于应用服务器集群，实现这种服务器可用状态实时监测、自动转移失败任务的机制是负载均衡。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>负载均衡，顾名思义，主要使用在业务量和数据量较高的情况下，当单台服务器不足以承担所有的负载压力时，通过负载均衡手段，将流量和数据分摊到一个集群组成的多台服务器上，以提高整体的负载处理能力。目前，不管是开源免费的负载均衡软件还是昂贵的负载均衡硬件，都提供失效转移功能。在网站应用中，当集群中的服务是无状态对等时，负载均衡可以起到事实上高可用的作用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群环境下，Session管理主要有以下几种手段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.Session复制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用服务器开启Web容器的Session复制功能，在集群中的几台服务器之间同步Session对象，使得每台服务器上都保存所有用户的Session信息，这样任何一台机器宕机都不会导致Session数据的丢失，而服务器使用Session时，也只需要在本机获取即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种方案虽然简单，从本机读取Session信息也很快速，但只能使用在集群规模比较小的情况下。当集群规模较大时，集群服务器间需要大量的通信进行Session复制，占用服务器和网络的大量资源，系统不堪负担。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.Session绑定Session绑定可以利用负载均衡的源地址Hash算法实现，负载均衡服务器总是将来源于同一IP的请求分发到同一台服务器上（也可以根据Cookie信息将同一个用户的请求总是分发到同一台服务器上，当然这时负载均衡服务器必须工作在HTTP协议层上，关于负载均衡算法的更多信息请参考本书第6章内容。这样在整个会话期间，用户所有的请求都在同一台服务器上处理，即Session绑定在某台特定服务器上，保证Session总能在这台服务器上获取。这种方法又被称作会话黏滞</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.利用Cookie记录Session</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>早期的企业应用系统使用C/S（客户端/服务器）架构，一种管理Session的方式是将Session记录在客户端，每次请求服务器的时候，将Session放在请求中发送给服务器，服务器处理完请求后再将修改过的Session响应给客户端。网站没有客户端，但是可以利用浏览器支持的Cookie记录Session</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用Cookie记录Session也有一些缺点，比如受Cookie大小限制，能记录的信息有限；每次请求响应都需要传输Cookie，影响性能；如果用户关闭Cookie，访问就会不正常。但是由于Cookie的简单易用，可用性高，支持应用服务器的线性伸缩，而大部分应用需要记录的Session信息又比较小。因此事实上，许多网站都或多或少地使用Cookie记录Session。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.Session服务器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用独立部署的Session服务器（集群）统一管理Session，应用服务器每次读写Session时，都访问Session服务器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种解决方案事实上是将应用服务器的状态分离，分为无状态的应用服务器和有状态的Session服务器，然后针对这两种服务器的不同特性分别设计其架构。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-4-高可用的服务" tabindex="-1"><a class="header-anchor" href="#◆-5-4-高可用的服务" aria-hidden="true">#</a> ◆ 5.4 高可用的服务</h6>
<blockquote>
<blockquote>
<p>几点高可用的服务策略</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.分级管理运维上将服务器进行分级管理，核心应用和服务优先使用更好的硬件，在运维响应速度上也格外迅速。显然，用户及时付款购物比能不能评价商品更重要，所以订单、支付服务比评价服务有更高优先级。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同时在服务部署上也进行必要的隔离，避免故障的连锁反应。低优先级的服务通过启动不同的线程或者部署在不同的虚拟机上进行隔离，而高优先级的服务则需要部署在不同的物理机上，核心服务和数据甚至需要部署在不同地域的数据中心。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.超时设置由于服务端宕机、线程死锁等原因，可能导致应用程序对服务端的调用失去响应，进而导致用户请求长时间得不到响应，同时还占用应用程序的资源，不利于及时将访问请求转移到正常的服务器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在应用程序中设置服务调用的超时时间，一旦超时，通信框架就抛出异常，应用程序根据服务调度策略，可选择继续重试或将请求转移到提供相同服务的其他服务器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.异步调用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用对服务的调用通过消息队列等异步方式完成，避免一个服务失败导致整个应用请求失败的情况。如提交一个新用户注册请求，应用需要调用三个服务：将用户信息写入数据库，发送账户注册成功邮件，开通对应权限。如果采用同步服务调用，当邮件队列阻塞不能发送邮件时，会导致其他两个服务也无法执行，最终导致用户注册失败。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果采用异步调用的方式，应用程序将用户注册信息发送给消息队列服务器后立即返回用户注册成功响应。而记录用户注册信息到数据库、发送用户注册成功邮件、调用用户服务开通权限这三个服务作为消息的消费者任务，分别从消息队列获取用户注册信息异步执行。即使邮件服务队列阻塞，邮件不能成功发送，也不会影响其他服务的执行，用户注册操作可顺利完成，只是晚一点收到注册成功的邮件而已。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.服务降级在网站访问高峰期，服务可能因为大量的并发调用而性能下降，严重时可能会导致服务宕机。为了保证核心应用和功能的正常运行，需要对服务进行降级。降级有两种手段：拒绝服务及关闭服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>拒绝服务：拒绝低优先级应用的调用，减少服务调用并发数，确保核心应用正常使用；或者随机拒绝部分请求调用，节约资源，让另一部分请求得以成功，避免要死大家一起死的惨剧。貌似Twitter比较喜欢使用随机拒绝请求的策略，经常有用户看到请求失败的故障页面，但是问下身边的人，其他人都正常使用，自己再刷新页面，也好了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>关闭功能：关闭部分不重要的服务，或者服务内部关闭部分不重要的功能，以节约系统开销，为重要的服务和功能让出资源。淘宝在每年的“双十一”促销中就使用这种方法，在系统最繁忙的时段关闭“评价”、“确认收货”等非核心服务，以保证核心交易服务的顺利完成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.幂等性设计应用调用服务失败后，会将调用请求重新发送到其他服务器，但是这个失败可能是虚假的失败。比如服务已经处理成功，但因为网络故障应用没有收到响应，这时应用重新提交请求就导致服务重复调用，如果这个服务是一个转账操作，就会产生严重后果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务重复调用是无法避免的，应用层也不需要关心服务是否真的失败，只要没有收到调用成功的响应，就可以认为调用失败，并重试服务调用。因此必须在服务层保证服务重复调用和调用一次产生的结果相同，即服务具有幂等性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有些服务天然具有幂等性，比如将用户性别设置为男性，不管设置多少次，结果都一样。但是对于转账交易等操作，问题就会比较复杂，需要通过交易编号等信息进行服务调用有效性校验，只有有效的操作才能继续执行。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-5-高可用的数据" tabindex="-1"><a class="header-anchor" href="#◆-5-5-高可用的数据" aria-hidden="true">#</a> ◆ 5.5 高可用的数据</h6>
<blockquote>
<blockquote>
<p>不同于高可用的应用和服务，由于数据存储服务器上保存的数据不同，当某台服务器宕机的时候，数据访问请求不能任意切换到集群中其他的机器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>保证数据存储高可用的手段主要是数据备份和失效转移机制。数据备份是保证数据有多个副本，任意副本的失效都不会导致数据的永久丢失，从而实现数据完全的持久化。而失效转移机制则保证当一个数据副本不可访问时，可以快速切换访问数据的其他副本，保证系统可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一种观点认为缓存已经成为网站数据服务的重要组成部分，事实上承担了业务中绝大多数的数据读取访问服务，缓存服务失效可能会导致数据库负载过高而宕机，进而影响整个网站的可用性，因此缓存服务需要实现和数据存储服务同样的高可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另一种观点认为，缓存服务不是数据存储服务，缓存服务器宕机引起缓存数据丢失导致服务器负载压力过高应该通过其他手段解决，而不是提高缓存服务本身的高可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于缓存服务器集群中的单机宕机，如果缓存服务器集群规模较大，那么单机宕机引起的缓存数据丢失比例和数据库负载压力变化都较小，对整个系统影响也较小。扩大缓存服务器集群规模的一个简单手段就是整个网站共享同一个分布式缓存集群，单独的应用和产品不需要部署自己的缓存服务器，只需要向共享缓存集群申请缓存资源即可。并且通过逻辑或物理分区的方式将每个应用的缓存部署在多台服务器上，任何一台服务器宕机引起的缓存失效都只影响应用缓存数据的一小部分，不会对应用性能和数据库负载造成太大影响。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了保证数据的高可用，网站通常会牺牲另一个也很重要的指标：数据一致性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据持久性保证数据可持久存储，在各种情况下都不会出现数据丢失的问题。为了实现数据的持久性，不但在写入数据时需要写入持久性存储，还需要将数据备份一个或多个副本，存放在不同的物理存储设备上，在某个存储故障或灾害发生时，数据不会丢失。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据可访问性在多份数据副本分别存放在不同存储设备的情况下，如果一个数据存储设备损坏，就需要将数据访问切换到另一个数据存储设备上，如果这个过程不能很快完成（终端用户几乎没有感知），或者在完成过程中需要停止终端用户访问数据，那么这段时间数据是不可访问的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据一致性在数据有多份副本的情况下，如果网络、服务器或者软件出现故障，会导致部分副本写入成功，部分副本写入失败。这就会造成各个副本之间的数据不一致，数据内容冲突。实践中，导致数据不一致的情形有很多种，表现形式也多种多样，比如数据更新返回操作失败，事实上数据在存储服务器已经更新成功。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CAP原理认为，一个提供数据服务的存储系统无法同时满足数据一致性（Consistency）、数据可用性（Availibility）、分区耐受性（PatitionTolerance，系统具有跨网络分区的伸缩性）这三个条件</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在大型网站中，通常会选择强化分布式存储系统的可用性（A）和伸缩性（P），而在某种程度上放弃一致性（C）。一般说来，数据不一致通常出现在系统高并发写操作或者集群状态不稳（故障恢复、集群扩容……）的情况下，应用系统需要对分布式数据处理系统的数据不一致性有所了解并进行某种意义上的补偿和纠错，以避免出现应用系统数据不正确。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2012年淘宝“双十一”活动期间，在活动第一分钟就涌入了1000万独立用户访问，这种极端的高并发场景对数据处理系统造成了巨大压力，存储系统较弱的数据一致性导致出现部分商品超卖现象（交易成功的商品数超过了商品库存数）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据一致性又可分为如下几点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据强一致各个副本的数据在物理存储中总是一致的；数据更新操作结果和操作响应总是一致的，即操作响应通知更新失败，那么数据一定没有被更新，而不是处于不确定状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据用户一致即数据在物理存储中的各个副本的数据可能是不一致的，但是终端用户访问时，通过纠错和校验机制，可以确定一个一致的且正确的数据返回给用户。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据最终一致这是数据一致性中较弱的一种，即物理存储的数据可能是不一致的，终端用户访问到的数据可能也是不一致的（同一用户连续访问，结果不同；或者不同用户同时访问，结果不同），但系统经过一段时间（通常是一个比较短的时间段）的自我恢复和修正，数据最终会达到一致。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据备份是一种古老而有效的数据保护手段，早期的数据备份手段主要是数据冷备，即定期将数据复制到某种存储介质（磁带，光盘……）上并物理存档保管，如果系统存储损坏，那么就从冷备的存储设备中恢复数据。冷备的优点是简单和廉价，成本和技术难度都较低。缺点是不能保证数据最终一致，由于数据是定期复制，因此备份设备中的数据比系统中的数据陈旧，如果系统数据丢失，那么从上个备份点开始后更新的数据就会永久丢失，不能从备份中恢复。同时也不能保证数据可用性，从冷备存储中恢复数据需要较长的时间，而这段时间无法访问数据，系统也不可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据冷备作为一种传统的数据保护手段，依然在网站日常运维中使用，同时在网站实时在线业务中，还需要进行数据热备，以提供更好的数据可用性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据热备可分为两种：异步热备方式和同步热备方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>异步方式是指多份数据副本的写入操作异步完成，应用程序收到数据服务系统的写操作成功响应时，只写成功了一份，存储系统将会异步地写其他副本（这个过程有可能会失败）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在异步写入方式下，存储服务器分为主存储服务器（Master）和从存储服务器（Slave），应用程序正常情况下只连接主存储服务器，数据写入时，由主存储服务器的写操作代理模块将数据写入本机存储系统后立即返回写操作成功响应，然后通过异步线程将写操作数据同步到从存储服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同步方式是指多份数据副本的写入操作同步完成，即应用程序收到数据服务系统的写成功响应时，多份数据都已经写操作成功。但是当应用程序收到数据写操作失败的响应时，可能有部分副本或者全部副本都已经写成功了（因为网络或者系统故障，无法返回操作成功的响应）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同步热备具体实现的时候，为了提高性能，在应用程序客户端并发向多个存储服务器同时写入数据，然后等待所有存储服务器都返回操作成功的响应后，再通知应用程序写操作成功。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>存储服务客户端在写多份数据的时候，并发操作，这意味着多份数据的总写操作延迟是响应最慢的那台存储服务器的响应延迟，而不是多台存储服务器响应延迟之和。其性能和异步热备方式差不多。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>传统的企业级关系数据库系统几乎都提供了数据实时同步备份的机制。而一开始就为大型网站而设计的各种NoSQL数据库（如HBase）更是将数据备份机制作为产品最主要的功能点之一。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>关系数据库热备机制就是通常所说的Master-Slave同步机制。Master-Slave机制不但解决了数据备份问题，还改善了数据库系统的性能，实践中，通常使用读写分离的方法访问Slave和Master数据库，写操作只访问Master数据库，读操作只访问Slave数据库。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>若数据服务器集群中任何一台服务器宕机，那么应用程序针对这台服务器的所有读写操作都需要重新路由到其他服务器，保证数据访问不会失败，这个过程叫作失效转移。失效转移操作由三部分组成：失效确认、访问转移、数据恢复。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.失效确认判断服务器宕机是系统进行失效转移的第一步，系统确认一台服务器是否宕机的手段有两种：心跳检测和应用程序访问失败报告</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于应用程序的访问失败报告，控制中心还需要再一次发送心跳检测进行确认，以免错误判断服务器宕机，因为一旦进行数据访问的失效转移，就意味着数据存储多份副本不一致，需要进行后续一系列复杂的操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.访问转移确认某台数据存储服务器宕机后，就需要将数据读写访问重新路由到其他服务器上。对于完全对等存储的服务器（几台存储服务器存储的数据完全一样，我们称几台服务器为对等服务器，比如主从结构的存储服务器，其存储的数据完全一样），当其中一台宕机后，应用程序根据配置直接切换到对等服务器上。如果存储是不对等的，那么就需要重新计算路由，选择存储服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.数据恢复因为某台服务器宕机，所以数据存储的副本数目会减少，必须将副本的数目恢复到系统设定的值，否则，再有服务器宕机时，就可能出现无法访问转移（所有副本的服务器都宕机了），数据永久丢失的情况。因此系统需要从健康的服务器复制数据，将数据副本数目恢复到设定值。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-6-高可用网站的软件质量保证" tabindex="-1"><a class="header-anchor" href="#◆-5-6-高可用网站的软件质量保证" aria-hidden="true">#</a> ◆ 5.6 高可用网站的软件质量保证</h6>
<blockquote>
<blockquote>
<p>目前大部分网站都采用Web自动化测试技术，使用自动测试工具或脚本完成测试。比较流行的Web自动化测试工具是ThoughtWorks开发的Selenium。Selenium运行在浏览器中，模拟用户操作进行测试，因此Selenium可以同时完成Web功能测试和浏览器兼容测试。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站通常也会开发自己的自动化测试工具，可以一键完成系统部署，测试数据生成、测试执行、测试报告生成等全部测试过程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.主干开发、分支发布代码修改都在主干（trunk）上进行，需要发布的时候，从主干上拉一个分支（branch）发布，该分支即成为一个发布版本，如果该版本发现Bug，继续在该分支上修改发布，并将修改合并（merge）回主干，直到下次主干发布。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.分支开发，主干发布任何修改都不得在主干上直接进行，需要开发一个新功能或者修复一个Bug时，从主干拉一个分支进行开发，开发完成且测试通过后，合并回主干，然后从主干进行发布，主干上的代码永远是最新发布的版本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前网站应用开发中主要使用的是分支开发、主干发布的方式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>继任者提出了一个火车发布模型：将每个应用的发布过程看作一次火车旅程，火车定点运行，期间有若干站点，每一站都进行例行检查，不通过的项目下车，剩下的项目继续坐着火车旅行，直到火车到达终点（应用发布成功）。但实际中，有可能所有项目都下车了，开着空车前进是没有意义的，火车不得不回到起点，等待解决了问题再重来一次。还有可能是车上有达官贵人（重点项目，CEO跟投资人拍胸脯的项目），他不上车，谁也别想走，他出了错，大家都跟着回去重来。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用发布成功后，仍然可能发现因为软件问题而引入的故障，这时候就需要做发布回滚，即卸载刚刚发布的软件，将上一个版本的软件包重新发布，使系统复原，消除故障。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站的主要业务服务器集群规模非常庞大，比如某大型应用集群服务器数量超过一万台。一旦发现故障，即使想要发布回滚也需要很长时间才能完成，只能眼睁睁看着故障时间不断增加却干着急。为了应付这种局面，大型网站会使用灰度发布模式，将集群服务器分成若干部分，每天只发布一部分服务器，观察运行稳定没有故障，第二天继续发布一部分服务器，持续几天才把整个集群全部发布完毕，期间如果发现问题，只需要回滚已发布的一部分服务器即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>灰度发布也常用于用户测试，即在部分服务器上发布新版本，其余服务器保持老版本（或者发布另一个版本），然后监控用户操作行为，收集用户体验报告，比较用户对两个版本的满意度，以确定最终的发布版本。这种手段也被称作AB测试。</p>
</blockquote>
</blockquote>
<h6 id="◆-5-7-网站运行监控" tabindex="-1"><a class="header-anchor" href="#◆-5-7-网站运行监控" aria-hidden="true">#</a> ◆ 5.7 网站运行监控</h6>
<blockquote>
<blockquote>
<p>“不允许没有监控的系统上线”，这是许多网站架构师在做项目上线评审时常说的一句话。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>监控数据采集</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.用户行为日志收集用户行为日志指用户在浏览器上所做的所有操作及其所在的操作环境，包括用户操作系统与浏览器版本信息，IP地址、页面访问路径、页面停留时间等，这些数据对统计网站PV/UV指标、分析用户行为、优化网站设计、个性化营销与推荐等非常重要。具体用户行为日志收集手段有两种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务器端日志收集。这个方案比较简单，Apache等几乎所有Web服务器都具备日志记录功能，可以记录大部分用户行为日志，开启Web服务器的日志记录功能即可。其缺点是可能会出现信息失真，如IP地址是代理服务器地址而不是用户真实IP；无法识别访问路径等。客户端浏览器日志收集。利用页面嵌入专门的JavaScript脚本可以收集用户真实的操作行为，因此比服务器日志收集更加精准。其缺点是比较麻烦，需要在页面嵌入特定的JavaScript脚本来完成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站的用户日志数据量惊人，数据存储与计算压力很大，目前许多网站逐步开发基于实时计算框架Storm的日志统计与分析工具。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.服务器性能监控收集服务器性能指标，如系统Load、内存占用、磁盘IO、网络IO等对尽早做出故障预警，及时判断应用状况，防患于未然，将故障扼杀在萌芽时期非常重要。此外根据性能监控数据，运维工程师可以合理安排服务器集群规模，架构师及时改善系统性能及调整系统伸缩性策略。目前网站使用比较广泛的开源性能监控工具是Ganglia，它支持大规模服务器集群，并支持以图形的方式在浏览器展示实时性能曲线。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.运行数据报告除了服务器系统性能监控，网站还需要监控一些与具体业务场景相关的技术和业务指标，比如缓冲命中率、平均响应延迟时间、每分钟发送邮件数目、待处理的任务总数等。对于服务器性能监控，网站运维人员可以在初始化系统时统一部署，应用程序开发完全不关心服务器性能监控。而运行数据需要在具体程序中采集并报告，汇总后统一显示，应用程序需要在代码中处理运行数据采集的逻辑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>监控数据采集后，除了用作系统性能评估、集群规模伸缩性预测等，还可以根据实时监控数据进行风险预警，并对服务器进行失效转移，自动负载调整，最大化利用集群所有机器的资源。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统报警</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>监控管理系统可以配置报警阈值和值守人员的联系方式，报警方式除了邮件，即时通信工具，还可以配置手机短信，语音报警，系统发生报警时，工程师即使在千里之外、夜里睡觉也能被及时通知，迅速响应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>失效转移除了应用程序访问失败时进行失效转移，监控系统还可以在发现故障的情况下主动通知应用，进行失效转移。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>自动优雅降级</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>优雅降级是指网站为了应付突然爆发的访问高峰，主动关闭部分功能，释放部分系统资源，保证网站核心功能正常访问的一个手段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站在监控管理基础之上实现自动优雅降级，是网站柔性架构的理想状态：监控系统实时监控所有服务器的运行状况，根据监控参数判断应用访问负载情况，如果发现部分应用负载过高，而部分应用负载过低，就会适当卸载低负载应用部分服务器，重新安装启动部分高负载应用，使应用负载总体均衡，如果所有应用负载都很高，而且负载压力还在继续增加，就会自动关闭部分非重要功能，保证核心功能正常运行。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-永无止境-网站的伸缩性架构" tabindex="-1"><a class="header-anchor" href="#◆-6-永无止境-网站的伸缩性架构" aria-hidden="true">#</a> ◆ 6 永无止境：网站的伸缩性架构</h3>
<blockquote>
<blockquote>
<p>只要技术上能做到向集群中加入服务器的数量和集群的处理能力成线性关系，那么网站就可以以此手段不断提升自己的规模，从一个服务几十人的小网站发展成服务几十亿人的大网站，从只能存储几个G图片的小网站发展成存储几百P图片的大网站。</p>
</blockquote>
</blockquote>
<h6 id="◆-6-1-网站架构的伸缩性设计" tabindex="-1"><a class="header-anchor" href="#◆-6-1-网站架构的伸缩性设计" aria-hidden="true">#</a> ◆ 6.1 网站架构的伸缩性设计</h6>
<blockquote>
<blockquote>
<p>网站的伸缩性设计可分成两类，一类是根据功能进行物理分离实现伸缩，一类是单一功能通过集群实现伸缩。前者是不同的服务器部署不同的服务，提供不同的功能；后者是集群内的多台服务器部署相同的服务，提供相同的功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站发展早期——通过增加服务器提高网站处理能力时，新增服务器总是从现有服务器中分离出部分功能和服务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每次分离都会有更多的服务器加入网站，使用新增的服务器处理某种特定服务。事实上，通过物理上分离不同的网站功能，实现网站伸缩性的手段，不仅可以用在网站发展早期，而且可以在网站发展的任何阶段使用。具体又可分成如下两种情况。纵向分离（分层后分离）：将业务处理流程上的不同部分分离部署，实现系统伸缩性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>横向分离（业务分割后分离）：将不同的业务模块分离部署，实现系统伸缩性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>横向分离的粒度可以非常小，甚至可以一个关键网页部署一个独立服务，比如对于电商网站非常重要的产品详情页面，商铺页面，搜索列表页面，每个页面都可以独立部署，专门维护。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将不同功能分离部署可以实现一定程度的伸缩性，但是随着网站访问量的逐步增加，即使分离到最小粒度的独立部署，单一的服务器也不能满足业务规模的要求。因此必须使用服务器集群，即将相同服务部署在多台服务器上构成一个集群整体对外提供服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当一头牛拉不动车的时候，不要去寻找一头更强壮的牛，而是用两头牛来拉车。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以搜索服务器为例，如果一台服务器可以提供每秒1000次的请求服务，即QPS（Query Per Second）为1000。那么如果网站高峰时每秒搜索访问量为10000，就需要部署10台服务器构成一个集群。若以缓存服务器为例，如果每台服务器可缓存40GB数据，那么要缓存100GB数据，就需要部署3台服务器构成一个集群。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群伸缩性又可分为应用服务器集群伸缩性和数据服务器集群伸缩性。这两种集群由于对数据状态管理的不同，技术实现也有非常大的区别。而数据服务器集群也可分为缓存数据服务器集群和存储数据服务器集群，这两种集群的伸缩性设计也不大相同。</p>
</blockquote>
</blockquote>
<h6 id="◆-6-2-应用服务器集群的伸缩性设计" tabindex="-1"><a class="header-anchor" href="#◆-6-2-应用服务器集群的伸缩性设计" aria-hidden="true">#</a> ◆ 6.2 应用服务器集群的伸缩性设计</h6>
<blockquote>
<blockquote>
<p>如果HTTP请求分发装置可以感知或者可以配置集群的服务器数量，可以及时发现集群中新上线或下线的服务器，并能向新上线的服务器分发请求，停止向已下线的服务器分发请求，那么就实现了应用服务器集群的伸缩性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这个HTTP请求分发装置被称作负载均衡服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实现负载均衡的基础技术不外以下几种。6.2.1 HTTP重定向负载均衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用HTTP重定向协议实现负载均衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HTTP重定向服务器是一台普通的应用服务器，其唯一的功能就是根据用户的HTTP请求计算一台真实的Web服务器地址，并将该Web服务器地址写入HTTP重定向响应中（响应状态码302）返回给用户浏览器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>浏览器请求访问域名www.mysite.com，DNS服务器解析得到IP地址是114.100.80.10，即HTTP重定向服务器的IP地址。然后浏览器通过IP地址114.100.80.10访问HTTP重定向负载均衡服务器后，服务器根据某种负载均衡算法计算获得一台实际物理服务器的地址（114.100.80.3），构造一个包含该实际物理服务器地址的重定向响应返回给浏览器，浏览器自动重新请求实际物理服务器的IP地址114.100.80.3，完成访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种负载均衡方案的优点是比较简单。缺点是浏览器需要两次请求服务器才能完成一次访问，性能较差；重定向服务器自身的处理能力有可能成为瓶颈，整个集群的伸缩性规模有限；使用HTTP302响应码重定向，有可能使搜索引擎判断为SEO作弊，降低搜索排名。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用DNS处理域名解析请求的同时进行负载均衡处理的一种方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>DNS域名解析负载均衡的优点是将负载均衡的工作转交给DNS，省掉了网站管理维护负载均衡服务器的麻烦，同时许多DNS还支持基于地理位置的域名解析，即会将域名解析成距离用户地理最近的一个服务器地址，这样可加快用户访问速度，改善性能。但是DNS域名解析负载均衡也有缺点，就是目前的DNS是多级解析，每一级DNS都可能缓存A记录，当下线某台服务器后，即使修改了DNS的A记录，要使其生效也需要较长时间，这段时间，DNS依然会将域名解析到已经下线的服务器，导致用户访问失败；而且DNS负载均衡的控制权在域名服务商那里，网站无法对其做更多改善和更强大的管理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站总是部分使用DNS域名解析，利用域名解析作为第一级负载均衡手段，即域名解析得到的一组服务器并不是实际提供Web服务的物理服务器，而是同样提供负载均衡服务的内部服务器，这组内部负载均衡服务器再进行负载均衡，将请求分发到真实的Web服务器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用反向代理服务器进行负载均衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Web服务器不需要使用外部I P地址，而反向代理服务器则需要配置双网卡和内部外部两套IP地址</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于反向代理服务器转发请求在HTTP协议层面，因此也叫应用层负载均衡。其优点是和反向代理服务器功能集成在一起，部署简单。缺点是反向代理服务器是所有请求和响应的中转站，其性能可能会成为瓶颈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在网络层通过修改请求目标地址进行负载均衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用三角传输模式的链路层负载均衡是目前大型网站使用最广的一种负载均衡手段。在Linux平台上最好的链路层负载均衡开源产品是LVS（Linux VirtualServer）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>负载均衡服务器的实现可以分成两个部分：1.根据负载均衡算法和Web服务器列表计算得到集群中一台Web服务器的地址。2.将请求数据发送到该地址对应的Web服务器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>负载均衡算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>轮询（Round Robin，RR）所有请求被依次分发到每台应用服务器上，即每台服务器需要处理的请求数目都相同，适合于所有服务器硬件都相同的场景。加权轮询（Weighted Round Robin，WRR）根据应用服务器硬件性能的情况，在轮询的基础上，按照配置的权重将请求分发到每个服务器，高性能的服务器能分配更多请求。随机（Random）请求被随机分配到各个应用服务器，在许多场合下，这种方案都很简单实用，因为好的随机数本身就很均衡。即使应用服务器硬件配置不同，也可以使用加权随机算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最少连接（Least Connections）记录每个应用服务器正在处理的连接数（请求数），将新到的请求分发到最少连接的服务器上，应该说，这是最符合负载均衡定义的算法。同样，最少连接算法也可以实现加权最少连接。源地址散列（Source Hashing）根据请求来源的IP地址进行Hash计算，得到应用服务器，这样来自同一个IP地址的请求总在同一个服务器上处理，该请求的上下文信息可以存储在这台服务器上，在一个会话周期内重复使用，从而实现会话黏滞。</p>
</blockquote>
</blockquote>
<h6 id="◆-6-3-分布式缓存集群的伸缩性设计" tabindex="-1"><a class="header-anchor" href="#◆-6-3-分布式缓存集群的伸缩性设计" aria-hidden="true">#</a> ◆ 6.3 分布式缓存集群的伸缩性设计</h6>
<blockquote>
<blockquote>
<p>和所有服务器都部署相同应用的应用服务器集群不同，分布式缓存服务器集群中不同服务器中缓存的数据各不相同，缓存访问请求不可以在缓存服务器集群中的任意一台处理，必须先找到缓存有需要数据的服务器，然后才能访问。这个特点会严重制约分布式缓存集群的伸缩性设计，因为新上线的缓存服务器没有缓存任何数据，而已下线的缓存服务器还缓存着网站的许多热点数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>必须让新上线的缓存服务器对整个分布式缓存集群影响最小，也就是说新加入缓存服务器后应使整个缓存服务器集群中已经缓存的数据尽可能还被访问到，这是分布式缓存集群伸缩性设计的最主要目标。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Memcached分布式缓存系统中，对于服务器集群的管理，路由算法至关重要，和负载均衡算法一样，决定着究竟该访问集群中的哪台服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>简单的路由算法可以使用余数Hash：用服务器数目除以缓存数据KEY的Hash值，余数为服务器列表下标编号。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用余数Hash路由算法可保证缓存数据在整个Memcached服务器集群中比较均衡地分布。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果不需要考虑缓存服务器集群伸缩性，余数Hash几乎可以满足绝大多数的缓存路由需求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3台服务器扩容至4台服务器，大约有75%（3/4）被缓存了的数据不能正确命中，随着服务器集群规模的增大，这个比例线性上升。当100台服务器的集群中加入一台新服务器，不能命中的概率是99%（N/(N+1)）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一种解决办法是在网站访问量最少的时候扩容缓存服务器集群，这时候对数据库的负载冲击最小。然后通过模拟请求的方法逐渐预热缓存，使缓存服务器中的数据重新分布。但是这种方案对业务场景有要求，还需要技术团队通宵加班（网站访问低谷通常是在半夜）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一致性Hash算法通过一个叫作一致性Hash环的数据结构实现KEY到缓存服务器的Hash映射</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具体应用中，这个长度为232的一致性Hash环通常使用二叉查找树实现，Hash查找过程实际上是在二叉查找树中查找不小于查找数的最小数值。当然这个二叉树的最右边叶子节点和最左边的叶子节点相连接，构成环。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>计算机的任何问题都可以通过增加一个虚拟层来解决。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>新加入一台缓存服务器，将会较为均匀地影响原来集群中已经存在的所有服务器，也就是说分摊原有缓存服务器集群中所有服务器的一小部分负载，其总的影响范围和上面讨论过的相同</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>但是不能被访问到数据）为其节点缓存数据量的1/4（X/(N+X)，N为原有物理节点数，X为新加入物理节点数），也就是集群中已经被缓存的数据有75%可以被继续命中</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>那么在实践中，一台物理服务器虚拟为多少个虚拟服务器节点合适呢？太多会影响性能，太少又会导致负载不均衡，一般说来，经验值是150，当然根据集群规模和负载均衡的精度需求，这个值应该根据具体情况具体对待。</p>
</blockquote>
</blockquote>
<h6 id="◆-6-4-数据存储服务器集群的伸缩性设计" tabindex="-1"><a class="header-anchor" href="#◆-6-4-数据存储服务器集群的伸缩性设计" aria-hidden="true">#</a> ◆ 6.4 数据存储服务器集群的伸缩性设计</h6>
<blockquote>
<blockquote>
<p>存储服务器集群的伸缩性设计相对更复杂一些，具体说来，又可分为关系数据库集群的伸缩性设计和NoSQL数据库的伸缩性设计。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>市场上主要的关系数据都支持数据复制功能，使用这个功能可以对数据库进行简单伸缩</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据写操作都在主服务器上，由主服务器将数据同步到集群中其他从服务器，数据读操作及数据分析等离线操作在从服务器上进行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据分库。这种方式的制约条件是跨库的表不能进行Join操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在大型网站的实际应用中，即使进行了分库和主从复制，对一些单表数据仍然很大的表，比如Facebook的用户数据库，淘宝的商品数据库，还需要进行分片，将一张表拆开分别存储在多个数据库中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前网站在线业务应用中比较成熟的支持数据分片的分布式关系数据库产品主要有开源的Amoeba（http://sourceforge.net/projects/amoeba/）和Cobar（http://code.alibabatech. com/wiki/display/cobar/Home）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Cobar是一个分布式关系数据库访问代理，介于应用服务器和数据库服务器之间（Cobar也支持非独立部署，以lib的方式和应用程序部署在一起）。应用程序通过JDBC驱动访问Cobar集群，Cobar服务器根据SQL和分库规则分解SQL，分发到MySQL集群不同的数据库实例上执行（每个MySQL实例都部署为主/从结构，保证数据高可用）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>前端通信模块负责和应用程序通信，接收到SQL请求（select<em>from users whereuserid in (12,22,23)）后转交给SQL解析模块，SQL解析模块解析获得SQL中的路由规则查询条件（userid in(12,22,23)）再转交给SQL路由模块，SQL路由模块根据路由规则配置（userid为偶数路由至数据库A，userid为奇数路由至数据库B）将应用程序提交的SQL分解成两条SQL（select</em>from users where useridin(12,22)；select*from users where userid in(23)；）转交给SQL执行代理模块，发送至数据库A和数据库B分别执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库A和数据库B的执行结果返回至SQL执行模块，通过结果合并模块将两个返回结果集合并成一个结果集，最终返回给应用程序，完成在分布式数据库中的一次访问请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Cobar的伸缩有两种：Cobar服务器集群的伸缩和MySQL服务器集群的伸缩。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Cobar服务器可以看作是无状态的应用服务器，因此其集群伸缩可以简单使用负载均衡的手段实现。而MySQL中存储着数据，要想保证集群扩容后数据一致负载均衡，必须要做数据迁移，将集群中原来机器中的数据迁移到新添加的机器中</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具体迁移哪些数据可以利用一致性Hash算法（即路由模块使用一致性Hash算法进行路由），尽量使需要迁移的数据最少。但是迁移数据需要遍历数据库中每条记录（的索引），重新进行路由计算确定其是否需要迁移，这会对数据库访问造成一定压力。并且需要解决迁移过程中数据的一致性、可访问性、迁移过程中服务器宕机时的可用性等诸多问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实践中，Cobar利用了MySQL的数据同步功能进行数据迁移。数据迁移不是以数据为单位，而是以Schema为单位。在Cobar集群初始化时，在每个MySQL实例创建多个Schema（根据业务远景规划未来集群规模，如集群最大规模为1000台数据库服务器，那么总的初始Schema数≥1000）。集群扩容的时候，从每个服务器中迁移部分Schema到新机器中，由于迁移以Schema为单位，迁移过程可以使用MySQL的同步机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>同步完成时，即新机器中Schema数据和原机器中Schema数据一致的时候，修改Cobar服务器的路由配置，将这些Schema的IP修改为新机器的IP，然后删除原机器中的相关Schema，完成MySQL集群扩容。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在整个分布式关系数据库的访问请求过程中，Cobar服务器处理消耗的时间是很少的，时间花费主要还是在MySQL数据库端</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>但由于Cobar路由后只能在单一数据库实例上处理查询请求，因此无法执行跨库的JOIN操作，当然更不能执行跨库的事务处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当网站业务面临不停增长的海量业务数据存储压力时，又不得不利用分布式关系数据库的集群伸缩能力</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从业务上回避分布式关系数据库的各种缺点：避免事务或利用事务补偿机制代替数据库事务；分解数据访问逻辑避免JOIN操作等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>还有一类分布式数据库可以支持JOIN操作执行复杂的SQL查询，如GreenPlum。但是这类数据库的访问延迟比较大（可以想象，JOIN操作需要在服务器间传输大量的数据），因此一般使用在数据仓库等非实时业务中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般而言，NoSQL数据库产品都放弃了关系数据库的两大重要基础：以关系代数为基础的结构化查询语言（SQL）和事务一致性保证（ACID）。而强化其他一些大型网站更关注的特性：高可用性和可伸缩性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>各种NoSQL产品，其支持的数据结构和伸缩特性也各不相同，目前看来，应用最广泛的是Apache HBase。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HBase为可伸缩海量数据储存而设计，实现面向在线业务的实时数据访问延迟。HBase的伸缩性主要依赖其可分裂的HRegion及可伸缩的分布式文件系统HDFS实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HBase启动多个HMaser，并通过Zookeeper（一个支持分布式一致性的数据管理服务）选举出一个主服务器，应用程序通过Zookeeper获得主HMaser的地址，输入Key值获得这个Key所在的HRegionServer地址，然后请求HRegionServer上的HRegion，获得需要的数据。</p>
</blockquote>
</blockquote>
<h6 id="◆-6-5-小结" tabindex="-1"><a class="header-anchor" href="#◆-6-5-小结" aria-hidden="true">#</a> ◆ 6.5 小结</h6>
<blockquote>
<blockquote>
<p>高手定律：这个世界只有遇不到的问题，没有解决不了的问题，高手之所以成为高手，是因为他们遇到了常人很难遇到的问题，并解决了。所以百度有很多广告搜索的高手，淘宝有很多海量数据的高手，QQ有很多高并发业务的高手，原因大抵如此。一个100万用户的网站，不会遇到1亿用户同时在线的问题；一个拥有100万件商品网站的工程师，可能无法理解一个拥有10亿件商品网站的架构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>救世主定律：遇到问题，分析问题，最后总能解决问题。如果遇到问题就急匆匆地从外面挖一个高手，然后指望高手如探囊取物般轻松搞定，最后怕是只有彼此抱怨和伤害。许多问题只是看起来一样，具体问题总是要具体对待的，没有银弹，没有救世主。所以这个定律准确地说应该是“没有救世主定律”。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-随需应变-网站的可扩展架构" tabindex="-1"><a class="header-anchor" href="#◆-7-随需应变-网站的可扩展架构" aria-hidden="true">#</a> ◆ 7 随需应变：网站的可扩展架构</h3>
<blockquote>
<blockquote>
<p>为什么有的网站必须规定系统发布日，一到发布日就如临大敌，整个技术部加班通宵达旦；而有的网站就可以随时发布，新功能可以随时快速上线。这些都有赖于网站的扩展性架构设计，就是在对现有系统影响最小的情况下，系统功能可持续扩展及提升的能力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>扩展性（Extensibility）指对现有系统影响最小的情况下，系统功能可持续扩展或提升的能力。表现在系统基础设施稳定不需要经常变更，应用之间较少依赖和耦合，对需求变更可以敏捷响应。它是系统架构设计层面的开闭原则（对扩展开放，对修改关闭），架构设计考虑未来功能扩展，当系统增加新功能时，不需要对现有系统的结构和代码进行修改。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>伸缩性（Scalability）指系统能够通过增加（减少）自身资源规模的方式增强（减少）自己计算处理事务的能力。如果这种增减是成比例的，就被称作线性伸缩性。在网站架构中，通常指利用集群的方式增加服务器数量、提高系统的整体事务吞吐能力。</p>
</blockquote>
</blockquote>
<h6 id="◆-7-3-利用分布式服务打造可复用的业务平台" tabindex="-1"><a class="header-anchor" href="#◆-7-3-利用分布式服务打造可复用的业务平台" aria-hidden="true">#</a> ◆ 7.3 利用分布式服务打造可复用的业务平台</h6>
<blockquote>
<blockquote>
<p>使用分布式服务是降低系统耦合性的另一个重要手段。如果说分布式消息队列通过消息对象分解系统耦合性，不同子系统处理同一个消息；那么分布式服务则通过接口分解系统耦合性，不同子系统通过相同的接口描述进行服务调用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>巨无霸应用系统带来如下几点问题。1.编译、部署困难：对于网站开发工程师而言，打包构建一个巨型应用是一件痛苦的事情，也许只是修改了一行代码，输入build命令后，抽完一支烟，回来一看，还在building；又去喝了一杯水，回来一看，还在building；又去了一次厕所，回来一看，还在building；好不容易build结束，一看编译失败，还得重来……</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.代码分支管理困难：复用的代码模块由多个团队共同维护修改，代码merge的时候总会发生冲突。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.数据库连接耗尽：巨型的应用、大量的访问，必然需要将这个应用部署在一个大规模的服务器集群上，应用与数据库的连接通常使用数据库连接池，以每个应用10个连接计，一个数百台服务器集群的应用将需要在数据库上创建数千个连接。数据库服务器上，每个连接都会占用一些昂贵的系统资源，以至于数据库缺乏足够的系统资源进行一般的数据操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.新增业务困难：想要在一个已经如乱麻般的系统中增加新业务，维护旧功能，难度可想而知：一脚踩进去，发现全都是雷，什么都不敢碰。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>解决方案就是拆分，将模块独立部署，降低系统耦合性。拆分可以分为纵向拆分和横向拆分两种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>纵向拆分：将一个大应用拆分为多个小应用，如果新增业务较为独立，那么就直接将其设计部署为一个独立的Web应用系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>横向拆分：将复用的业务拆分出来，独立部署为分布式服务，新增业务只需要调用这些分布式服务，不需要依赖具体的模块代码，即可快速搭建一个应用系统，而模块内业务逻辑变化的时候，只要接口保持一致就不会影响业务程序和其他模块。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>纵向拆分相对较为简单，通过梳理业务，将较少相关的业务剥离，使其成为独立的Web应用。而对于横向拆分，不但需要识别可复用的业务，设计服务接口，规范服务依赖关系，还需要一个完善的分布式服务管理框架。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于大型网站，除了Web Service所提供的服务注册与发现，服务调用等标准功能，还需要分布式服务框架能够支持如下特性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>负载均衡</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>失效转移</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>高效的远程通信</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于大型网站，核心服务每天的调用次数会达到数以亿计，如果没有高效的远程通信手段，服务调用会成为整个系统性能的瓶颈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>整合异构系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>版本管理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了应对快速变化的需求，服务升级不可避免，如果仅仅是服务内部实现逻辑升级，那么这种升级对服务请求者而言是透明的，无需关注。但如果服务的访问接口也发生了变化，就需要服务请求者和服务提供者同时升级才不会导致服务调用失败。企业应用系统可以申请停机维护，同时升级接口。但是网站服务不可能中断，因此分布式服务框架需要支持服务多版本发布，服务提供者先升级接口发布新版本的服务，并同时提供旧版本的服务供请求者调用，当请求者调用接口升级后才可以关闭旧版本服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实时监控</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式服务框架还需要监控服务提供者和调用者的各项指标，提供运维和运营支持。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站需要更简单更高效的分布式服务框架构建其SOA（Service OrientedArchitecture面向服务的体系架构）。据称Facebook利用Thrift（一个开源的远程服务调用框架）管理其分布式服务，服务的注册、发现及调用都通过Thrift完成，但对于一个大型网站可以使用的分布式服务框架，仅有Thrift还远远不够，遗憾的是，Facebook没有开源其基于Thrift的分布式服务框架。目前国内有较多成功实施案例的开源分布式服务框架是阿里巴巴的Dubbo（http://code.alibabatech.com/wiki/display/dubbo/Home/）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务消费者程序通过服务接口使用服务，而服务接口通过代理加载具体服务，具体服务可以是本地的代码模块，也可以是远程的服务，因此对应用较少侵入：应用程序只需要调用服务接口，服务框架根据配置自动调用本地或远程实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务框架客户端模块通过服务注册中心加载服务提供者列表（服务提供者启动后自动向服务注册中心注册自己可提供的服务接口列表），查找需要的服务接口，并根据配置的负载均衡策略将服务调用请求发送到某台服务提供者服务器。如果服务调用失败，客户端模块会自动从服务提供者列表选择一个可提供同样服务的另一台服务器重新请求服务，实现服务的自动失效转移，保证服务高可用。Dubbo的远程服务通信模块支持多种通信协议和数据序列化协议，使用NIO通信框架，具有较高的网络通信性能。</p>
</blockquote>
</blockquote>
<h6 id="◆-7-4-可扩展的数据结构" tabindex="-1"><a class="header-anchor" href="#◆-7-4-可扩展的数据结构" aria-hidden="true">#</a> ◆ 7.4 可扩展的数据结构</h6>
<blockquote>
<blockquote>
<p>有没有办法能够做到可扩展的数据结构设计呢？无需修改表结构就可以新增字段呢？许多NoSQL数据库使用的ColumnFamily（列族）设计就是一个解决方案。ColumnFamily最早在Google的Bigtable中使用，这是一种面向列族的稀疏矩阵存储格式</p>
</blockquote>
</blockquote>
<h6 id="◆-7-5-利用开放平台建设网站生态圈" tabindex="-1"><a class="header-anchor" href="#◆-7-5-利用开放平台建设网站生态圈" aria-hidden="true">#</a> ◆ 7.5 利用开放平台建设网站生态圈</h6>
<blockquote>
<blockquote>
<p>大型网站为了更好地服务自己的用户，开发更多的增值服务，会把网站内部的服务封装成一些调用接口开放出去，供外部的第三方开发者使用，这个提供开放接口的平台被称作开放平台。第三方开发者利用这些开放的接口开发应用程序（APP）或者网站，为更多的用户提供价值。网站、用户、第三方开发者互相依赖，形成一个网站的生态圈，既为用户提供更多的价值，也提高了网站和第三方开发者的竞争能力和盈利能力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>开放平台是网站内部和外部交互的接口，外部需要面对众多的第三方开发者，内部需要面对网站内诸多的业务服务。虽然每个网站的业务场景和需求都各不相同，但是开放平台的架构设计却大同小异</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>API 接口：是开放平台暴露给开发者使用的一组API，其形式可以是RESTful、WebService、RPC等各种形式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>协议转换：将各种API输入转换成内部服务可以识别的形式，并将内部服务的返回封装成API的格式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>安全：除了一般应用需要的身份识别、权限控制等安全手段，开放平台还需要分级的访问带宽限制，保证平台资源被第三方应用公平合理使用，也保护网站内部服务不会被外部应用拖垮。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>审计：记录第三方应用的访问情况，并进行监控、计费等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>路由：将开放平台的各种访问路由映射到具体的内部服务。流程：将一组离散的服务组织成一个上下文相关的新服务，隐藏服务细节，提供统一接口供开发者调用。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-固若金汤-网站的安全架构" tabindex="-1"><a class="header-anchor" href="#◆-8-固若金汤-网站的安全架构" aria-hidden="true">#</a> ◆ 8 固若金汤：网站的安全架构</h3>
<blockquote>
<blockquote>
<p>2011年中国互联网领域爆出两桩比较大的安全事故，一桩是新浪微博遭XSS攻击，另一桩是以CSDN为代表的多个网站泄露用户密码和个人信息。</p>
</blockquote>
</blockquote>
<h6 id="◆-8-1-道高一尺魔高一丈的网站应用攻击与防御" tabindex="-1"><a class="header-anchor" href="#◆-8-1-道高一尺魔高一丈的网站应用攻击与防御" aria-hidden="true">#</a> ◆ 8.1 道高一尺魔高一丈的网站应用攻击与防御</h6>
<blockquote>
<blockquote>
<p>全球大约70%的Web应用攻击都来自XSS攻击和SQL注入攻击。此外，常用的Web应用还包括CSRF、Session劫持等手段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>XSS攻击即跨站点脚本攻击（Cross Site Script），指黑客通过篡改网页，注入恶意HTML脚本，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>常见的XSS攻击类型有两种，一种是反射型，攻击者诱使用户点击一个嵌入恶意脚本的链接，达到攻击的目的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另外一种XSS攻击是持久型XSS攻击，黑客提交含有恶意脚本的请求，保存在被攻击的Web站点的数据库中，用户浏览网页时，恶意脚本被包含在正常页面中，达到攻击的目的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>XSS防攻击也是非常复杂的。主要手段有如下两种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>XSS攻击者一般都是通过在请求中嵌入恶意脚本达到攻击的目的，这些脚本是一般用户输入中不使用的，如果进行过滤和消毒处理，即对某些html危险字符转义，如“&gt;”转义为“&amp;gt”、“＜”转义为“&amp;lt”等，就可以防止大部分攻击。为了避免对不必要的内容错误转义，如“3＜5”中的“＜”需要进行文本匹配后再转义，如“＜img src=”这样的上下文中的“＜”才转义。事实上，消毒几乎是所有网站最必备的XSS防攻击手段。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>即浏览器禁止页面JavaScript访问带有HttpOnly属性的Cookie。HttpOnly并不是直接对抗XSS攻击的，而是防止XSS攻击者窃取Cookie。对于存放敏感信息的Cookie，如用户认证信息等，可通过对该Cookie添加HttpOnly属性，避免被攻击脚本窃取。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>注入攻击主要有两种形式，SQL注入攻击和OS注入攻击。SQL注入攻击的原理如图8.3所示。攻击者在HTTP请求中注入恶意SQL命令（drop table users;），服务器用请求参数构造数据库SQL命令时，恶意SQL被一起构造，并在数据库中执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>攻击者获取数据库表结构信息的手段有如下几种。开源如果网站采用开源软件搭建，如用Discuz!搭建论坛网站，那么网站数据库结构就是公开的，攻击者可以直接获得。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>错误回显如果网站开启错误回显，即服务器内部500错误会显示到浏览器上。攻击者通过故意构造非法参数，使服务端异常信息输出到浏览器端，为攻击猜测数据库表结构提供了便利。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>防御SQL注入攻击首先要避免被攻击者猜测到表名等数据库表结构信息</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用预编译手段，绑定参数是最好的防SQL注入方法。目前许多数据访问层框架，如IBatis，Hibernate等，都实现SQL预编译和参数绑定，攻击者的恶意SQL会被当做SQL的参数，而不是SQL命令被执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了SQL注入，攻击者还根据具体应用，注入OS命令、编程语言代码等，利用程序漏洞，达到攻击目的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CSRF的主要手法是利用跨站请求，在用户不知情的情况下，以用户的身份伪造请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其核心是利用了浏览器Cookie或服务器Session策略，盗取用户身份。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CSRF的防御手段主要是识别请求者身份。主要有下面几种方法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CSRF是一个伪造用户请求的操作，所以需要构造用户请求的所有参数才可以。表单Token通过在请求参数中增加随机数的办法来阻止攻击者获得所有请求参数：在页面表单中增加一个随机数作为Token，每次响应页面的Token都不相同，从正常页面提交的请求会包含该Token值，而伪造的请求无法获得该值，服务器检查请求参数中Token的值是否存在并且正确以确定请求提交者是否合法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>验证码相对说来，验证码则更加简单有效，即请求提交时，需要用户输入验证码，以避免在用户不知情的情况下被攻击者伪造请求。但是输入验证码是一个糟糕的用户体验，所以请在必要时使用，如支付交易等关键页面。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HTTP请求头的Referer域中记录着请求来源，可通过检查请求来源，验证其是否合法。很多网站使用这个功能实现图片防盗链（如果图片访问的页面来源不是来自自己网站的网页就拒绝）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>也称作错误回显，许多Web服务器默认是打开异常信息输出的，即服务器端未处理的异常堆栈信息会直接输出到客户端浏览器，这种方式虽然对程序调试和错误报告有好处，但同时也给黑客造成可乘之机。通过故意制造非法输入，使系统运行时出错，获得异常信息，从而寻找系统漏洞进行攻击。防御手段也很简单，通过配置Web服务器参数，跳转500页面（HTTP响应码500表示服务器内部错误）到专门的错误页面即可，Web应用常用的MVC框架也有这个功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HTML注释为调试程序方便或其他不恰当的原因，有时程序开发人员会在PHP、JSP等服务器页面程序中使用HTML注释语法进行程序注释，这些HTML注释就会显示在客户端浏览器，给黑客造成攻击便利。程序最终发布前需要进行代码review或自动扫描，避免HTML注释漏洞。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>文件上传一般网站都会有文件上传功能，设置头像、分享视频、上传附件等。如果上传的是可执行的程序，并通过该程序获得服务器端命令执行能力，那么攻击者几乎可以在服务器上为所欲为，并以此为跳板攻击集群环境的其他机器。最有效的防御手段是设置上传文件白名单，只允许上传可靠的文件类型。此外还可以修改文件名、使用专门的存储等手段，保护服务器免受上传文件攻击。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>路径遍历攻击者在请求的URL中使用相对路径，遍历系统未开放的目录和文件。防御方法主要是将JS、CSS等资源文件部署在独立服务器、使用独立域名，其他文件不使用静态URL访问，动态参数不包含文件路径信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ModSecurity是一个开源的Web应用防火墙，探测攻击并保护Web应用程序，既可以嵌入到Web应用服务器中，也可以作为一个独立的应用程序启动。ModSecurity最早只是Apache的一个模块，现在已经有Java、.NET多个版本，并支持Nginx。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ModSecurity采用处理逻辑与攻击规则集合分离的架构模式。处理逻辑（执行引擎）负责请求和响应的拦截过滤，规则加载执行等功能。而攻击规则集合则负责描述对具体攻击的规则定义、模式识别、防御策略等功能（可以通过文本方式进行描述）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站安全漏洞扫描工具是根据内置规则，构造具有攻击性的URL请求，模拟黑客攻击行为，用以发现网站安全漏洞的工具。许多大型网站的安全团队都有自己开发的漏洞扫描工具，不定期地对网站的服务器进行扫描，查漏补缺。市场上也有很多商用的网站安全漏洞扫描平台。</p>
</blockquote>
</blockquote>
<h6 id="◆-8-2-信息加密技术及密钥安全管理" tabindex="-1"><a class="header-anchor" href="#◆-8-2-信息加密技术及密钥安全管理" aria-hidden="true">#</a> ◆ 8.2 信息加密技术及密钥安全管理</h6>
<blockquote>
<blockquote>
<p>信息加密技术可分为三类：单项散列加密、对称加密和非对称加密。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>常用的单向散列算法有MD5、SHA等。单向散列算法还有一个特点就是输入的任何微小变化都会导致输出的完全不同，这个特性有时也会被用来生成信息摘要、计算具有高离散程度的随机数等用途。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对称加密是指加密和解密使用的密钥是同一个密钥（或者可以互相推算）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对称加密通常用在信息需要安全交换或存储的场合，如Cookie加密、通信加密等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对称加密的优点是算法简单，加解密效率高，系统开销小，适合对大量数据加密。缺点是加解密使用同一个密钥，远程通信的情况下如何安全的交换密钥是个难题，如果密钥丢失，那么所有的加密信息也就没有秘密可言了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>常用的对称加密算法有DES算发、RC算法等</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>非对称加密和解密使用的密钥不是同一密钥，其中一个对外界公开，被称作公钥，另一个只有所有者知道，被称作私钥。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>非对称加密技术通常用在信息安全传输，数字签名等场合。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实际应用中，常常会混合使用对称加密和非对称加密。先使用非对称加密技术对对称密钥进行安全传输，然后使用对称加密技术进行信息加解密与交换。而有时，对同一个数据两次使用非对称加密，可同时实现信息安全传输与数字签名的目的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>非对称加密的常用算法有RSA算法等。HTTPS传输中浏览器使用的数字证书实质上是经过权威机构认证的非对称加密的公钥。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>密钥安全管理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>前述的几种加密技术，能够达到安全保密效果的一个重要前提是密钥的安全。不管是单向散列加密用到的salt、对称加密的密钥、还是非对称加密的私钥，一旦这些密钥泄露出去，那么所有基于这些密钥加密的信息就失去了秘密性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>改善密钥安全性的手段有两种</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一种方案是把密钥和算法放在一个独立的服务器上，甚至做成一个专用的硬件设施，对外提供加密和解密服务，应用系统通过调用这个服务，实现数据的加解密。由于密钥和算法独立部署，由专人维护，使得密钥泄露的概率大大降低。但是这种方案成本较高，而且有可能会成为应用的瓶颈，每次加密、解密都需要进行一次远程服务调用，系统性能开销也较大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另一种方案是将加解密算法放在应用系统中，密钥则放在独立服务器中，为了提高密钥的安全性，实际存储时，密钥被切分成数片，加密后分别保存在不同存储介质中，兼顾密钥安全性的同时又改善了性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用程序调用密钥安全管理系统提供的加解密服务接口对信息进行加解密，该接口实现了常用的加密解密算法并可根据需求任意扩展。加解密服务接口通过密钥服务器的密钥服务取得加解密密钥，并缓存在本地（定时更新）。而密钥服务器中的密钥则来自多个密钥存储服务器，一个密钥分片后存储在多个存储服务器中，每个服务器都有专人负责管理。密钥申请者、密钥管理者、安全审核人员通过密钥管理控制台管理更新密钥，每个人各司其事，没有人能查看完整的密钥信息。</p>
</blockquote>
</blockquote>
<h6 id="◆-8-3-信息过滤与反垃圾" tabindex="-1"><a class="header-anchor" href="#◆-8-3-信息过滤与反垃圾" aria-hidden="true">#</a> ◆ 8.3 信息过滤与反垃圾</h6>
<blockquote>
<blockquote>
<p>常用的信息过滤与反垃圾手段有以下几种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>文本匹配</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>文本匹配主要解决敏感词过滤的问题。通常网站维护一份敏感词列表，如果用户发表的信息含有列表中的敏感词，则进行消毒处理（将敏感词转义为***）或拒绝发表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>那么如何快速地判断用户信息中是否含有敏感词呢？如果敏感词比较少，用户提交信息文本长度也较短，可直接使用正则表达式匹配。但是正则表达式的效率一般较差，当敏感词很多，用户发布的信息也很长，网站并发量较高时，就需要更合适的方法来完成，这方面公开的算法有很多，基本上都是Trie树的变种，空间和时间复杂度都比较好的有双数组Trie算法等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Trie算法的本质是确定一个有限状态自动机，根据输入数据进行状态转移。双数组Trie算法优化了Trie算法，利用两个稀疏数组存储树结构，base数组存储Trie树的节点，check数组进行状态检查。双数组Trie数需要根据业务场景和经验确定数组大小，避免数组过大或者冲突过多。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另一种更简单的实现是通过构造多级Hash表进行文本匹配。假设敏感词表包含敏感词：阿拉伯、阿拉汗、阿油、北京、北大荒、北风。那么可以构造如图8.11所示的过滤树，用户提交的信息逐字顺序在过滤树中匹配。过滤树的分支可能会比较多，为了提高匹配速度，减少不必要的查找，同一层中相同父节点的字可放在Hash表中。该方案处理速度较快，稍加变形，即可适应各种过滤场景，缺点是使用Hash表会浪费部分内存空间，如果网站敏感词数量不多，浪费部分内存还是可以接受的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有时候，为了绕过敏感词检查，某些输入信息会被做一些手脚，如“阿_拉_伯”，这时候还需要对信息做降噪预处理，然后再进行匹配。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分类算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对广告贴、垃圾邮件等内容的识别比较好的自动化方法是采用分类算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>先将批量已分类的邮件样本（如50000封正常邮件，2000封垃圾邮件）输入分类算法进行训练，得到一个垃圾邮件分类模型，然后利用分类算法结合分类模型对待处理邮件进行识别。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>比较简单实用的分类算法有贝叶斯分类算法，这是一种利用概率统计方法进行分类的算法。贝叶斯算法解决概率论中的一个典型问题：一号箱子放有红色球和白色球各20个，二号箱子放有白色球10个，红色球30个，现在随机挑选一个箱子，取出来一个球的颜色是红色的，请问这个球来自一号箱子的概率是多少。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>利用贝叶斯算法进行垃圾邮件的识别基于同样原理，根据已分类的样本信息获得一组特征值的概率，如“茶叶”这个词出现在垃圾邮件中的概率为20%，出现在非垃圾邮件中的概率为1%，就得到分类模型。然后对待处理邮件提取特征值，比如取到了茶叶这个特征值，结合分类模型，就可以判断其分类。贝叶斯算法得到的分类判断是一个概率值，因此会存在误判（非垃圾邮件判为垃圾邮件）和漏判（垃圾邮件判为非垃圾邮件）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>贝叶斯算法认为特征值之间是独立的，所以也被称作是朴素贝叶斯算法（NativeBayes），这个假设很多时候是不成立的，特征值之间具有关联性，通过对朴素贝叶斯算法增加特征值的关联依赖处理，得到TA N算法。更进一步，通过对关联规则的聚类挖掘，得到更强大的算法，如ARCS算法（Association Rule ClusteringSystem）等。但是由于贝叶斯分类算法简单，处理速度快，仍是许多实时在线系统反垃圾的首选。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分类算法除了用于反垃圾，还可用于信息自动分类，门户网站可用该算法对采集来的新闻稿件进行自动分类，分发到不同的频道。邮箱服务商根据邮件内容推送的个性化广告也可以使用分类算法提高投送相关度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>黑名单</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于垃圾邮件，除了用分类算法进行内容分类识别，还可以使用黑名单技术，将被报告的垃圾邮箱地址放入黑名单，然后针对邮件的发件人在黑名单列表中查找，如果查找成功，则过滤该邮件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>黑名单也可用于信息去重，如将文章标题或者文章关键段落记录到黑名单中，以减少搜索引擎收录重复信息等用途。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>黑名单可以通过Hash表实现，该方法实现简单，时间复杂度小，满足一般场景使用。但是当黑名单列表非常大时，Hash表需要占据极大的内存空间。例如在需要处理10亿个黑名单邮件地址列表的场景下，每个邮件地址需要8个字节的信息指纹，即需要8GB内存，为了减少Hash冲突，还需要一定的Hash空间冗余，假如空间利用率为50%，则需要16GB的内存空间。随着列表的不断增大，一般服务器将不可承受这样的内存需求。而且列表越大，Hash冲突越多，检索速度越慢。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在对过滤需求要求不完全精确的场景下，可用布隆过滤器代替Hash表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过一个二进制列表和一组随机数映射函数实现</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>仍以需要处理10亿邮件地址黑名单列表为例，在内存中建立一个2GB大小的存储空间，即16GB个二进制bit，并全部初始化为0。要将一个邮箱地址加入黑名单时，使用8个随机映射函数（F1,F2,…,F8）得到0~16GB范围内的8个随机数，从而将该邮箱地址映射到16GB二进制存储空间的8个位置上，然后将这些位置置为1。当要检查一个邮箱地址是否在黑名单中时，使用同样的映射函数，得到16GB空间8个位置上的bit，如果这些值都为1，那么该邮箱地址在黑名单中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以看到，处理同样数量的信息，布隆过滤器只使用Hash表所需内存的1/8。但是布隆过滤器有可能导致系统误判（布隆过滤器检查在黑名单中，但实际却并未放入过）。因为一个邮箱地址映射的8个bit可能正好都被其他邮箱地址设为1了，这种可能性极小，通常在系统可接受范围内。但如果需要精确的判断，则不适合使用布隆过滤器。</p>
</blockquote>
</blockquote>
<h6 id="◆-8-4-电子商务风险控制" tabindex="-1"><a class="header-anchor" href="#◆-8-4-电子商务风险控制" aria-hidden="true">#</a> ◆ 8.4 电子商务风险控制</h6>
<blockquote>
<blockquote>
<p>大型电商网站都配备有专门的风控团队进行风险控制，风控的手段也包括自动和人工两种。机器自动识别为高风险的交易和信息会发送给风控审核人员进行人工审核，机器自动风控的技术和方法也不断通过人工发现的新风险类型进行逐步完善。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>机器自动风控的技术手段主要有规则引擎和统计模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.规则引擎当交易的某些指标满足一定条件时，就会被认为具有高风险的欺诈可能性。比如用户来自欺诈高发地区；交易金额超过某个数值；和上次登录的地址距离差距很大；用户登录地与收货地不符；用户第一次交易等等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型网站在运营过程中，结合业界的最新发现，会总结出数以千计的此类高风险交易规则。一种方案是在业务逻辑中通过编程方式使用if…else…代码实现这些规则，可想而知，这些代码会非常庞大，而且由于运营过程中不断发现新的交易风险类型，需要不断调整规则，代码也需要不断修改……</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>网站一般使用规则引擎技术处理此类问题。规则引擎是一种将业务规则和规则处理逻辑相分离的技术，业务规则文件由运营人员通过管理界面编辑，当需要修改规则时，无需更改代码发布程序，即可实时使用新规则。而规则处理逻辑则调用规则处理输入的数据</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.统计模型</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>规则引擎虽然技术简单，但是随着规则的逐渐增加，会出现规则冲突，难以维护等情况，而且规则越多，性能也越差。目前大型网站更倾向于使用统计模型进行风控。风控领域使用的统计模型使用前面提到的分类算法或者更复杂的机器学习算法进行智能统计。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>根据历史交易中的欺诈交易信息训练分类算法，然后将经过采集加工后的交易信息输入分类算法，即可得到交易风险分值。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>经过充分训练后的统计模型，准确率不低于规则引擎。分类算法的实时计算性能更好一些，由于统计模型使用模糊识别，并不精确匹配欺诈类型规则，因此对新出现的交易欺诈还具有一定预测性。</p>
</blockquote>
</blockquote>
<h6 id="◆-8-5-小结" tabindex="-1"><a class="header-anchor" href="#◆-8-5-小结" aria-hidden="true">#</a> ◆ 8.5 小结</h6>
<blockquote>
<blockquote>
<p>网站的相对安全是通过提高攻击门槛达到的。让攻击者为了获得有限的利益必须付出更大的代价，致使其得不偿失，望而却步。</p>
</blockquote>
</blockquote>
<h3 id="◆-9-2-淘宝网技术架构演化" tabindex="-1"><a class="header-anchor" href="#◆-9-2-淘宝网技术架构演化" aria-hidden="true">#</a> ◆ 9.2 淘宝网技术架构演化</h3>
<blockquote>
<blockquote>
<p>2003年，花3000美金买来的淘宝网站是用PHP开发的，淘宝的工程师做了简单的汉化处理，并对数据库做了读写分离</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2004年，淘宝在SUN技术顾问的协助下进行了一次重要的重构，放弃了原来的LAMP架构，转而使用Java作为开发平台，使用Oracle做后端数据库</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统架构使用了当时在企业应用领域崭露头角的MVC框架和ORM框架，分别解决视图与业务逻辑分离的问题和对象与关系数据库解耦的问题，淘宝没有使用当时风头正劲的Struts和Hibernate，而是选择了自己开发MVC框架Webx，而ORM框架则选择了IBatis。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>随着淘宝技术的不断发展壮大，淘宝对集群环境下分布式高可用系统的架构设计技术越来越得心应手，Oracle、IBM、EMC也变得不是必须，于是淘宝开始逐步放弃使用这些昂贵的设备和软件，回归到开源的MySQL及NoSQL系统，正如淘宝2003年建站之初的选择。这也再一次验证了辩证法关于事物发展的否定之否定及螺旋式上升的普遍规律，仿佛回到原点，但一切已经完全不同了。</p>
</blockquote>
</blockquote>
<h3 id="◆-10-1-wikipedia网站整体架构" tabindex="-1"><a class="header-anchor" href="#◆-10-1-wikipedia网站整体架构" aria-hidden="true">#</a> ◆ 10.1 Wikipedia网站整体架构</h3>
<blockquote>
<blockquote>
<p>目前Wikipedia网站建立在LAMP（Linux+Apache+MySQL+PHP）之上，其他基础技术组件也全部采用免费的开源软件。因为Wikipedia是非盈利的，所以尽可能使用免费的软件和廉价的服务器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Wikipedia架构的主要组成部分如下。GeoDNS：基于开源域名服务器软件BIND（Berkeley Internet Name Domain）的增强版本，可将域名解析到离用户最近的服务器。LVS：基于Linux的开源负载均衡服务器。Squid：基于Linux的开源反向代理服务器。Lighttpd：开源的应用服务器，较主流的Apache服务器更轻量、更快速。实践中，有许多网站使用Lighttpd作为图片服务器。PHP：免费的Web应用程序开发语言，最流行的网站建站语言。Memcached：无中心高性能的开源分布式缓存系统，稳定、可靠、历久弥新，是网站分布式缓存服务必备的。Lucene：由Apache出品，Java开发的开源全文搜索引擎。MySQL：开源的关系数据库管理系统，虽被Oracle收购，但开源社区将其继续开源发展的决心不动摇。</p>
</blockquote>
</blockquote>
<h6 id="◆-10-2-wikipedia性能优化策略" tabindex="-1"><a class="header-anchor" href="#◆-10-2-wikipedia性能优化策略" aria-hidden="true">#</a> ◆ 10.2 Wikipedia性能优化策略</h6>
<blockquote>
<blockquote>
<p>作为一个百科服务类网站，Wikipedia主要面临的挑战是如何应对来自全球各地的巨量并发的词条查询请求。相对其他网站，Wikipedia的业务比较简单，用户操作大部分是只读的，这些前提使Wikipedia的性能优化约束变得简单，可以让技术团队将每一种性能优化手段都发挥到极致，且业务束缚较少。因此Wikipedia的性能优化比较有典型意义。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Wikipedia前端性能优化</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓网站前端是指应用服务器（也就是PHP服务器）之前的部分，包括DNS服务、CDN服务、反向代理服务、静态资源服务等</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对Wikipedia而言，80%以上的用户请求可以通过前端服务返回，请求根本不会到达应用服务器，这也就使得网站最复杂、最有挑战的应用服务端和存储端压力骤减。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Wikipedia前端架构的核心是反向代理服务器Squid集群，大约部署有数十台服务器，请求通过LVS负载均衡地分发到每台Squid服务器，热点词条被缓存在这里，大量请求可直接返回响应，请求无需发送到Apache服务器，减轻应用负载压力。Squid缓存不能命中的请求再通过LVS发送到Apache应用服务器集群，如果有词条信息更新，应用服务器使用Invalidation Notification服务通知Squid缓存失效，重新访问应用服务器更新词条。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在反向代理Squid之前，则是被Wikipedia技术团队称为“圣杯”的CDN服务，CDN服务对于Wikipedia性能优化居功至伟。因为用户查询的词条大部分集中在比重很小的热点词条上，将这些词条内容页面缓存在CDN服务器上，而CDN服务器又部署在离用户浏览器最近的地方，用户请求直接从CDN返回，响应速度非常快，这些请求甚至根本不会到达Wikipedia数据中心的Squid服务器，服务器压力减小，节省的资源可以更快地处理其他未被CDN缓存的请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Wikipedia CDN缓存的几条准则为：●内容页面不包含动态信息，以免页面内容缓存很快失效或者包含过时信息。●每个内容页面有唯一的REST风格的URL，以便CDN快速查找并避免重复缓存。●在HTML响应头写入缓存控制信息，通过应用控制内容是否缓存及缓存有效期等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Wikipedia还使用许多其他开源组件对应用层进行如下优化。●使用APC，这是一个PHP字节码缓存模块，可以加速代码执行减少资源消耗。●使用Imagemagick进行图片处理和转化。●使用Tex进行文本格式化，特别是将科学公式内容转换成图片格式。●替换PHP的字符串查找函数strtr()，使用更优化的算法重构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Wikipedia后端性能优化</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>后端服务通常是一些有状态的服务，即需要提供数据存储服务，这些服务大多建立在网络通信和磁盘操作基础上，是性能的瓶颈，也是性能优化的重灾区。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>后端优化最主要的手段是使用缓存，将热点数据缓存在分布式缓存系统的内存中，加速应用服务器的数据读操作速度，减轻存储和数据库服务器的负载。Wikipedia的缓存使用策略如下：●热点特别集中的数据直接缓存到应用服务器的本地内存中，因为要占用应用服务器的内存且每台服务器都需要重复缓存这些数据，因此这些数据量很小，但是读取频率极高。●缓存数据的内容尽量是应用服务器可以直接使用的格式，比如HTML格式，以减少应用服务器从缓存中获取数据后解析构造数据的代价。●使用缓存服务器存储session对象。●相比数据库，Memcached的持久化连接非常廉价，如有需要就创建一个Memcached连接。作为存储核心资产的MySQL数据库，Wikipedia也做了如下优化：●使用较大的服务器内存。在Wikipedia应用场景中，增加内存比增加其他资源更能改善MySQL性能。●使用RAID0磁盘阵列以加速磁盘访问，RAID0虽然加速磁盘访问，但是却降低了数据库的持久可靠性（一块盘坏了，整个数据库的数据都不完整了）。显然Wikipedia认为性能问题迫在眉睫，而数据可靠性问题可以通过其他手段解决（如MySQL主从复制，数据异步备份等）。●将数据库事务一致性设置在较低水平，加快宕机恢复速度。●如果Master数据库宕机，立即将应用切换到Salve数据库，同时关闭数据写服务，这意味着关闭词条编辑功能。Wikipedia通过约束业务获得更大的技术方案选择余地，很多时候业务后退一小步，技术就可以前进一大步。</p>
</blockquote>
</blockquote>
<h3 id="◆-11-海量分布式存储系统doris的高可用架构设计分析" tabindex="-1"><a class="header-anchor" href="#◆-11-海量分布式存储系统doris的高可用架构设计分析" aria-hidden="true">#</a> ◆ 11 海量分布式存储系统Doris的高可用架构设计分析</h3>
<blockquote>
<blockquote>
<p>对于一个数据存储系统而言，高可用意味着两个意思：●高可用的服务：任何时候，包括宕机、硬盘损坏、系统升级、停机维护、集群扩容等各种情况，都可以对系统进行读写访问操作。●高可靠的数据：任何情况下，数据可靠存储，不丢失。</p>
</blockquote>
</blockquote>
<h6 id="◆-11-1-分布式存储系统的高可用架构" tabindex="-1"><a class="header-anchor" href="#◆-11-1-分布式存储系统的高可用架构" aria-hidden="true">#</a> ◆ 11.1 分布式存储系统的高可用架构</h6>
<blockquote>
<blockquote>
<p>对一个大规模集群的存储系统而言，服务器宕机、交换机失效是常态，架构师必须为这些故障发生时，保证系统依然可用而进行系统设计。在系统架构层面，保证高可用的主要手段是冗余：服务器热备，数据多份存储。使整个集群在部分机器故障的情况下可以进行灵活的失效转移（Failover），保证系统整体依然可用，数据持久可靠。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统整体上可分为如下三个部分。●应用程序服务器：它们是存储系统的客户，对系统发起数据操作请求。●数据存储服务器：他们是存储系统的核心，负责存储数据、响应应用服务器的数据操作请求。●管理中心服务器：这是一个由两台机器组成的主-主热备的小规模服务器集群，主要负责集群管理，对数据存储集群进行健康心跳检测；集群扩容、故障恢复管理；对应用程序服务器提供集群地址配置信息服务等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用服务器写入数据时，根据集群配置和应用可用性级别使用路由算法在每个序列中计算得到一台服务器，然后同时并发写入这些服务器中；应用服务器读取数据时，只需要随机选择一个序列，根据相同路由算法计算得到服务器编号和地址，即可读取。通常情况下，系统最少写入的副本份数是两份</p>
</blockquote>
</blockquote>
<h3 id="◆-12-1-秒杀活动的技术挑战" tabindex="-1"><a class="header-anchor" href="#◆-12-1-秒杀活动的技术挑战" aria-hidden="true">#</a> ◆ 12.1 秒杀活动的技术挑战</h3>
<blockquote>
<blockquote>
<p>并发请求数是10,000，秒杀系统需要面对的技术挑战有如下几点</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.对现有网站业务造成冲击</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.高并发下的应用、数据库负载</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户在秒杀开始前，通过不停刷新浏览器页面以保证不会错过秒杀，这些请求如果按照一般的网站应用架构，访问应用服务器、连接数据库，会对应用服务器和数据库服务器造成极大的负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.突然增加的网络及服务器带宽</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设商品页面大小200K（主要是商品图片大小），那么需要的网络和服务器带宽是2G（200K×10,000），这些网络带宽是因为秒杀活动新增的，超过网站平时使用的带宽。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.直接下单</p>
</blockquote>
</blockquote>
<h6 id="◆-12-2-秒杀系统的应对策略" tabindex="-1"><a class="header-anchor" href="#◆-12-2-秒杀系统的应对策略" aria-hidden="true">#</a> ◆ 12.2 秒杀系统的应对策略</h6>
<blockquote>
<blockquote>
<p>秒杀系统的应对策略有如下几点</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.秒杀系统独立部署</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.秒杀商品页面静态化</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>重新设计秒杀商品页面，不使用网站原来的商品详情页面，页面内容静态化：将商品描述、商品参数、成交记录和用户评价全部写入一个静态页面，用户请求不需要经过应用服务器的业务逻辑处理，也不需要访问数据库。所以秒杀商品服务不需要部署动态的Web服务器和数据库服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.租借秒杀活动网络带宽因为秒杀新增的网络带宽，必须和运营商重新购买或者租借。为了减轻网站服务器的压力，需要将秒杀商品页面缓存在CDN，同样需要和CDN服务商临时租借新增的出口带宽。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4.动态生成随机下单页面URL</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了避免用户直接访问下单页面URL，需要将该URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。</p>
</blockquote>
</blockquote>
<h6 id="◆-12-3-秒杀系统架构设计" tabindex="-1"><a class="header-anchor" href="#◆-12-3-秒杀系统架构设计" aria-hidden="true">#</a> ◆ 12.3 秒杀系统架构设计</h6>
<blockquote>
<blockquote>
<p>1.如何控制秒杀商品页面购买按钮的点亮购买按钮只有在秒杀活动开始的时候才能点亮，在此之前是灰色的。如果该页面是动态生成的，当然可以在服务器端构造响应页面输出，控制该按钮是灰色还是点亮，但是为了减轻服务器端负载压力，更好地利用CDN、反向代理等性能优化手段，该页面被设计为静态页面，缓存在CDN、反向代理服务器上，甚至用户浏览器上。秒杀开始时，用户刷新页面，请求根本不会到达应用服务器。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>解决办法是使用JavaScript脚本控制，在秒杀商品静态页面中加入一个JavaScript文件引用，该JavaScript文件中加入秒杀是否开始的标志和下单页面URL的随机数参数，当秒杀开始的时候生成一个新的JavaScript文件并被用户浏览器加载，控制秒杀商品页面的展示。这个JavaScript文件使用随机版本号，并且不被浏览器、CDN和反向代理服务器缓存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这个JavaScript文件非常小，即使每次浏览器刷新都访问JavaScript文件服务器也不会对服务器集群和网络带宽造成太大压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.如何只允许第一个提交的订单被发送到订单子系统由于最终能够成功秒杀到商品的用户只有一个，因此需要在用户提交订单时，检查是否已经有订单提交。事实上，由于最终能够成功提交订单的用户只有一个，为了减轻下单页面服务器的负载压力，可以控制进入下单页面的入口，只有少数用户能进入下单页面，其他用户直接进入秒杀结束页面。假设下单服务器集群有10台服务器，每台服务器只接受最多10个下单请求</p>
</blockquote>
</blockquote>
<h3 id="◆-13-大型网站典型故障案例分析" tabindex="-1"><a class="header-anchor" href="#◆-13-大型网站典型故障案例分析" aria-hidden="true">#</a> ◆ 13 大型网站典型故障案例分析</h3>
<blockquote>
<blockquote>
<p>大型网站的架构师最有价值的地方不在于他们掌握了多少技术，而在于他们经历过多少故障。每一次故障都会给公司带来难以估计的利益损失，所以培养一个网站架构师的成本不单要看付了他多少薪水，给了他多少股票，还要看为他引起的故障买了多少次单。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-1-写日志也会引发故障" tabindex="-1"><a class="header-anchor" href="#◆-13-1-写日志也会引发故障" aria-hidden="true">#</a> ◆ 13.1 写日志也会引发故障</h6>
<blockquote>
<blockquote>
<p>●应用程序自己的日志输出配置和第三方组件日志输出要分别配置。●检查log配置文件，日志输出级别至少为Warn，并且检查log输出代码调用，调用级别要符合其真实日志级别。●有些开源的第三方组件也会不恰当地输出太多的Error日志，需要关闭这些第三方库的日志输出，至于哪些第三方库有问题，只有在遇到问题时才知道。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-2-高并发访问数据库引发的故障" tabindex="-1"><a class="header-anchor" href="#◆-13-2-高并发访问数据库引发的故障" aria-hidden="true">#</a> ◆ 13.2 高并发访问数据库引发的故障</h6>
<blockquote>
<blockquote>
<p>●首页不应该访问数据库，首页需要的数据可以从缓存服务器或者搜索引擎服务器获取。●首页最好是静态的。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-3-高并发情况下锁引发的故障" tabindex="-1"><a class="header-anchor" href="#◆-13-3-高并发情况下锁引发的故障" aria-hidden="true">#</a> ◆ 13.3 高并发情况下锁引发的故障</h6>
<blockquote>
<blockquote>
<p>故障现象：某应用服务器不定时地因为响应超时而报警，但是很快又超时解除，恢复正常，如此反复，让运维人员非常苦恼。原因分析：程序中某个单例对象（singleton object）中多处使用了synchronized（this），由于this对象只有一个，所有的并发请求都要排队获得这唯一的一把锁。一般情况下，都是一些简单操作，获得锁，迅速完成操作，释放锁，不会引起线程排队。但是某个需要远程调用的操作也被加了synchronized（this），这个操作只是偶尔会被执行，但是每次执行都需要较长的时间才能完成，这段时间锁被占用，所有的用户线程都要等待，响应超时，这个操作执行完后释放锁，其他线程迅速执行，超时解除。经验教训：●使用锁操作要谨慎。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-5-应用启动不同步引发的故障" tabindex="-1"><a class="header-anchor" href="#◆-13-5-应用启动不同步引发的故障" aria-hidden="true">#</a> ◆ 13.5 应用启动不同步引发的故障</h6>
<blockquote>
<blockquote>
<p>在应用程序中加入一个特定的动态页面（比如只返回OK两个字母），启动脚本先启动JBoss，然后在脚本中不断用curl命令访问这个特定页面，直到收到OK，才启动Apache。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-6-大文件读写独占磁盘引发的故障" tabindex="-1"><a class="header-anchor" href="#◆-13-6-大文件读写独占磁盘引发的故障" aria-hidden="true">#</a> ◆ 13.6 大文件读写独占磁盘引发的故障</h6>
<blockquote>
<blockquote>
<p>故障现象：某应用主要功能是管理用户图片，接到部分用户投诉，表示上传图片非常慢，原来只需要一两秒，现在需要几十秒，有时等半天结果浏览器显示服务器超时。原因分析：图片需要使用存储，最有可能出错的地方是存储服务器。检查存储服务器，发现大部分文件只有几百KB，而有几个文件非常大，有数百兆，读写这些大文件一次需要几十秒，这段时间，磁盘基本被这个文件操作独占，导致其他用户的文件操作缓慢。经验教训：●存储的使用需要根据不同文件类型和用途进行管理，图片都是小文件，应该使用专用的存储服务器，不能和大文件共用存储。批处理用的大文件可以使用其他类型的分布式文件系统。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-7-滥用生产环境引发的故障" tabindex="-1"><a class="header-anchor" href="#◆-13-7-滥用生产环境引发的故障" aria-hidden="true">#</a> ◆ 13.7 滥用生产环境引发的故障</h6>
<blockquote>
<blockquote>
<p>●访问线上生产环境要规范，不小心就会导致大事故。网站数据库有专门的DBA维护，如果发现数据库存在错误记录，需要进行数据订正，必须走数据订正流程，申请DBA协助。于是就有工程师为避免麻烦，直接写一段数据库更新操作的代码，悄悄放到生产环境应用服务器上执行，神不知鬼不觉地订正了数据。但是如果不小心写错了SQL，后果可想而知。</p>
</blockquote>
</blockquote>
<h6 id="◆-13-8-不规范的流程引发的故障" tabindex="-1"><a class="header-anchor" href="#◆-13-8-不规范的流程引发的故障" aria-hidden="true">#</a> ◆ 13.8 不规范的流程引发的故障</h6>
<blockquote>
<blockquote>
<p>●代码提交前使用diff命令进行代码比较，确认没有提交不该提交的代码。●加强code review，代码在正式提交前必须被至少一个其他工程师做过codereview，并且共同承担因代码引起的故障责任。</p>
</blockquote>
</blockquote>
<h3 id="◆-第4篇-架构师" tabindex="-1"><a class="header-anchor" href="#◆-第4篇-架构师" aria-hidden="true">#</a> ◆ 第4篇 架构师</h3>
<blockquote>
<blockquote>
<p>架构师是软件开发组织中一个比较特殊的角色，除了架构设计，软件开发等技术类工作，通常还需要承担一些管理职能：规划产品路线、估算人力资源和时间资源、安排人员职责分工，确定计划里程碑点、指导工程师工作、过程风险评估与控制等。这些管理事务需要对产品技术架构、功能模块划分、技术风险都熟悉的架构师参与或直接负责。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在软件开发过程中，架构师除了实现技术架构，完成产品技术实现外，还需要和项目组内外各种角色沟通协调，可以说架构师相当多的时间用在和人打交道上。处理好人的关系对架构和项目的成功至关重要。</p>
</blockquote>
</blockquote>
<h6 id="◆-14-1-关注人而不是产品" tabindex="-1"><a class="header-anchor" href="#◆-14-1-关注人而不是产品" aria-hidden="true">#</a> ◆ 14.1 关注人而不是产品</h6>
<blockquote>
<blockquote>
<p>一定要坚信：一群优秀的人做一件他们热爱的事，一定能取得成功。不管过程多么曲折，不管外人看来多么不可思议不靠谱。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所以最好的软件项目管理不是制订计划，组织资源，跟踪修正项目进展，对成员进行激励和惩罚，而是发掘项目组每个成员的优秀潜能，让大家理解并热爱软件产品最终的蓝图和愿景。每个人都是为实现自我价值而努力，不是为了领工资而工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>寻找一个值得共同奋斗的目标，营造一个让大家都能最大限度发挥自我价值的工作氛围。</p>
</blockquote>
</blockquote>
<h6 id="◆-14-2-发掘人的优秀" tabindex="-1"><a class="header-anchor" href="#◆-14-2-发掘人的优秀" aria-hidden="true">#</a> ◆ 14.2 发掘人的优秀</h6>
<blockquote>
<blockquote>
<p>是事情成就了人，而不是人成就了事。指望优秀的人来帮自己成事，不如做成一件事让自己和参与的人都变得优秀。</p>
</blockquote>
</blockquote>
<h6 id="◆-14-3-共享美好蓝图" tabindex="-1"><a class="header-anchor" href="#◆-14-3-共享美好蓝图" aria-hidden="true">#</a> ◆ 14.3 共享美好蓝图</h6>
<blockquote>
<blockquote>
<p>蓝图应该是表述清楚的：产品要做什么、不做什么、要达到什么业务目标，都需要描述清楚。蓝图应该是形象的：产品能为用户创造什么价值、能实现什么样的市场目标、产品最终会长什么样，都需要形象地想象出来。蓝图应该是简单的：不管内部还是外部沟通，都能一句话说明白：我们在做什么。</p>
</blockquote>
</blockquote>
<h6 id="◆-14-6-成就他人" tabindex="-1"><a class="header-anchor" href="#◆-14-6-成就他人" aria-hidden="true">#</a> ◆ 14.6 成就他人</h6>
<blockquote>
<blockquote>
<p>我们活着不是为了工作，不是为了做设计、写程序，这些不是我们生活的目的。我们活着是为了成就我们自己，而要想成就自己，就必须首先成就他人。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每个人都有自己成就的目标，而工作是达成自我成就的一种手段：通过工作的挑战，发掘自我的潜能，重新认知自我和世界。</p>
</blockquote>
</blockquote>
<h3 id="◆-15-网站架构师职场攻略" tabindex="-1"><a class="header-anchor" href="#◆-15-网站架构师职场攻略" aria-hidden="true">#</a> ◆ 15 网站架构师职场攻略</h3>
<blockquote>
<blockquote>
<p>开发软件的目的是为了解决现实世界的问题，但是很多时候人们并不清楚真正的问题是什么。有可能大家很辛苦地忙活了一场，发现做出来的软件一点价值没有。</p>
</blockquote>
</blockquote>
<h6 id="◆-15-1-发现问题-寻找突破" tabindex="-1"><a class="header-anchor" href="#◆-15-1-发现问题-寻找突破" aria-hidden="true">#</a> ◆ 15.1 发现问题，寻找突破</h6>
<blockquote>
<blockquote>
<p>有些问题在被解决以后，人们才发现事情原来可以这样啊。淘宝出现之后，人们发现购物可以更便宜、更便捷；iPhone出现之后，人们发现手机原来可以不光用来打电话发短信；而微信出现之后，人们才发现手机发短信甚至打电话竟然可以不花钱。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓问题，就是体验—期望，当体验不能满足期望，就会觉得出了问题。消除问题有两种手段：改善体验或者降低期望。降低期望只是回避了问题，而如果直面期望和体验之间的差距，就会发现问题所在，找到突破点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>新员工最不需要做的事情就是证明自己的能力。在新环境中一时施展不开就怀疑自己的能力，进而担心被其他人怀疑自己的能力，于是努力想要证明自己，但是常常事与愿违，反而出乱子，伤害了公司和自己的利益。其实既然能经过层层考核和挑选进入公司，就已经证明你有和工作要求相匹配的能力，你要相信当初选中你的同事的眼光和能力。</p>
</blockquote>
</blockquote>
<h3 id="◆-16-3-按职责角色划分架构师" tabindex="-1"><a class="header-anchor" href="#◆-16-3-按职责角色划分架构师" aria-hidden="true">#</a> ◆ 16.3 按职责角色划分架构师</h3>
<blockquote>
<blockquote>
<p>产品架构师负责具体互联网产品的技术架构。当产品业务规划确定后，产品架构师就要开始产品的架构设计了，和运营团队确定PV数、用户数、商品数等产品运营目标、发展规划、非功能指标；和产品经理确定功能需求、模块划分等功能目标；和项目经理确定各种开发资源。获得必要的信息后进行整体架构设计，参与项目开发。产品架构师一般会参与产品的整个生命周期。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基础服务架构师有时候也被称为平台架构师，负责开发基础框架、公共组件、通用服务等平台类产品。在大型互联网应用中，基础服务承担着海量的数据存储和核心业务处理服务，有许多挑战性的工作。基础设施架构师负责网络、存储、数据库运维管理的架构师，此类架构师一般有专门的称呼（如DBA等）。</p>
</blockquote>
</blockquote>
<p>◆ 附录A大型网站架构技术一览</p>
<blockquote>
<blockquote>
<p>附录A大型网站架构技术一览</p>
</blockquote>
</blockquote>
<p>◆ 附录B Web开发技术发展历程</p>
<blockquote>
<blockquote>
<p>早期的Web服务器只简单地响应浏览器端的请求，返回静态的HTML。随着CGI（CommonGateway Interface，通用网关接口）技术的出现，Web服务端可以根据不同用户请求产生动态页面内容</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Web服务器将请求数据交给CGI程序，CGI程序进行运算处理，生成HTML输出，通过Web服务器返回给浏览器。早期主要的CGI编程语言是Perl，高效便捷的开发特性使其成为当时许多网站开发的首选。但是Web服务器通过启动独立进程的方式调用CGI程序，消耗许多不必要的系统资源。Java Servlet则以线程方式在Java Web容器中调用Servlet，较CGI方式消耗资源更少。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般来说CGI技术（广义上也包括Java Servlet）被称作脚本模式，CGI程序需要解析HTTP请求，处理业务逻辑，并在输出流中构造响应信息的HTML。这种技术的优点和缺点是同一个特性——可以在CGI程序中做任何事情。CGI程序在获得最大处理能力的同时，也给开发人员带来了麻烦：负责编写业务逻辑程序的程序员不擅长处理HTML，而负责页面构造的美工人员则对程序束手无策。同样维护这样的程序也是一个噩梦，业务代码和页面语法耦合在一起，让人无从下手。PHP及随后ASP、JSP的出现改善了这一局面，与CGI在程序中输出HTML流正好相反，开发人员可以在HTML中嵌入程序代码。这种模式被称作服务器页面模式。直到现在，PHP仍然是许多中小型网站建站首选技术，和Apache、MySQL、Linux共同组成一个强大的Web开发平台，被称作LAMP。</p>
</blockquote>
</blockquote>
</div></template>


