<template><div><h1 id="超大流量分布式系统架构解决方案-人人都是架构师2-0" tabindex="-1"><a class="header-anchor" href="#超大流量分布式系统架构解决方案-人人都是架构师2-0" aria-hidden="true">#</a> 超大流量分布式系统架构解决方案：人人都是架构师2.0</h1>
<p>高翔龙</p>
<h2 id="◆-前言" tabindex="-1"><a class="header-anchor" href="#◆-前言" aria-hidden="true">#</a> ◆ 前言</h2>
<blockquote>
<blockquote>
<p>验证系统所能够承受的最大负载是否接近于预期，是否经得住大流量的冲击，绝非是一件易事。有过分布式系统开发经验的同学都应该非常清楚，简单对某个接口、子系统进行压测，并不能够准确探测出系统整体的容量水位，这是由分布式系统与生俱来的复杂性决定的，并且对环境、目标都有着极为严苛的要求。近些年，全链路压测似乎备受追捧，基本上各大互联网企业，比如，阿里、京东等都会在大促前夕利用自研的“军演系统”在线上进行压测实战演练，其目的就是确保大促来临时核心链路的整体稳定。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>像天猫这种级别的大型电商网站，主要的技术挑战是来自庞大的用户规模所带来的大流量、高并发，以及海量数据，在“双11”“双12”等大促场景下尤为明显。如果不对流量进行合理管制，肆意放任大流量冲击系统，那么将会导致一系列的问题出现，比如一些可用的连接资源被耗尽、分布式缓存的容量被撑爆、数据库吞吐量降低，最终必然会导致系统产生雪崩效应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>热点数据的大并发读/写操作，可谓是秒杀、限时抢购等场景下最核心的2个技术难题。针对热点数据的大并发读操作，尽管我们可以通过分布式缓存来提升系统的QPS，但是缓存系统的单点容量还是存在上限的，一旦超过临界水位，分布式缓存容易被瞬间击穿。而热点数据的大并发写操作，势必会下潜至数据库，那么这就会引起大量的线程相互竞争InnoDB的行锁，并发越大时，等待的线程就越多，这会严重影响数据库的TPS，导致RT线性上升，最终导致系统发生雪崩。</p>
</blockquote>
</blockquote>
<h2 id="◆-第1章-大系统小做——大规模服务化架构" tabindex="-1"><a class="header-anchor" href="#◆-第1章-大系统小做——大规模服务化架构" aria-hidden="true">#</a> ◆ 第1章 大系统小做——大规模服务化架构</h2>
<blockquote>
<blockquote>
<p>互联网场景下应对大流量、高并发，以及海量数据，服务化改造似乎是必经之路，</p>
</blockquote>
</blockquote>
<h3 id="◆-1-1-分布式系统的架构演变过程" tabindex="-1"><a class="header-anchor" href="#◆-1-1-分布式系统的架构演变过程" aria-hidden="true">#</a> ◆ 1.1 分布式系统的架构演变过程</h3>
<blockquote>
<blockquote>
<p>通常来说，网站由小变大的过程，几乎都需要经历单机架构、集群架构、分布式架构、分布式多活数据中心架构。伴随着业务系统架构一同演变的还有各种外围系统和存储系统，比如关系数据库的分库分表改造、从本地缓存过渡到分布式缓存等。当系统架构演变到一定阶段且逐渐趋向于稳定和成熟后，架构师们需要对技术细节追本溯源，如果现有的技术或者框架不能有效满足业务需要，就需要从“拿来主义”的消费者角色转变为自行研发的生产者角色。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>单机架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于一个刚上线的项目，我们往往会将WebServer、文件服务器和数据库全都部署在同一台物理服务器上，并将所有的业务逻辑全都耦合在同一个单体应用中，这样做的好处只有一个——省钱</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一旦业务开始加速发展，用户逐渐增多，系统瓶颈便会开始暴露，这时架构师们就可以考虑对现有网站架构做出以下四点调整：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 独立部署，避免不同的系统相互之间争夺共享资源（比如CPU、内存、磁盘等）；● WebServer集群，提高容错性；● 部署分布式缓存系统，使查询操作尽可能在缓存命中；● 数据库实施读/写分离改造，实现HA（High Availability，高可用性）架构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群（Cluster）技术可以将多台独立的服务器通过网络相互连接组合起来，形成一个有效的整体对外提供服务，使用集群的意义就在于其目标收益远高于所付出的实际成本和代价。互联网领域存在一个共识，那就是当一台服务器的处理能力接近或已超出其容量上限时，不要企图更换一台性能更强劲的服务器，通常的做法是采用集群技术，通过增加新的服务器来分散并发访问流量，1台不够就扩到2台，2台不够就扩到4台，只要业务系统能够随意支持服务器的横向扩容，那么从理论上来说就应该无惧任何挑战，从而实现可伸缩性和高可用架构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于无状态的WebServer节点来说，通常我们会使用Nginx来实现负载均衡调度，但是在线上环境中，Nginx也应该具备高可用性，这可以依靠DNS轮询来实现，或者如果你所在企业使用的是云主机，则可以使用云服务商提供的SLB服务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在集群环境中，WebServer节点的数量越多，并行处理能力和容错性就越强，哪怕其中某些节点因为种种原因宕机，也不会导致系统不可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>伴随着WebServer集群改造的还有分布式缓存和数据库，对于查询操作我们应当尽可能在缓存中命中，从而降低数据库的负载压力。尽管缓存技术可以分担数据库的大部分查询压力，但是写入操作和无法在缓存命中的数据仍然需要频繁地对数据库进行读/写操作，因此对数据库实施读/写分离改造也迫在眉睫。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>业务发展到一定阶段后必然会变得更加复杂，用户规模也会线性上升，这时架构师就可以考虑对现有网站架构做出以下两点调整：● 利用CDN加速系统响应；● 业务垂直化，降低耦合，从而实现分而治之的管理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于中国的网络环境相对比较复杂，跨网络、跨地域的用户访问网站时，速度有较大差别，因此，当用户流量增大之后，我们需要考虑将系统中的一些静态资源数据（如图片、音频、视频、脚本文件及HTML网页等）缓存在CDN节点上，因为CDN正在变得越来越廉价</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于用户的请求并不会直接落到企业的数据中心，而是请求到离用户最近的ISP（Internet Service Provider，互联网服务提供商）上，因此可以大幅提升系统整体的响应速度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>垂直拆分业务子系统</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这个阶段主要需要解决的问题就是降低业务耦合，实现高内聚低耦合，提升系统容错性，避免牵一发而动全身的风险。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在一次限时抢购活动中，我们预计零点开抢时的那一拨峰值流量肯定会远高于平时，因此在几天前运维部门的同学就提前扩容了上百台服务器来应对“双11”。在活动开始前，大家摩拳擦掌，屏住呼吸紧盯着电脑屏幕“观赏”流量监控曲线图时，“悲剧”发生了，随着倒数结束，活动正式开始，流量曲线居然没有太大的起伏，这让当时在场的小伙伴们瞬间懵掉了，紧急排查故障后发现，前端App在每一次业务请求提交之前都会先将客户端埋点数据上报到专门用于数据采集的WebServer上（后期需要利用大数据平台对埋点数据进行一些用户行为的实时/离线分析），然后再请求到业务系统上执行逻辑处理。但因为我们的疏忽，负责数据采集的WebServer和核心业务系统使用的是同一个Nginx服务器进行请求转发，由于没有对数据采集的机器做扩容，导致Nginx日志中出现大量的请求超时异常，从而严重影响了核心业务的正常运转。据不完全统计，这次活动至少导致了2/3的用户无法正常访问，而那些“侥幸”正常访问并下单的用户，也因为在指定时间内无法顺利完成支付而导致大量的订单回流。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一定要具备大系统小做的意识，所谓拆系统其实指的就是业务垂直化，简而言之，架构师可以根据系统业务功能的不同拆分出多个业务模块（一般大型电商网站都会拆分出首页、用户、搜索、广告、购物、订单、商品、收益结算等子系统），再由不同的业务团队负责承建，分而治之，独立部署</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为什么要实现服务化架构呢</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>随着用户规模逐渐庞大，需求更加复杂，我们一定会对耦合在一个Web容器中的单体应用进行垂直化改造，以业务功能为维度拆分出多个子系统，这样做就是为了能够更清晰地规划和体现出每个子系统的职责，降低业务耦合，以及提升容错性。但是在多元化的业务需求下，子系统中一定会存在较多的共享业务，这些共享业务肯定会被重复建设，产生较多的冗余业务代码。而且，业务系统中数据库连接之类的底层资源必然会限制业务系统所允许横扩的节点数量，因为在横扩过程中，连接数是机器数的平方。除了共享业务重复建设和资源连接受限，还有一个不容忽视的问题，当业务做大时，技术团队的人员规模也开始膨胀，太多人共同维护一个系统肯定会坏事，尤其是那些“手潮”的同学，经常会导致版本冲突。因此为了避免这些问题，服务化架构（Service-Oriented Architecture，SOA）改造刻不容缓</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-6 服务化架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务化与微服务架构的区别</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实施服务化改造后，原本耦合在WebServer中的业务逻辑被剥离，因此这些子系统从某种意义上来说仅仅只是充当着控制层（Controller）的角色，由于无须处理任何复杂的业务逻辑，因此吞吐量相对会有所提升，但是业务的逻辑处理由独立部署的服务负责，所以架构师需要认真思考如何有效提升整体的服务质量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓的微服务架构，从宏观上来看，无非就是细化了服务拆分过程中的粒度，粒度越细，业务耦合越小，容错性就越好，并且后期扩展也会越容易。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>那么服务到底应该如何拆分才称得上“微服务”呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以子系统为维度来进行拆分，这样的拆分粒度适中，所付出的成本与实际收益会相对等价，否则粒度过细不仅会提升维护成本，还会影响排查问题时的效率，更重要的是，业务开发同学很难梳理清楚服务之间的依赖关系。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群与分布式的区别</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>集群是指将多台服务器集中在一起，目的是实现同一业务；而分布式是指将不同的业务分布在不同的地方，目的是实现不同的业务；前者是串联工作，而后者是并联工作。在此大家需要注意，分布式架构中的每一个子节点都允许构成一个集群，但集群却并不一定就是分布式的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>再举一个贴近生活的例子。假设你厨艺高超，声名远播，周末盛情邀约了几个小伙伴来你家聚餐，你一个人负责买菜、切菜、炒菜、上菜，这便是单机架构；而某一天更多朋友来你家做客时，你发现似乎有些力不从心，这时你需要几个人一起来协作帮忙，以便提升效率，这就是集群架构；假设你家大业大，有上百位朋友都相约你家吃饭时，你会需要更多的人来协作帮忙，并且相互之间需要明确职责分工，A组负责买菜，B组负责洗菜，C组负责炒菜，D组负责上菜，这就是分布式+集群架构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>前后端分离架构演进</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我们的业务现状包含H5、APP，PC-WEB 3个端。根据端的不同请求会落到不同的域名上，再由对应的接入层来负责请求的接入，WebServer充当了聚合层，负责调用下游服务执行具体的业务逻辑处理后响应请求结果，同时还耦合有前端代码。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-7 未前后端分离的整体架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 下游RPC接口发生变化时，上游依赖这个接口的各个端的WebServer都需要修改代码；● 各个端的WebServer中存在大量的代码冗余；● 前后端职责模糊，前端需要关心后端语法，后端需要维护模板代码；● 前后端联调成本高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其实各个端WebServer中的逻辑大致都是相似的，只存在极少数的不同（比如：数据的返回格式存在区别、入参存在区别、展示交互存在区别，以及调用下游服务的数量存在区别等），因此我们开始尝试使用Node.js技术实施前后端分离改造来解决上述提出的诸多痛点</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-8 前后端分离改造后整体架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先需要改造的是WebServer的拆分问题，不再继续以域名为维度进行拆分，而是以子系统维度来进行拆分，这样便可以有效解决大量代码拷贝和冗余等问题，最终只需保留一套代码即可。然后将耦合在WebServer中的前端模板代码前移至Node.js中，由Node.js充当中间层来负责具体的服务端渲染和数据二次加工等任务，这样不仅减少了耦合，同时还降低了前后端联调成本（前端开发人员与后端开发人员约定好数据的返回格式后，不再需要等待后端一起联调，可以自行调用Mock服务来进行验证），以及维护成本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>API网关服务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果没有Spring Cloud的出现，可能大部分互联网企业至今都只能够选择基于Dubbo来落地服务化架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>API网关已经成为微服务架构体系中的标准，简单来说，网关层作为整个系统的入口，所有的前端请求都需要通过它来访问后端服务，并由它统一负责处理一些公共逻辑，比如：鉴权、流控、日志记录、安全防护、负载均衡、灰度发布等。如果是基于Spring Cloud的，那么开箱即用的Zuul组件则用于支持开发人员快速构建一个健壮的、高性能的，且具备良好伸缩性的API网关服务。遗憾的是，由于存在架构上的差异，Dubbo目前并没有为开发人员提供成熟、易用的网关服务，因此我们通常会在服务上游构建一层WebServer用以满足如下3个需求：● 将外部的HTTP协议适配为内部的二进制协议；● 聚合操作；● 集成一些公共逻辑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大家思考一个问题，在不引入API网关的情况下，WebServer其实也能够实现API网关能做的所有事情，那么我们为何还需要大费周章地引入网关层呢？事实上，是否需要引入网关层是由业务复杂度来决定的，如果业务不多，且相对简单的情况下，那么网关层就不是刚需，但如果业务众多和复杂，在没有引入网关层的情况下，那些耦合在WebServer中的公共逻辑的维护成本就会变得非常高，甚至一个小功能的升级，都将耗费大量的时间和人力成本，但如果引入了API网关，事情就会变得简单起来，因为网关逻辑和业务逻辑是完全独立的，架构团队只需要统一对网关层进行升级即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者所在企业也是使用Dubbo来落地服务化架构的，业务初期我们也并未引入API网关，由WebServer来负责处理网关业务，但随着业务发展到一定阶段后，WebServer变得越来越重，架构团队不得不考虑引入网关层来解决现有痛点。我们最早的解决方案是将接入层Nginx改造为网关层，但发现Lua脚本的维护成本实和实现难度较大，因此，后续我们选择了将一些流控、灰度发布、安全防护，以及日志记录等一些相对简单的网关逻辑放在接入层，尽可能将流量挡在系统上游，而对于一些复杂的网关逻辑，则单独引入了一层API网关，替换掉原本的WebServer，将聚合操作下潜至服务层，API网关通过优化后的泛化调用方式调用下游目标服务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-9 API网关层架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>灰度发布，简单来说，就是通过一系列的规则和策略，先将一小部分的用户作为“金丝雀”，让其请求路由到新版本应用上进行观察，待运行正常后，再逐步导流更多的用户到灰度环境中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果初期灰度环境的机器数量不多，为了避免系统容量被持续递增的用户流量撑爆而产生宕机，我们还需要实时扩容灰度环境的机器数量，以便支撑更多用户的访问。当所有的用户都顺利切换到新版本应用上后，再停机之前的老版本应用，即可完成灰度发布。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>就算灰度期新版本应用存在问题，我们也能够迅速将流量切换回老版本上。其实，实施灰度发布的目的就在于试错，尽可能控制和缩小问题的影响范围。从产品的角度来看，灰度发布的好处是，能够通过收集用户的使用反馈来更好地完善和改进当前产品。然而从研发的角度来看，从预发布环境到灰度环境，都是在不停地试错，以确保最终上线的稳定，哪怕灰度期出现问题，也能够做到快速止损，缩小问题的影响范围，从而保证绝大多数用户可用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>API网关作为整个系统的入口，那么在API网关中嵌入灰度逻辑就显得顺理成章，并且对于业务系统而言也不存在任何侵入性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>API网关物理上虽然是由Nginx和独立的Gateway服务构成的，但其逻辑上仍然是作为同一个整体对外提供服务，对于灰度发布这种相对简单的网关逻辑，我们选择了在Nginx中嵌入Lua脚本来实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>嵌入在Nginx中的Lua脚本会首先从Header中获取出Token并解析出用户的UserId，再请求Redis验证当前的UserId是否包含在白名单中，只有那些包含在白名单中的用户，才允许访问灰度环境中的新版本应用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-10 基于API网关实现灰度发布</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于网关的技术选型，目前市面上开源的网关实现方案有很多选择，比如基于Nginx的KONG、API Umbrella，基于Node.js的apigee、StrongLoop等</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式多活数据中心架构演进</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>出于对灾备、高可用等方面的考虑，稍微有点实力的企业都会选择构建多个数据中心，由主数据中心负责核心业务的正常运转，其他数据中心负责数据备份，及承担一些边缘业务。假设主数据中心发生重大灾难，灾备数据中心可以有效接管，从而减少对用户的影响。传统企业，比如电信、银行一类，大多会构建“两地三中心”架构，即：生产数据中心、同城灾备中心，以及异地灾备中心</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-11 “两地三中心”架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“两地三中心”架构尽管具备较好的容灾和容错性，但存在一个弊端，那就是会产生大量的资源浪费。因为多数据中心之间仅仅只是主/备关系，只有当灾难真正不幸降临时，灾备数据中心才能派上用场和体现出它的价值，平时几乎都是闲置状态，这对于那些资金紧张或是互联网企业来说，几乎是难以接受的，前者出于资金压力，而后者却因为需要面对高并发、大流量，以及海量的数据的洗礼，需要充分地利用资源，所以空闲出这么多机器绝对是不能忍受的。目前越来越多的企业，正在逐步从原有的灾备模式开始过渡到“分布式多活数据中心（DistributedActive/Active Data Centers）”的建设上</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-12 “分布式多活”架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式多活数据中心</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实际上就是将2个或者2个以上的数据中心同时并行对外提供服务，实现了对资源的充分利用，避免了资源利用率低下等诸多问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>主要需要面对如下3个难题：● 多数据中心之间需要打通内网专线通道；● RPC调用需要做到就近调用；● 数据同步问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者所在企业的2个数据中心分布情况还是比较复杂的，一个在华东，一个在华南，首先需要打通内网专线通道，提高网络传输速度尽可能降低延迟，正常情况下，运维同学给出的理论延迟率可以控制在20ms内。存储层的数据同步既是核心同时也是难点，因为数据的实时性、一致性、冲突等问题在某些特定场景下是存在矛盾且无解的，所以分布式多活的建设需要根据实际的业务场景而定，业界几乎并没有完美的异地多活方案，也并非所有的业务都能够实现分布式多活，但我们可以采取多种有效的手段，尽可能保证绝大部分核心业务能够实现分布式多活。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-服务治理需求" tabindex="-1"><a class="header-anchor" href="#◆-1-2-服务治理需求" aria-hidden="true">#</a> ◆ 1.2 服务治理需求</h3>
<blockquote>
<blockquote>
<p>服务化与RPC协议</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务化其实只是一个抽象概念，而RPC协议才是用于实现服务调用的关键。RPC由客户端（服务调用方）和服务端（服务提供方）两部分构成，和在同一个进程空间内执行本地方法调用相比，RPC的实现细节会相对复杂不少。简单来说，服务提供方所提供的方法需要由服务调用方以网络的形式进行远程调用，因此这个过程也称为RPC请求，服务提供方根据服务调用方提供的参数执行指定的服务方法，执行完成后再将执行结果响应给服务调用方，这样一次RPC调用就完成了</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-13 RPC的请求调用过程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务化框架的核心就是RPC，目前市面上成熟的RPC实现方案有很多，比如JavaRMI、Web Service、Hessian及Finagle等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不同的RPC实现对序列化和反序列化的处理也不尽相同，比如将对象序列化成XML/JSON等文本格式尽管具备良好的可读性、扩展性和通用性，但却过于笨重，不仅报文体积大，解析过程也较为缓慢，因此在一些特别注重性能的场景下，采用二进制协议更合适。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实现服务调用无非就是跨进程通信而已，那是否可以使用Socket技术自行实现呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>梳理一下完成一次RPC调用主要需要经历的三个步骤：● 底层的网络通信协议处理；● 解决寻址问题；● 请求/响应过程中参数的序列化和反序列化工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RPC的本质就是屏蔽上述复杂的底层处理细节，让服务提供方和服务调用方都能够以一种极其简单的方式（甚至简单到就像是在实现一个本地方法和调用一个本地方法一样）来实现服务的发布和调用，使开发人员只需要关注自身的业务逻辑即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于服务治理框架Dubbo实现服务化</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者在生产环境使用的服务治理框架基于的就是Apache开源的Dubbo。之所以选择Dubbo，主要因为其设计精良、使用简单、性能高效，以及技术文档丰富等特点。并且Dubbo还预留了足够多的接口，以便让开发人员能够以一种非常简单的方式对其进行功能扩展，更好地满足和适配自身业务，所以Dubbo在开源社区拥有众多的技术拥护者和推进者。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Dubbo为开发人员提供了一套完善的监控中心，使我们能够非常清楚地知道指定服务的状态信息（如服务调用成功次数、服务调用失败次数、平均响应时间等）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>警惕因超时和重试引起的系统雪崩</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当企业的系统架构逐步演变到服务化阶段时，架构师重点需要考虑的问题是服务如何拆分、粒度如何把控，以及服务之间的RPC调用应该如何实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务治理所涉及的范围较广，包括但不限于：服务注册/发现、服务限流、服务熔断、负载均衡、服务路由、配置管理、服务监控等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>服务治理的主要作用是改变运行时服务的行为和选址逻辑，达到限流，权重配置等目的，当然，采取什么样的治理策略还需要依赖监控数据来进行全方位的分析和指导。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以服务的动态注册/发现为例，当服务变得越来越多时，如果把服务的调用地址（URL）配置在服务调用方，那么URL的配置管理将变得非常麻烦</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>因此引入注册中心的目的就是实现服务的动态注册和发现，让服务的位置更加透明，这样服务调用方将得到解脱，并且在客户端实现负载均衡和Failover将会大大降低对硬件负载均衡器的依赖，从而减少企业的支出成本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-17 不依赖于注册/发现</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-18 服务端服务发现模式</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>客户端服务发现模式（Client-side Service Discovery Pattern）相信大家都非常熟悉了，Dubbo整体架构其实也基于的是此模式。基础的服务注册步骤和服务端模式是一致的，只是将服务发现交给了Consumer来负责实现，无须再引入代理中心，由Consumer根据指定的负载均衡算法从地址列表中选择一个可用的服务节点进行RPC调用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式场景下，依赖的外围系统越多，系统存在宕机的风险就越大。在服务端服务发现模式下，我们需要额外引入代理中心来负责服务发现和请求的负载均衡等任务，这就意味着代理中心必须具备容错性和伸缩性；而且，从性能表现来看，客户端模式整体的吞吐量也会优于服务端模式，毕竟在服务端模式下需多增加一层网络开销，不如客户端模式来得直接。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>部署监控中心是为了更好地掌握服务当前的状态信息，因为有了这些指标数据后我们才能够清楚目标服务的负载压力，以便迅速做出调整，采用合理的治理策略。比如在大促场景下，为了让系统的负载处于比较均衡的水位，不会因为峰值流量过大，导致系统产生雪崩而宕机，我们往往都会选择“断臂求生”，采用流控、熔断，或服务降级等治理策略对外提供有损服务，尽可能保证交易系统的稳定和大多数用户能用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>关于服务化后的分布式事务问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实施服务化改造后事务的问题应该如何解决？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其实分布式事务一直就是业界没有彻底解决的一个技术难题，没有通用的解决方案，没有高效的实现手段，但是这并不能成为我们不去解决的借口。既然分布式事务实施起来非常困难，那么我们为什么不换个思路，使用其他更优秀的替代方案呢？只要能够保证最终一致性，哪怕数据会出现短暂不一致窗口期又有什么关系？在架构的演变过程中，哪个是主要矛盾就优先解决哪一个，就像我们对JVM进行性能调优一样，吞吐量和低延迟这两个目标本身就是相互矛盾的，如果吞吐量优先，那么GC就必然需要花费更长的暂停时间来执行内存回收；反之，频繁地执行内存回收，又会导致程序吞吐量的下降，因此大家要学会权衡和折中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>注册中心性能瓶颈方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>随着服务拆分的粒度越来越细，服务及服务实例越来越多，整个服务治理体系中注册中心的性能瓶颈会逐渐开始暴露出来，这几乎是任何一家大中型规模的电商企业都会经历和面对的问题。笔者所在企业目前线上环境常态下的服务数量都保持在1W+左右，更不用说大促扩容后的服务数量，由于我们之前使用的注册中心是ZooKeeper，所以面临着如下2个棘手的问题：● 服务扩容时，应用启动异常缓慢；● 冗余的服务配置项会增加存储压力和扩大网络开销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ZooKeeper真的不太适合作为大规模服务化场景下的注册中心，因为它是一个典型的CP系统，是基于ZAB（Zookeeper Atomic Broadcast，原子广播）协议的强一致性中间件，它的写操作存在单点问题，无法通过水平扩容来解决。当客户端发送写请求时，集群中的其他节点会优先转发给Leader节点，由Leader节点来负责具体的写入操作，只有当集群中&amp;gt；=N/2+1个节点都同步成功后，一次写操作才算完成。当服务扩容时，TPS越高，服务注册时的写入效率就越低，这会导致上游产生大量的请求排队，表象就是服务启动变得异常缓慢。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Dubbo服务启动时向注册中心写入的配置项有近30多个，但是其中大部分配置项都不需要传递给消费者，或者说消费者并不需要这些配置项（比如：interface、method、owner等），消费者完全可以通过接口API在生成Proxy时获取到必要的关键信息，那么在服务大规模扩容时，冗余的配置项会导致数据量的急剧膨胀，增加ZooKeeper集群的存储压力，甚至直接导致内存溢出。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大促结束后，运维同学需要释放掉过剩的服务资源，减少不必要的资源开销，在不考虑服务优雅下线的情况下，通常采用的做法是简单粗暴的“kill-9”操作，但这会导致消费者无法及时更新本地的服务地址列表，在某个单位时间内仍然路由到失效节点上，导致大量的调用超时异常，因此我们的架构团队扩展了Dubbo的优雅下线功能（Dubbo2.5.3版本的优雅停机存在Bug）。简单来说，对那些需要下线的服务，会优先从注册中心内摘除它们注册时写入的相关信息，然后等服务处理完当前任务后再结束其进程。尽管设计上是合理的，但需要释放的服务数量之多，服务节点的任何变化，都会导致消费者每次都全量拉取一个服务接口下的所有服务地址列表信息，笔者线上注册中心的内网带宽是1.5Gbit/s，消费者拉取带来的瞬时流量瞬间就会将ZooKeeper集群的网卡打满，导致大量的消费者没有及时拉取到变化后的服务地址列表而继续路由到失效节点上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图1-20 注册中心的3个改造阶段</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式多活架构下的服务就近调用方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>理论上，尽管多数据中心之间通过内网专线通道可以将网络传输的延迟率控制在几十ms内，但在一些特殊情况下，比如大促带来的峰值流量极有可能瞬间就将延迟率放大数倍，导致大量的服务调用产生超时，因此企业在实施分布式多活架构后，服务调用应该优先在同机房内进行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>并非所有业务都能够实现分布式多活，只能够通过多种有效手段来保证绝大多数的核心业务实现多活架构，因此部分未实现多活的服务才需要进行跨机房调用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实际上，这是一个优先级路由的问题，目前笔者所在企业采用的方案是扩展Dubbo的路由功能，加入路由分级策略实现服务的就近调用。简单来说，当Provider注册时，会将当前所在机房的标识信息一同写进注册中心；这样一来，当Consumer进行调用时，便有迹可循，通过检测机房的标识信息来判断路由走向。</p>
</blockquote>
</blockquote>
<h2 id="◆-第3章-削峰填谷——流控方案" tabindex="-1"><a class="header-anchor" href="#◆-第3章-削峰填谷——流控方案" aria-hidden="true">#</a> ◆ 第3章 削峰填谷——流控方案</h2>
<blockquote>
<blockquote>
<p>像天猫这种级别的大型电商网站，主要的技术挑战是来自庞大的用户规模所带来的大流量、高并发，以及海量数据，在“双11”“双12”等大促场景下尤为明显。如果不对流量进行合理管制，肆意放任大流量冲击系统，那么将会导致一系列的问题出现，比如一些可用的连接资源被耗尽、分布式缓存的容量被撑爆、数据库吞吐量降低，最终必然会导致系统产生雪崩效应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大型电商网站的制胜法宝无非就是通过扩容、静态化、限流、缓存，以及队列5种常规手段来保护系统的稳定运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>马</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本章的重点是流量管制，只要我们能够采用合理且有效的方式管制住峰值流量，使其井然有序地对系统进行访问，那么无论任何情况下，系统都能够稳定运行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>流量管制的目的是保护系统，让系统的负载压力处于一个比较均衡的水位，而不是刻意为了限流而限流，否则将会严重影响用户体验，得不偿失。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-为什么需要限流" tabindex="-1"><a class="header-anchor" href="#◆-3-1-为什么需要限流" aria-hidden="true">#</a> ◆ 3.1 为什么需要限流</h3>
<blockquote>
<blockquote>
<p>3.1 为什么需要限流</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于单台服务器的处理能力极其有限，因此当一台服务器的处理能力接近或已超出其容量上限时，采用集群技术对服务器进行扩容，可以很好地提升系统整体的并行处理能力，在集群环境中，节点的数量越多，系统的并行处理能力和容错性就越强。静态化其实是一个老生常谈的话题，简而言之，系统需要将动态数据和静态数据分而治之，用户对静态数据的访问，应该避免请求直接落到企业的数据中心，而是应该在CDN中获取，以加速系统的响应速度。和现实生活中流量管制的场景类似，当网站举行大促活动时，那些单价比平时更给力、更具吸引力的热卖商品一定会吸引大量的用户前来购买，访问骤增的同时会带来读/写流量的骤增，因此需要采用合理且有效的限流手段对系统做好保护，毕竟不是任何场景都可以仅通过缓存和服务降级等技术手段就能够实现一本万利的，如系统中的写服务（用户下单、库存扣减、商品评论等）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大促场景下热点数据的读操作一直就是最核心的技术难题之一，通过缓存技术，系统在应对高并发、大流量时可谓如虎添翼，因为缓存的读/写效率要远胜于任何关系数据库，合理地使用缓存技术，系统的吞吐量将会得到质的提升。当触发流量高峰时，系统上下游对请求的处理表现必然不尽相同，对于那些无状态的上游系统来说，大促开始前运维同学根据需要进行相应的扩容调整就可以很好地提升其并行处理能力，但下游的存储系统因为扩/缩容成本相对比较昂贵，不可能和上游系统保持同等规模的节点数量，因此当系统上下游处理能力存在差距，且对于那些不需要进行实时处理的请求来说，可以通过队列转储系统上下游的消息内容形成漏斗，待下游有足够的处理能力时再进行处理，以降低存储系统的负载压力，避免上下游逐层影响而产生雪崩效应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任何一个分布式系统的容量都会存在上限，哪怕天猫这种级别的网站也不例外。一旦用户流量过载，系统的吞吐量便会逐渐开始下降，RT线性上升，最终导致系统容量被撑爆而产生宕机。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>架构师在对系统架构进行设计时，一定要考虑到系统整个链路中的各个环节，就像笔者所示应对高并发、大流量的5种常规手段一样，这些看似平淡无奇甚至“毫无新意”的技术，组合在一起时却能爆发出惊人的力量。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分享笔者亲身经历过的一次过度设计案例</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一般而言，商品的下单流程大致需要经历：生成订单号→库存扣减→生成订单→用户付款4个主要步骤。在大部分情况下，下单流程一般都会被设计成同步模式来确保其正确性，在某次限时抢购活动中，为了实现削峰处理，负责此次活动的开发人员却奇思妙想地将下单流程设计成了“伪异步”模式，即成功扣减库存后，通知MQ，由消费者成功消费后再负责向订单库写入订单数据生成订单，但写入MQ操作后并没有立即返回，而是一直卡在下单接口中轮训订单的生成状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这里引入MQ完全就是多余的，虽然采用了异步下单，但业务上仍然保持着同步模式。试想一下，由于接入层的线程数和峰值订单的处理速度是有限的，当并发过大时，大量的请求都会产生阻塞，新的请求由于无法被及时处理，必然会产生大量的超时异常，严重影响用户体验。如果业务上真的需要将下单流程设计为异步模式，那么在写入MQ后就应该做到立即返回，而不是选择将工作线程“hang”住，当然，笔者其实更建议大家采用同步模式，直接在接入层限流更为简单和可靠。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在高并发、大流量场景下合理地运用扩容、静态化、限流、缓存，以及队列5种常规手段，可以使用户流量保持在系统可处理的容量范围之内。[插图]图3-1 漏斗模型</p>
</blockquote>
</blockquote>
<h3 id="◆-3-2-限流方案" tabindex="-1"><a class="header-anchor" href="#◆-3-2-限流方案" aria-hidden="true">#</a> ◆ 3.2 限流方案</h3>
<blockquote>
<blockquote>
<p>3.2 限流方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>常见的限流算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实际的开发过程中，基本上每个开发人员都直接或间接地与限流算法打过交道，比如池化资源技术（数据库连接池、线程池、对象池等）除可以用于资源复用外，同时也具备限流功能。以数据库连接池为例，我们都知道数据库连接是一种非常昂贵且数量有限的底层资源，为了避免并发环境下连接数超过数据库所能够承载的最大上限，合理地运用连接池技术，可以有效限制单个进程内能够申请到的最大连接数，确保在并发环境下连接数不会超过资源阈值。池化资源技术的限流其实就是通过计数器算法来控制全局的总并发数，在生产环境中，笔者使用的也正是这种简单有效的限流算法来实现接入层，以及部分服务层的限流任务。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>介绍目前市面上常见的3种限流算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1.令牌桶算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>令牌桶（Token Bucket）算法主要用于限制流量的平均流入速率，并且还允许出现一定程度上的突发流量</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于令牌桶算法的限流场景较多，比如Nginx的限流模块就是一个典型的采用令牌桶算法的实现。基本流程如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 每秒会有r 个令牌被放入桶内，也就是说，会以1/r 秒的平均速率向桶中依次放入令牌（比如每秒共放入10个令牌，那么每0.1秒放入1个令牌）；</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 桶的容量固定不变，假设桶中最多只允许存放b个令牌，桶满则溢出；● 当一个n字节的请求包到达时，将消耗n个令牌，然后再发送该数据包；</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 若桶中的可用令牌数小于n，则该数据包将被执行限流处理（被抛弃或缓存）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-2 令牌桶算法流程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2.漏桶算法漏桶算法（Leaky Bucket）也可以高效地实现流量管制。基本流程如下所示：● 可以以任意速率向桶中流入水滴；● 桶的容量是固定不变的，如果桶满了则溢出（新流入的水滴被丢弃）；● 按照固定的速率从桶中流出水滴。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从本质上来说，令牌桶算法和漏桶算法都可以用于在高并发、大流量场景下对流量实施管制，让系统的负载处于比较均衡的水位，不会因为峰值流量过大而导致系统被击垮。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这两种算法的限流方向是截然相反的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>令牌桶算法限制的是流量的平均流入速率，并且可以允许出现一定程度上的突发流量，当桶中令牌数量不足扣减时，新的请求将被执行限流处理；而漏桶算法限制的是流量的流出速率，而不是流入速率，并且这种流出速率还是保持固定不变的，不允许像令牌桶算法那样出现突发流量，当流入的水滴超过桶的容量时，新的请求将被执行限流处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-3 漏桶算法流程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.计数器算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在单位时间内，会由一个计数器专门负责计数，不停地与阈值进行比较，当等于阈值时，便触发限流逻辑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>计数器算法主要用于限制单位时间内的总并发数。假设限流阈值被设定为1000次/秒，每请求一次，计数器递增一次，单位时间内计数值与限流阈值相等时，则意味着后续请求将被执行限流处理，只有达到时间临界点后，才会对计数器进行重置，新的请求才可以继续访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.2.2 基于Guava实现平均速率限流</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Guava是Google提供的对Java API进行上层封装的开源工具包，在开发过程中使用Guava或Commons提供的类库，可以大幅度减少开发人员的编码量，使得开发人员能够更专注于自身的业务逻辑，提升开发效率。Guava最大的特点就是封装了Java API中的集合框架和Cache等特性，因此，在本地缓存领域除了可以使用EhCache外，Guava也是非常不错的选择</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Guava提供的RateLimiter抽象类能够以一种非常简单的方式帮助开发人员在代码中实现流量的平均流入速率限流。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者通过调用RateLimiter的create（doublepermitsPerSecond）方法创建了一个RateLimiter实例，参数“permitsPerSecond”设置了每秒向桶中放入5个Token。假设每次每个请求都只从桶中获取1个Token，那么大约需要2秒才可以从桶中获取10个Token，也就是说，系统每秒只允许5个并发请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了应对突发流量，RateLimiter也支持请求一次从桶中获取多个Token</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>模拟了一次突发流量的情况，当请求一次性拿完了桶中仅有的5个Token后，大约需要等待1秒，后续请求才可以继续从桶中获取出Token，因为每0.2秒放入1个Token，需要在偿还完之前因突发流量提前透支的Token数量后，才能允许请求进行消费。假设在limit.acquire（5）方法前休眠1秒，限流效果将发生变化，因为程序在休眠时，桶中已经被放入了足够数量的Token。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了标准的平均速率限流，如果希望系统在启动时的限流速率从慢速逐渐过渡到平均速率，给系统一个缓冲时间，那么RateLimiter也提供有相应的支持，只需要在create（）方法中设置缓冲时间即可，如下所示：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设请求被执行限流后，我们不希望请求一直处于等待状态获取Token，而是直接丢弃或短暂等待，那么便需要使用RateLimiter提供的tryAcquire（）方法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.2.3 接入层限流方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Nginx是一个开源的高性能HTTP服务器，同时也可以作为一个反向代理服务器，甚至还可以作为一个IMAP/POP 3/SMTP服务器。由于Nginx拥有强悍的并发处理能力，因此许多互联网企业都将Nginx部署在接入层，将其当作反向代理服务器来使用，负责请求的负载均衡和分发等工作。除此之外，Nginx自带的限流模块还能够有效帮助开发同学在接入层中限制流量的平均速率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>开启Nginx的限流功能，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Nginx的配置信息中，参数limit_req_zone用于设置每个IP地址在单位时间内所允许发起的请求数，值“rate=10r/s”表示每个IP地址每秒只允许发起10个请求。如果每秒每个IP地址发起的请求数超过10个应该怎么办呢？参数limit_req的作用类似于缓冲区，用于缓存还没有来得及进行处理的请求，值“burst=100”表示缓存的请求数为100，在缓冲区中也缓存不下时，新的请求将会被拒绝和抛弃。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分享一下笔者所在企业的接入层限流方案。由于我们在高防/Web防火墙这一层就已经部署了完善的IP地址防刷机制，并且结合实际情况来看，将流量尽可能挡在系统上游，针对URL进行限流意义会更大，所以我们最终采用了Redis+Lua的分布式限流方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-5 使用Nginx+Lua实现接入层限流</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于容错性考虑，每一个Nginx节点都会对应着一个独立的Redis节点，由Redis来负责存储与限流相关的配置信息，比如：限流名单、错误码、提示信息、限流阈值、限流开关，以及单位时间等。当请求来临时，Nginx会向Redis发起Evalsha命令执行Lua限流脚本验证目标URL在单位时间内的请求次数是否已达限流阈值，如果未达阈值，则将请求转发给下游系统，反之限流。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在上述程序示例中，首先对限流开关进行了验证，只有在开关打开的情况下才会执行限流逻辑。然后验证当前URL是否包含在限流名单中，如果不在则直接放行，反之将目标URL作为key键，通过调用Redis的INCRBY命令递增单位时间内的访问次数；当计数值为1时，则表示首次访问，需要通过命令EXPIRE对其设置过期时间（即单位时间），最后判断计数值是否大于限流阈值来决定请求走向。如果单位时间内已达限流阈值，直至key过期后才会自动重置计数值。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3.2.4 应用层限流——限时抢购限流方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以限时抢购场景为例，当用户成功下单后便需要扣减指定商品的库存数量，但是大量的并发请求针对数据库中同一行记录执行写操作必然会导致数据库出现较大的负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>针对系统瓶颈点进行优化是一方面，但只有系统上游能够配合交易系统做好限流保护，方能事半功倍。那么我们应该如何限制接口的调用频率来实现爆款商品的抢购限流呢？以笔者的早期方案为例，限制好目标SKU在单位时间内允许的抢购次数，一旦超出所设定的阈值，系统便会拒绝后续用户的抢购请求（如果希望拥有较好的用户体验，客户端可以配合实施抢购失败时的排队等待页面效果）。比如，目标SKU的限流阈值被设定为1000/s，当超出阈值后，后续请求只能是拒绝或排队，直至到了时间临界点对计数器进行重置后，之前那些被拒用户才可以继续参与抢购。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图][插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>优秀的架构从来都不是被设计出来的，而是随着业务的野蛮生长，以及用户规模的递增而逐渐演变而来的，其中自然就避免不了试错。笔者早期确实是拍脑袋以SKU作为资源来限制商品的下单频率，但随着用户规模的线性上升，继续采用这样的方式显然是不合理的，因为交易系统的总容量是有限的，而SKU的数量理论上是无限的（比如交易系统的容量上线是1000/s，有2000爆款都需要在同一时间开放给用户进行抢购，那么以SKU为资源的限流阈值应该如何设定呢），忽略交易系统所能够承受的最大负载必然会增加系统的宕机风险，所以评估交易系统的容量上限，给出合理限流阈值，限制服务接口的调用频率才是关键。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果在业务逻辑中以硬编码方式嵌入限流代码，不仅会带来侵入性问题，同时还会增加复杂度，更重要的是不具备灵活性。试想一下，处于流量高峰期，如果突然需要对某个接口追加限流，硬编码的限流方式明显是无法满足需求的，最坏的情况就是眼睁睁地看着系统被流量击穿而宕机，那么是否还有更优的解决方案呢？笔者在2017年的“双11”期间曾尝试过基于JVM-Sandbox的非侵入式运行期AOP限流方案，相对硬编码的限流方式而言，的确更加灵活，但仍然存在一个弊端，那就是维护成本较高，不太规范化，所以最终我们选择对阿里开源的Sentinel流控中间件进行了功能扩展，并作为我们整体的流控平台。简单来说，Sentinel是一个面向分布式服务架构的轻量级流控中间件，主要以流量为切入点，从流控、熔断降级、负载保护等多个维度来确保系统的稳定性，并且开发人员还可以从Sentinel控制台提供的监控大盘中观察到流量的实时走向（包括通过QPS、拒绝QPS、RT等）。当然Sentinel是低侵入性的，且以插件的形式为各类主流框架提供有适配。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-3-基于时间分片的削峰方案" tabindex="-1"><a class="header-anchor" href="#◆-3-3-基于时间分片的削峰方案" aria-hidden="true">#</a> ◆ 3.3 基于时间分片的削峰方案</h3>
<blockquote>
<blockquote>
<p>3.3 基于时间分片的削峰方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓削峰，其实指的就是对峰值流量进行分散处理，避免在同一时间段内产生较大的用户流量冲击系统，从而降低系统的负载压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如何在业务上做调整来实现流量削峰。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>活动分时段进行实现削峰</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>若某一个SKU的库存数量为5000，抢购时段被分为10次，则运营人员在每个时段放置的库存数量为500（SKU/时段），同一时段聚集的用户流量将会被有效分散，大家都不会火急火燎地在同一个时间点去抢购心仪的爆款商品，这样系统的负载压力将会大大降低。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在业务上做调整来对流量进行削峰，也能够收获非常好的限流效果，这便是站在业务的角度对系统实施保护的一个非常典型的案例。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过答题验证实现削峰</p>
</blockquote>
</blockquote>
<h3 id="◆-3-4-基于消息队列的解耦、削峰、最终一致性方案" tabindex="-1"><a class="header-anchor" href="#◆-3-4-基于消息队列的解耦、削峰、最终一致性方案" aria-hidden="true">#</a> ◆ 3.4 基于消息队列的解耦、削峰、最终一致性方案</h3>
<blockquote>
<blockquote>
<p>基于消息队列的解耦、削峰、最终一致性方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>异步调用是能够显著提升程序执行性能的技术，开发人员可以通过创建线程来实现方法的异步调用，将程序中原本的串行化执行流程变为并发/并行执行，并且在Java 7的新增语法特性中，Fork/Join框架的到来也正式让Java语言过渡到了多核并行计算时代，由于能够将一个任务量化到最小，并提供了高计算密度的并行处理能力，因此任务的执行效率将得到质的提升。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于消息队列实现解耦</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ActiveMQ、Kafka、RocketMQ、HornetQ、RabbitMQ，以及ZeroMQ等，笔者建议用户规模较小的网站使用遵循JMS（Java Message Service）规范的ActiveMQ这类轻量级产品即可（甚至也可以使用Redis提供的Publish/Subscribe模型），而像Kafka、RocketMQ这类消息中间件，天生就是为互联网场景下拥有高并发、大流量的分布式系统而设计的。因为在这种规模的消息体量上，我们重点需要考虑的是消息中间件的吞吐量、可用性及扩展性等多个方面的问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-6 通过消息中间件解耦服务调用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当系统上下游处理能力存在差距，且对于那些不需要进行实时处理的请求来说，可以通过队列转储系统上下游的消息内容形成漏斗，待下游有足够的处理能力时再进行处理，也就是通过限制消息队列的出队速率来保证流量可控，使之有条不紊地对系统进行访问操作，在最大程度上保护系统的稳定运行；其次分布式事务一直就是业界没有彻底解决的老大难问题，没有通用的解决方案，没有高效的实现手段，并且对于互联网企业来说落地成本实在太高，值得庆幸的是，通过消息队列来实现最终一致性似乎给我们带来了一道曙光，不必再被强一致性带来的性能问题所困扰，对于那些能够接受数据存在短期不一致的业务场景来说，这或许最优的解决方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>常见消息中间件的使用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>建议大家使用为互联网场景量身定制的分布式消息中间件产品来实现系统之间的解耦、异步调用及大流量削峰等操作，比如Apache开源的Kafka、RocketMQ等产品</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RocketMQ是阿里开源的一款分布式消息中间件，前身为MetaQ，但是在3.0版本之后，阿里正式将其更名为RocketMQ。在历年的“双11”大促活动中，RocketMQ都承担着阿里生产系统100%的消息流转，在核心交易链路有着稳定和出色的表现，是承载交易峰值（2016年为17万笔/秒）的核心基础产品之一。同Dubbo一样幸运，于2017年9月25日，Apache官方宣布，RocketMQ顺利毕业正式成为Apache的顶级项目，它具备以下六个特点：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 支持顺序消息；● 支持事务消息；● 支持集群与广播模式；● 亿级消息堆积能力；● 完善的分布式特性；● 支持Push与Pull两种消息订阅模式。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RocketMQ由NameServer、Broker、Producer及Consumer四部分构成，每个部分都可以采用集群部署，在最大程度上保证了消息服务整体的高可用性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当成功启动NameServer节点后，再启动多个Broker（Master）节点，如下所示：在此需要注意，如果是在同一台物理机器上部署多Master集群模式，那么必须为不同的Broker节点指定不同的端口号</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于消息队列的一些典型案例</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实际开发过程中使用消息中间件的3个主要目的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先，通过异步调用可以很好地解决分布式环境下系统之间的耦合问题，减少系统中一些非必需的依赖调用，加速系统响应，降低复杂度和维护成本，从而保证进程功能的单一性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>需要同步等待返回结果的使用RPC调用，而无须关心结果响应的异步调用，建议使用MQ；</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当系统上下游处理能力存在差距，且对于那些不需要进行实时处理的请求来说，可以通过队列转储系统上下游的消息内容形成漏斗，待下游有足够的处理能力时再进行处理，也就是通过限制消息队列的出队速率来保证流量可控，使之有条不紊地对系统进行访问操作，在最大程度上保护系统的稳定运行；对于那些能够接受数据存在短期不一致的业务场景来说，基于消息队列实现最终一致性方案来替代强一致性的分布式事务或许是最优的解决方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>就削峰案例而言，使用消息队列的目的更多是控制住并发写流量，以此降低后端存储系统的负载压力，如果并发写的流量过大，则必然会降低存储系统的吞吐量，RT线性上升，存储系统的容量容易被瞬间撑爆而引起雪崩现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>消息队列</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过限制消息队列的出队速率来保证流量可控。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>相信绝大多数的互联网电商企业都会存在这样的监控需求，比如需要监控单位时间内系统中http接口的耗时Top排行，我们往往都会选择在Webserver中实现一个特定的拦截器，记录每一次请求的开始和结束时间，然后计算出执行耗时并转储，以便后续的统计查询。为了确保准确性，监控数据往往都会全量采集上报，如果是直接写入数据库，对数据库而言那绝对是不小的压力，流量高峰期数据库的容量可能瞬间就会被撑爆，而且这也并非业务系统的主要流程，完全可以通过消息队列来实现异步解耦和削峰处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>拦截器中的逻辑非常简单，当一次请求结束后，仅仅只需负责将执行耗时的计算结果异步写入消息队列即可，对业务系统的性能影响几乎可以忽略不计，然后由Flink负责拉取消息进行流式计算，得出相关接口在单位时间内的成功/失败请求次数、平均耗时等数据，井然有序地落盘到存储系统中，最后再由监控系统从存储系统中获取结果集进行可视化展示，以便开发人员能够实时获悉异常接口，做好限流保护</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图3-10 通过消息队列实现数据的采集上报削峰</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分库分表场景下，数据最初以什么样的维度进行落盘，最后就只能通过什么样的维度进行查询。订单数据需要对此进行查询的往往同时包含卖家和买家两类用户群体，卖家需要查询哪些买家对自己店铺的商品进行了下单，而买家也需要通过订单信息完成后续的付款等操作，因此在实际的开发过程中，我们往往会将同一份订单数据同时落盘seller_id和buyer_id 2个维度，以此满足买家和卖家的查询需求。为了保证写入性能，我们往往不会采用同步双写模式，虽然这样的方式最简单，而是当某一个维度落盘成功后，异步落盘另一个维度数据，以此提升订单系统的TPS，但是尽管性能得到了保障，系统的复杂度却提升了，其中最麻烦的就是数据一致性问题应该如何保证？由于我们的交易链路业务非常复杂，落地强一致性的分布式事务来保证数据一致性非常困难，所以最终我们的架构团队选择了基于消息队列的“线上检测补偿”方案来保证t_order_seller表和t_order_buyer表的数据最终一致</p>
</blockquote>
</blockquote>
<h2 id="◆-第4章-大促抢购核心技术难题——读-写优化方案" tabindex="-1"><a class="header-anchor" href="#◆-第4章-大促抢购核心技术难题——读-写优化方案" aria-hidden="true">#</a> ◆ 第4章 大促抢购核心技术难题——读/写优化方案</h2>
<blockquote>
<blockquote>
<p>热点数据的大并发读/写操作，可谓是秒杀、限时抢购等场景下最核心的2个技术难题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>提升单机处理能力最有效的办法就是采用集群技术对服务器进行水平扩容，只要系统能够具备良好的伸缩性，那么从理论上来说，其容量便可无限延伸。在此需大家注意，大促场景下因热点数据导致的单点瓶颈已经不再是简单地通过水平扩容就能够解决的。针对热点数据的大并发读操作，尽管我们可以通过分布式缓存来提升系统的QPS，但是缓存系统的单点容量还是存在上限的，一旦超过临界水位，分布式缓存容易被瞬间击穿。而热点数据的大并发写操作，势必会下潜至数据库，那么这就会引起大量的线程相互竞争InnoDB的行锁，并发越大时，等待的线程就越多，这会严重影响数据库的TPS，导致RT线性上升，最终导致系统发生雪崩。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-缓存技术简介" tabindex="-1"><a class="header-anchor" href="#◆-4-1-缓存技术简介" aria-hidden="true">#</a> ◆ 4.1 缓存技术简介</h3>
<blockquote>
<blockquote>
<p>缓存指的是将被频繁访问的热点数据存储在距离计算最近的地方，以方便系统快速做出响应，比如静态资源数据（包括图片、音频、视频、脚本文件及HTML网页等），我们可以缓存在CDN（Content DeliveryNetwork，内容分发网络）上，由于用户的请求并不是落到企业的数据中心，而是请求到离用户最近的ISP（Internet Service Provider，互联网服务提供商）上，因此可以大幅提升系统整体的响应速度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-1 系统动静分离架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>和CDN缓存类似，反向代理服务器也可以缓存状态更新不频繁的静态资源数据。尽管反向代理服务器是部署在企业的数据中心机房内，但由于它处于Webserver的上游，用户请求无须经过Webserver就可以快速将结果返回给用户，因此也可以将静态数据缓存在反向代理服务器上，以达到加快系统响应速度的目的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于数据库的读/写效率远远比不上缓存系统，因此除可以使用CDN、反向代理等手段缓存静态资源数据外，业务系统从数据库等存储系统中获取的热点数据也可以进行缓存，当再次获取目标数据时，可以优先从缓存命中，以减轻对下游存储系统的负载压力。我们在实际开发过程中使用的缓存产品无非也就是本地缓存和分布式缓存两大类，当然无论是使用的本地缓存还是分布式缓存，其目的都是解决如下两个问题：● 降低下游存储系统的负载压力；● 提升系统的响应速度。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本地缓存</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在持久层领域</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Hibernate在上层对JDBC进行了封装，并提供HQL语句实现对数据库的CRUD操作，简化了开发人员直接使用JDBC时所带来的诸多不便，在一定程度上提升了编码效率。开发人员可以在程序中将任意的POJO对象与数据库表建立映射关系，除了常规的关联关系，还可以将对象之间的继承关系映射到数据库中。那Hibernate与Ehcache究竟存在怎样的协作关系呢？其实Hibernate中的二级缓存缺省使用的就是Ehcache，尽管大部分开发人员并没有在程序中直接使用Ehcache，但是只要你在持久层代码中用到了Hibernate，就等于已经间接地使用了Ehcache来缓存查询结果集。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>GuavaCache也是实际开发过程中大家接触和使用得非常多的一款本地缓存组件。从严格意义上来说，GuavaCache仅仅只是Guava功能的一个子集，相对于Ehcache，GuavaCache则显得更加轻量，而且笔者在生产环境中使用的也正是GuavaCache+Redis组合实现的多级缓存架构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本地缓存的优点非常明显，那就是读/写性能非常好，但它同时也存在如下两个痛点：● 占用应用系统的内存资源；● 数据一致性问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>使用本地缓存虽然能够在一定程度上降低存储系统的负载压力，提升系统整体的吞吐量，但在互联网领域，应用系统的可用内存资源本身就捉襟见肘，而本地缓存会共享JVM有限的内存资源，假设缓存数据所占用的资源比例较大，那么JVM极有可能在后续的操作中因腾不出足够多的Heap空间用于为新对象分配内存空间，从而导致程序在运行的过程中抛出java.lang.OutOfMemoryError异常，虽然本地缓存可用于提升系统的响应速度，但这却是一种空间换时间的取舍；其次，由于GC次数的增多或者暂停时间的延长，还会在一定程度上影响系统的吞吐量。除此之外，由于各个应用节点之间是无状态的，极有可能出现部分节点数据有更新，而其余节点的数据未被更新，从而导致数据存在不一致的情况发生。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于本地缓存会过多占用应用系统的内存资源，所以，在一些规模较大的应用系统中，开发人员往往更倾向于选择分布式缓存作为容器来缓存热点数据。不过Ehcache在正式发布3.x里程碑版本后，开始提供off-heap（堆外内存）特性。该特性可以有效避免缓存的热点数据占用应用系统过多的内存资源，以及降低GC次数和暂停时间，这对于Ehcache的拥护者和使用者来说确实是一件值得庆幸的事情，虽然笔者在生产环境中并没有选择Ehcache作为本地缓存方案，但也使用了off-heap技术来规避资源占用率较高和频繁GC等诸多问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除Ehcache外，笔者向大家推荐一款相对小众但性能却非常出色的内存数据库MapDB，笔者生产环境中许多场景都有用到MapDB提供的数据类型、off-heap，以及mmap等特性实现数据存储（比如：本地缓存、自研的分布式缓存等）。简单来说，MapDB是一款基于Apache2.0协议的开源Java内存数据库（新版本使用Kotlin语言实现），支持Maps、Sets、Lists、Queues等多种数据类型支持，并且还提供有ACID事务、快照、增量备份等诸多实用功能，最重要的是，性能接近于java.util集合。在实际开发过程中通过使用或扩展MapDB的功能来实现基于off-heap的数据存储，可以屏蔽诸多底层实现细节，让开发人员能够更专注于自身业务逻辑的实现。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-高性能分布式缓存redis" tabindex="-1"><a class="header-anchor" href="#◆-4-2-高性能分布式缓存redis" aria-hidden="true">#</a> ◆ 4.2 高性能分布式缓存Redis</h3>
<blockquote>
<blockquote>
<p>高性能分布式缓存Redis</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>本地缓存尽管可以提供快速的数据访问能力，但是缺点和局限性也非常明显。对于那些需要考虑数据共享，以及数据一致性的业务场景来说，本地缓存则显得有些无能为力，并且本地缓存的容量实在有限，无法实现水平扩容。因此对于那些业务发展较为迅猛的互联网电商企业来说，从单纯的本地缓存架构过渡到分布式缓存架构几乎是必然的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式缓存产品</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>开源的Redis、Memcache</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>淘宝自主研发的Tair、腾讯自主研发的CKV</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis的整体性能是非常高效的，无论是使用Redis官方提供的Benchmark工具，还是使用自行编写的测试代码对Redis进行性能测试，结果都非常令人满意。从压测结果来看，Redis单机的TPS/QPS都接近10w/s。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>早期版本，Redis官方并没有提供Cluster功能，因此如果想实现Sharding操作，则只能够自行搭建Redis集群，然后通过特定的路由算法来对数据进行读/写操作。接下来，我们首先来了解分布式场景下三种最常见的路由算法，如下所示：● Hash算法；● Consistent Hash算法，● 分槽算法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Hash算法似乎非常简单和易于理解，首先hash（routekey），再进行求余操作后即可明确目标库和目标表。但随着后续单表数据量的持续膨胀，我们往往需要再次对节点进行水平扩容，不过此时的数据迁移成本会比较高。假设从原先的32个库水平扩容到64个库后，路由目标肯定也会随之发生变化，也就是说，节点产生的任何变动，几乎都需要对所有的历史数据进行全量迁移，否则将无法命中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>相对于Hash算法而言，Consistent Hash算法尽管在实现和设计上更为复杂，但是所带来的好处却是显而易见的。简单来说，首先需要抽象出一个0～232的圆，然后hash（节点）将其映射到圆的各个位置上，接着再hash（routekey）采用顺时针方式查找圆上最近的节点即可（如果超过232仍然找不到节点，则映射到圆的第一个节点上）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-3 Consistent Hash算法</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设后续我们需要对节点进行相应的扩容调整，那么只有在圆上增加节点的地点逆时针方向的第一个节点上的相关数据会受到影响，这和Hash算法相比是存在本质区别的，至少能够确保大部分历史数据还是可以正常命中的，无须全量迁移，影响面相对较小</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-4 Consistent Hash算法扩容影响</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>尽管Consistent Hash算法能够在一定程度上降低数据的迁移成本，提升命中率，但是却仍然存在一个不容忽视的问题，那就是当圆上节点太少时，容易因为节点分布不均，从而导致数据产生倾斜</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-5 数据倾斜</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于节点分布不均，将会导致大量的数据都在node1节点上命中，如果在并发较高的情况下，node1节点极有可能会因为负载较大而产生宕机。因此为了避免数据倾斜，我们可以引入虚拟节点机制，即对同一个节点计算多次（个）Hash，使其映射到圆的各个位置上，具体做法可以通过在节点IP地址或主机名的后面增加编号来实现（比如：192.168.1.1-01，192.168.1.1-02，192.168.1.1-03，192.168.1.1-0n），这样一来，即可使数据均匀分布到各个节点上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分槽算法则是介于Hash算法与Consistent Hash算法之间，算是取得了很好的折中，相对而言，尽管牺牲了一定的灵活性，但却大大降低了数据的管理成本。因为分槽算法是以Slot为维度的，当节点伸缩需要对历史数据进行迁移时，仅仅只需要移动相关的Slot即可，无须关心具体的数据。换句话说，Slot的数量从一开始就是固定的，不会因为节点的伸缩而变化，比如某个key从一开始就被路由到固定数据区间的Solt上，那么它将永远也只能够被路由到这个Solt上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis从3.x版本开始，已经正式开始提供了基于分槽算法的Cluster模式，对于运维人员和开发人员来说，Redis集群节点的伸缩将会变得非常容易。Cluster模式下一共包含有16384个Slot，由集群节点各自负责维护一小段Slot用于存储不同区间的数据。当客户端进行数据的读/写操作时，通过阅读Jedis的源码我们不难发现，key作为路由条件会首先进行CRC16运算，然后mod 16384得出具体的Slot，最后通过映射关系再路由到目标Redis节点的Slot上</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Redis非集群的情况下，开发人员在程序中可以通过JedisPool的getResource（）方法来获取到一个Jedis实例。但在Cluster模式下，则需要通过使用JedisCluster来实现数据的读/写操作</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>述程序示例中，通过HostAndPort可以指定集群中的单个Redis节点信息。尽管我们还可以声明一个List&amp;lt；HostAndPort&amp;gt；来指定所有的Redis节点信息，但是只配置一个Redis节点信息也是可以的，因为当Jedis客户端连接上集群中的某一个Redis节点时，就意味着已经成功连接上了整个Redis集群。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-3-同一热卖商品高并发读难题" tabindex="-1"><a class="header-anchor" href="#◆-4-3-同一热卖商品高并发读难题" aria-hidden="true">#</a> ◆ 4.3 同一热卖商品高并发读难题</h3>
<blockquote>
<blockquote>
<p>4.3 同一热卖商品高并发读难题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者所在企业2018年的“双11”大促活动中的峰值流量接近75w/s</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大促开始前的2个月就已经在准备各种压测和技术预案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>毕竟当你所负责的系统能够有效应对亿级流量时，这必然会为你的职业生涯带来无以言喻的成就感和自豪感，并且这也会成为你引以为傲的宝贵经验。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以限时抢购这个业务场景为例。在程序中使用缓存技术，不仅能够提升系统整体的响应速度，还能在一定程度上有效降低关系数据库的负载压力。尽管对Redis进行Cluster后可以理论上认为容量是可以无限延伸的，并且数据的读/写操作经过了水平化处理，不同的key均会落到不同的缓存节点上，以此避免所有的用户流量都集中落到同一个缓存节点上。但是对于限时抢购场景下的热卖商品来说，由于单价比平时更给力、更具吸引力，那么自然会比平时吸引更大的流量进来，这时同一个key必然会落到同一个缓存节点上，因此分布式缓存在这种情况下一定会出现单点瓶颈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>例子，某明星出轨的消息很容易引爆流量，有可能随着事件的发酵会在接下来的一周内稳坐各大新闻版面头条。单从技术细节上来分析，假设这条消息存储在分布式缓存中，但由于消息是缓存在固定的Slot上的，尽管缓存系统单点支撑10w/s的QPS没有任何压力，但是在短短几分钟内，光是用户留言就达到了上百万条，更别说是阅读这条消息时所产生的流量，因此分布式缓存的单点容量容易瞬间被撑爆，导致资源连接耗尽。为了解决分布式缓存存在的单点瓶颈，本书提供如下两种配套解决方案：● 多级缓存方案；● RedisCluster模式一主多从读/写分离方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>多级缓存方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>结合二八定律来看，限时抢购场景下的读操作比例一定会远远大过于写操作，毕竟热卖商品库存是相对有限的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当分布式缓存因热点问题导致出现单点瓶颈时，本地缓存就可以派得上用场了，笔者在生产环境中正是结合本地缓存+分布式缓存组合实现的多级缓存方案来共同应对限时抢购场景下同一热卖商品的高并发读难题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-6 结合本地缓存+分布式缓存的多级缓存方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于分布式缓存而言，在数据的分布和用户的访问请求都是相对均匀的情况下，我们确实可以通过扩容集群节点就能够无限延伸分布式缓存的整体容量，但是当出现热点问题，流量访问相对集中时，再通过水平扩容缓存节点则无法有效应对，而本地缓存却非常适合这样的业务场景。由于本地缓存分布在各个WebServer节点中，接入层的负载均衡策略可以确保用户的访问请求相对均匀，这样一来，WebServer的节点越多，系统整体的QPS就越强，那么自然也就不存在所谓的热点问题了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于本地缓存会共享同一个JVM进程内的Heap空间，为了避免本地缓存占用过多的内存资源从而导致程序在运行的过程中抛出java.lang.OutOfMemoryError异常，所以笔者不建议把所有的商品信息都缓存在本地缓存中。例如，访问热度不高的商品可以直接访问分布式缓存，而本地缓存中存储更多的是访问热度较高的热卖商品。对于商品数据，我们需要根据其类型有针对性地配置本地缓存的更新策略。例如，由于商品的图片、视频等资源都缓存在CDN中，因此本地缓存中理论上只需要缓存以下两类数据：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 商品详情数据；● 商品库存。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>像商品详情这类变化频率较低的数据，一般在限时抢购活动开始之前就可以全量推送到所有参与限时抢购WebServer节点的本地缓存中，直至活动结束。当然，由于我们不可能保证商品详情数据自始至终都不会发生变化，所以针对这类数据可以设置较长的缓存过期时间。但是像商品库存这类数据却变化得非常频繁，自然也就需要将缓存的过期时间设置得相对短一些，一般几秒后就可以从分布式缓存中获取最新的库存数据。当大家看到这里时是否会产生一个疑问，本地缓存中存储的商品库存与实际商品库存之间可能会因为时差而造成数据的不一致，这样是否会导致超卖？对于读场景而言，其实完全可以接受在一定程度上出现数据脏读，因为这只会导致一些原本已经没有库存的少量下单请求误以为还有库存而已，等到最终扣减库存时再提示用户所购买的商品已经售罄即可（实际上，接入层Nginx中也可以再缓存一份下游商品详情接口的数据，不过其过期时间务必要小于本地缓存所设置的过期时间，尽可能将流量挡在系统上游）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实施多级缓存方案时，本地缓存更新策略的选择也是非常重要的，通常来说，本地缓存的更新策略可以分为如下两类：● 被动更新；● 主动更新。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>被动更新策略，简单来说，就是在单位时间内如果缓存项发生过期，则重新执行回源操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在执行回源操作期间，务必确保单机只能够允许一个线程在执行操作，从而避免缓存失效的瞬间大量的请求穿透到分布式缓存上引起雪崩效应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于GuavaCache具备轻量、易用等特性，且提供有丰富的被动更新机制，所以在生产环境中笔者也正是选择的GuavaCache来实现本地缓存</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者使用的更新机制为expireAfterWrite，当缓存项过期触发回源操作时，GuavaCache会通过重入锁ReentrantLock严格地控制单机只能有一个线程在执行操作，而其他线程则必须阻塞等待直至回源操作完成，不过当回源操作结束后，之前那些被阻塞的线程仍然会逐一获取锁来验证回源结果；也就是说，每个线程必须轮流地经历取锁、取值，以及释放锁的过程，这样会存在一定程度上的性能损耗。而refreshAfterWrite机制则可以有效避免expireAfterWrite机制在并发环境下因为锁资源竞争所带来的性能损耗，同expireAfterWrite类似，在执行回源操作时，单机仍然只允许一个线程在执行操作，但其他线程并不会阻塞，而是直接返回旧值；这么做虽然可以提升性能，但却仍然存在一个明显的问题，那就是refreshAfterWrite机制并不能够严格地确保返回值都是新值。当然具体应该使用哪一种缓存被动更新机制，则还需要结合具体的业务场景而定。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果想缩短本地缓存与分布式缓存之间数据不一致的窗口期</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>那就是基于消息队列的主动更新策略</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在我们通过后台配置管理系统或者商品服务修改了分布式缓存中的商品数据后，再把消息异步写入到消息队列中，这样一来，所有订阅了目标Topic的消费者就都可以消费最新的商品数据并更新本地缓存项。但实施此方案会相对复杂一些，而且由于引入了消息队列，还需要增加额外的工作成本和系统宕机风险。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-7 基于消息队列实现本地缓存的主动更新</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓存穿透思考</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于SKU非常多，因此任何一个电商平台几乎都不会把所有的商品数据全量存储在本地缓存中，只会对热点数据做优化。当我们使用多级缓存方案解决分布式缓存存在的单点问题时，就会面临一个问题，那就是如何配置热点key？笔者建议将热点key存放在配置中心内，便于管理。不过，在大促活动开始前，开发人员需要从运营同学那里提前获悉所有热卖商品的热点key，否则一切都是徒劳的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当大促活动开始后，如果已经成功配置好了本地缓存，那么分布式缓存的单点负载将会处于一个相对比较平稳的水位。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>热卖商品尽管可以在活动开始前就提前分析出来，并由运营人员交给开发人员进行配置，但是那些提前发现不了并突然成为热点的数据，以及被热点数据瞬间附带起来的流量似乎就成了漏网之鱼。对于这种在运行时突然形成的热点，往往会令架构师们束手无策，所以我们需要认真思考如何防止本地缓存发生穿透，避免系统产生雪崩效应。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一些大型的互联网电商企业内部往往都搭建有适用于自身业务特点的热点自动发现平台。简单来说，就是将交易系统产生的相关数据，以及在上游系统中埋点上报的相关数据异步写入到日志系统中，然后通过热点自动发现平台对收集到的日志数据做调用次数统计和热点分析，如果确诊为热点数据，就立即通知交易系统做好热点保护，防患于未然。尽管热点自动发现平台能够很好地在运行期自动探测热点，以及实施热点保护，但如果处于流量高峰期，由于存在滞后性问题，可能还未来得及对交易系统做好保护就已经发生缓存穿透了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实际开发过程中针对本地缓存穿透的相关解决方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RedisCluster模式下的读/写分离方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>大家需要注意，在Cluster模式下引入了读/写分离功能，并不代表需要废弃掉多级缓存方案，毕竟将用户流量尽可能挡在系统上游加速系统响应才是关键。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-4-同一热卖商品高并发写难题" tabindex="-1"><a class="header-anchor" href="#◆-4-4-同一热卖商品高并发写难题" aria-hidden="true">#</a> ◆ 4.4 同一热卖商品高并发写难题</h3>
<blockquote>
<blockquote>
<p>同一热卖商品高并发写难题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在针对同一热卖商品的高并发读业务场景下，为了避免分布式缓存因热点问题导致出现单点瓶颈，我们在实际的开发过程中可以采用多级缓存方案，并结合Redis客户端Lettuce来显式开启Cluster模式的下读/写分离操作，通过水平扩容Slave节点来无限延伸系统容量，从而避免本地缓存发生穿透。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>读的问题得到了解决</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>针对同一热卖商品的高并发写难题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>InnoDB引擎的行锁问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在关系数据库中（以MySQL为例）扣减库存时如何避免超卖呢？通常来说，通过悲观锁或乐观锁方式都可以很好地解决这个问题，但是悲观锁通常来说性能较差，因此很少会有企业选择在生产环境中使用for update的方式来实现库存扣减，而是倾向于相对更加轻量级的乐观锁方案。所谓乐观锁，简单来说，就是在我们的商品表中构建一个version字段，在并发环境下，多个用户拿到的stock和version必然是相同的，因此在第1个用户成功扣减库存后，需要对version进行加1操作；当第2个用户扣减库存时，由于version不匹配，为了提升库存扣减的成功率，可以适当进行重试，如果库存不足，则说明商品已经售罄，反之继续对version进行加1操作。使用乐观锁方案扣减库存的伪代码，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当大促活动开始后，那些单价比平时更给力、更具吸引力的热卖商品肯定会吸引大量的用户前来购买，这样一来，必然会产生大量针对数据库中同一行记录的并发更新操作，因此，MySQL为了确保一致性，InnoDB引擎会缺省对同一行数据记录加锁，把并发事务变为串行事务来执行，以保证正确性。在此大家需要注意，InnoDB的行锁特性其实是一把利与弊都非常明显的双刃剑，在保证一致性的同时却大大降低了可用性。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通常来说，秒杀场景的爆款商品的库存数量相对较少，当发生库存扣减操作时，实际上落到数据库中的写流量很小，只要系统上游能够配合交易系统做好限流保护，数据库基本上不会有太大的负载压力，但大库存的限时抢购场景就恰恰相反了。以笔者所在企业为例，大促爆款商品的库存数量多达几万～十几万不等，那么像扣减库存这种针对同一热卖商品的大并发写操作则是不可避免的，因此如果选择在关系数据库中执行扣减库存操作，那么当触发流量高峰时，由于都是针对同一行数据进行更新操作，必然会引起大量的线程相互竞争InnoDB的行锁，并发越大等待的线程就越多，这会严重影响数据库的TPS，导致RT线性上升，最终可能引发系统出现雪崩。因此，为了避免关系数据库沦为瓶颈，笔者建议大家将热卖商品的库存扣减操作转移至外部进行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于Redis乐观锁的库存扣减方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在限时抢购场景下，如果系统上游不配合交易系统做限流保护，随意放任大量的并发更新请求直接在关系数据库中扣减同一热卖商品的库存数据，这必然会导致线程之间相互竞争InnoDB的行锁。由于数据库中针对同一行数据的更新操作是串行执行的，那么某一个线程在未释放锁之前，其余的线程将会全部阻塞在队列中等待拿锁，并发越高，等待的线程就越多，这会严重影响数据库的TPS，从而导致RT线性上升，最终可能引发系统出现雪崩。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如何在Redis中实现库存扣减</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>之所以会选择在Redis中进行库存扣减操作，其中最主要的原因还是看中Redis与生俱来的高效的读/写性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如何避免商品超卖</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>或许有些同学的第一反应是采用分布式锁来避免超卖，但是这样的方案太重，效率提不上来，所以本书就不对分布式锁方案进行过多讲解了，而是为大家分享如下两种避免超卖的解决方案：● 基于乐观锁实现库存扣减；● 结合Lua脚本实现库存扣减。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者曾为大家讲解了如何基于乐观锁的方式在关系数据库中实现商品的库存扣减操作，那么接下来，笔者就为大家演示如何通过使用Redis提供的WATCH/MULTI/EXEC等命令来达到同样的效果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>WATCH命令用于监视一个或多个key，如果在事务执行之前，目标key所对应的值发生了改变，那么事务就会执行失败；而MULTI命令用于将事务块内的多条命令按照先后顺序放进一个队列中，最后由EXEC命令原子性地进行提交执行。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>将WATCH/MULTI/EXEC等命令相结合即可实现乐观锁效果，如下所示：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先使用WATCH命令对目标商品的库存进行监视，然后通过MULTI命令标记一个事务块的开始，当库存扣减命令成功添加进事务队列后，在通过EXEC命令提交事务执行前，如果目标商品的库存数量没有被更改，则意味着一次库存扣减操作是成功的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Redis内部，每个数据库都是由redis.h/redisDb结构类型来表示的，其内部会存储一个watched_keys字典，字典的key就是被监视的目标key，而对应的value则是一个链表类型的数据结构，链表中存放着所有正在监视的客户端</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-10 watched_keys字典数据结构</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当客户端执行WATCH命令时，Redis就会将被监视的key与相关客户端关联在watched_keys字典中。只要Redis中发生有任何的修改命令，在成功执行之后都会调用multi.c/touchWatchKey函数对watched_keys字典进行检查，确认是否有客户端在监视已经发生修改的key，如果有，那么就会将链表中的这些客户端全部标记为REDIS_DIRTY_CAS状态，后续提交事务时将会发生中断</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图4-11 Redis客户端的状态切换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Jedis中使用乐观锁方式扣减商品库存的伪代码</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>JedisCluster当前并不支持WATCH/MULTI/EXEC等命令，当然这并不意味着Cluster模式下我们无法使用乐观锁，我们可以通过重写其decrBy方法，利用其缺省的路由机制来实现</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在限时抢购场景下，基于乐观锁方式在Redis中扣减库存会存在一个问题，那就是针对同一热卖商品的并发写操作越高，其WATCH的碰撞概率就越大，同时库存扣减的成功率也就越低。这是不可避免的，因此在实际的开发过程中，开发人员往往需要在业务代码中指定重试次数来提升库存扣减的成功率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>是否有更优的解决方案，既可以提高库存扣减的成功率，同时还能够有效利用Redis的原子操作特性，将读/写命令合并成一条命令执行，让其更加聚焦，减少网络开销和提高系统整体的吞吐量？答案是肯定的，那就是对Redis的功能进行扩展，通过嵌入Lua脚本的方式来实现库存扣减。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>嵌入Lua脚本的库存扣减方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Lua是一个非常轻量级的脚本语言，它由C语言编写而成，可以很容易被C/C++代码调用，同时也可以很方便地反向调用C/C++函数，介于这样的特性，我们可以选择将Lua脚本嵌入应用程序中，从而为应用程序提供灵活的扩展性和功能定制，这便是Lua语言诞生的意义。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>介绍如何通过嵌入Lua脚本的方式来动态扩展Redis的功能，从而实现基于原子操作的商品库存扣减</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>早在Redis 2.6版本之前，开发人员如果想对Redis进行功能扩展，则只能通过修改源码的方式来实现，但是这样的方式太重，几乎没有任何灵活性可言，所以在2.6版本之后，Redis中开始内置有Lua解释器，允许开发人员通过嵌入Lua脚本的方式来动态扩展Redis的功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis是基于单线程模型的，所以注定了内部命令的执行是具备原子的，在并发环境下，任何一条命令在执行时永远都不会受到其他命令的干扰，都是严格按照先后顺序逐一执行的。在此大家或许会产生一个疑问，一段Lua脚本中的逻辑会由诸多复杂的操作命令构成，那么Redis在执行Lua脚本时，其操作还能保证是原子的嘛？大家完全不用担心，虽然Lua脚本中包含有诸多复杂命令，但是在真正通过EVAL或EVALSHA命令调用执行时，Redis从整体上仍然把它当做是单条命令在执行，所以说仍然是原子的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过嵌入Lua脚本来实现库存扣减在性能上会更加出色，毕竟命令变得聚焦了，整体上客户端只需要向Redis请求一次，降低了网络开销。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>只要商品未售罄，就能够确保库存一定可以扣减成功，避免了乐观锁方式下高并发导致的WATCH碰撞概率问题，大大提升了库存扣减的成功率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>商品库存扣减的Lua脚本</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当成功编写好Lua脚本后，我们应该如何嵌入到Redis中进行执行呢？Redis提供有如下2种方式：● EVAL;● EVALSHA.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>EVAL命令和EVALSHA命令都可以用于调用执行Lua脚本，但使用EVAL命令客户端每次都需要重复向Redis传递一段相同的Lua脚本，网络开销较大。而EVALSHA命令则是从Redis中获取已经缓存好的脚本执行，也就是说，EVALSHA命令相对更加节省网络带宽</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在使用EVALSHA命令之前，我们首先需要使用SCRIPT LOAD命令加载相应的Lua脚本到缓存中，等待Redis返回一串SHA1校验码，后续我们在使用EVALSHA命令时，只需要传入这串SHA1校验码，以及相应的参数信息即可，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>变化后的实时库存应该如何同步给数据库呢？这其实非常简单，当从Redis中成功扣减目标商品的实时库存后，我们可以将其写入到消息队列中，通过消息队列来实现削峰，确保写入数据库时的流量可控，那么数据库的负载压力就会始终保持在一个比较均衡的水位，不会因为针对同一行数据的并发写流量过大而导致性能下降。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis这种单线程模型，与生俱来就具备原子性，而在并发环境下，对共享资源的访问，我们却往往需要通过CAS（Compare AndSwap，比较与交换）机制或Synchronized语句来保证线程安全。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其实CAS机制底层是通过CPU指令集（比如：IA64或x86指令集中的cmpxchg指令）来实现原子操作的。在Java语法层面上，JDK1.5之后的java.util.concurrent.atomic包下已经提供有开箱即用的AtomicInteger、AtomicLong，以及AtomicReference等诸多原子操作类，使得开发人员能够以一种非常简单的方式在并发环境下实现对共享变量的原子操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>CAS指令所需的3个操作数</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 内存位置；● 旧的预期值；● 新值。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当CAS指令执行时，内存位置的值要和旧的预期值对等，处理器才会用新值更新，否则更新失败。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对int类型的变量执行“i++”操作是非线程安全的，但使用AtomicInteger的getAndIncrement（）方法却可以实现原子自增，源码如下所示：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在使用CAS时有2个问题大家需要注意，首先是ABA问题，其次是自旋锁带来的性能开销问题。先从ABA开始谈起，假设我们将A改为B，然后又将其变为A后，那么CAS指令在执行时会认其值为并没有发生任何变化，但实际上数据已经发生了变化，因此为了解决这个问题，大家可以使用带版本号的AtomicStampedReference类来避免。而自旋锁问题，当对共享资源的并发更新粒度越大时，其自旋概率也就越大</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这会导致大量的线程因无限重试而占用过多的CPU资源，虽然Synchronized同步需要经历线程从BLOCKED到RUNNABLE状态的切换（其过程又涉及操作系统用户态和内核态的转换），但资源竞争激烈的场景下使用Synchronized同步或许会更加合适，反之笔者才建议使用CAS。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于AliSQL数据库提升并发写性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Redis中实施爆款商品的库存扣减方案会带来较大的改造成本，那么是否还有一些改造成本较小的解决方案？答案是肯定的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>阿里开源的AliSQL数据库</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2016年8月9日，阿里正式启动了AliSQL数据库的开源计划。从官方发布的测试结果来看，AliSQL数据库的综合性能较MySQL官方版本提升了约70%，尤其是针对秒杀场景做了特殊优化，性能可提升100倍左右。如果仅仅是希望使用AliSQL替换MySQL官方版本来应对秒杀场景，那么可以将AliSQL理解为一款为互联网电商业务特殊定制的高性能MySQL数据库，AliSQL在云计算及金融等领域也能够大展拳脚。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>采用批量提交扣减商品库存方案能够有效提升系统整体的TPS，那么这在AliSQL中又是如何实现的呢？其实AliSQL在InnoDB引擎层前面对同一行的热点更新SQL做了收集。简而言之，AliSQL首先会对热点记录做Hash，其中每一个桶就是一个热点行，对每个桶做收集，然后由桶里面的第一个事务一批次地把当前桶里收集的所有库存扣减请求一次性提交掉，这样就将原先的串行化操作变成了批处理操作。为了提升整体性能，当第一批提交的时候第二批开始收集，这样就将单线程的串行变成了批处理的线程</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>无论是在Redis中扣减库存，还是在AliSQL中扣减库存，为了提升系统整体的TPS，都是先收集库存扣减请求，达到阈值后再做合并处理，最后批量进行提交。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-5-本章小结" tabindex="-1"><a class="header-anchor" href="#◆-4-5-本章小结" aria-hidden="true">#</a> ◆ 4.5 本章小结</h3>
<blockquote>
<blockquote>
<p>大家提供了多级缓存+RedisCluster模式下的读/写分离方案。而写难题，则提供基于Redis乐观锁的库存扣减方案，以及嵌入Lua脚本的库存扣减方案</p>
</blockquote>
</blockquote>
<h2 id="◆-第5章-星罗棋布——分库分表方案" tabindex="-1"><a class="header-anchor" href="#◆-第5章-星罗棋布——分库分表方案" aria-hidden="true">#</a> ◆ 第5章 星罗棋布——分库分表方案</h2>
<blockquote>
<blockquote>
<p>随着用户规模的线性上升，单库的性能瓶颈会逐渐开始暴露，由于数据库的检索效率越来越低，将会导致生产环境中产生较多的慢速SQL。对于那些非结构化的数据，可以将其存储在NoSQL数据库中来提升性能，但是重要的业务数据，仍然需要落盘在关系数据库（如MySQL数据库）中。那么如何提升关系数据库的并行处理能力和检索效率就成为架构师们需要思考和解决的难题，并且单库如果宕机，业务系统也就随之瘫痪了。因此，在互联网场景下，架构师们务必确保后端存储系统具备高容错、容灾能力，为了解决这些问题，目前互联网场景下常见的做法便是对数据库实施分库分表，即Sharding改造。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者接触的第一款分库分表中间件为淘宝的TDDL（Taobao Distribute Data Layer），但其Matrix层源码直至今日也并未开源实属遗憾。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Shark、ApacheSharding-JDBC等优秀的分库分表中间件层出不穷。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-1-关系数据库的架构演变" tabindex="-1"><a class="header-anchor" href="#◆-5-1-关系数据库的架构演变" aria-hidden="true">#</a> ◆ 5.1 关系数据库的架构演变</h3>
<blockquote>
<blockquote>
<p>关系数据库常见的性能瓶颈主要有两个，如下所示：● 大量的并发读/写操作，导致单库出现难以承受的负载压力；● 单表存储数据量过大，导致检索效率低下。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任何一个刚上线的互联网项目前期用户规模都不大，系统整体并发量相对较小，因此企业一般会在这个阶段选择将所有的数据信息都存储在单库中进行读/写操作。但是随着用户规模不断提升，单库逐渐力不从心，TPS/QPS越来越低，因此到了这个阶段，DBA会将数据库设置为读/写分离状态（生产环境一般会采用一主一从或一主多从），由Master负责写操作，而Slave作为备库，不会开放写操作，但可以允许读操作，主备之间保持数据同步即可。根据二八法则来看，80%的数据库流量均发生在读操作上，剩下的20%则为写操作，经过读/写分离改造后，可以大大提升单库无法支撑的负载压力</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果Master存在TPS较高的情况，Master与Slave之间数据同步是会存在一定延迟的，因此在写入Master之前最好将同一份数据落到缓存中，以避免高并发情况下，从Slave中获取不到指定数据的情况发生。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库垂直分库</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于将数据库的读/写操作进行了分离，Master负责写入，Slave负责读取，系统整体的吞吐量相对于单库而言自然会有一定的提升，但是只依靠数据库的读/写分离并不能一劳永逸，随着用户规模的线性上升，系统瓶颈一定会暴露。因此到了这个阶段，DBA便会开始对数据库进行垂直分库改造。所谓垂直分库，简单来说，就是企业根据自身业务的垂直划分，将原本冗余在单库中的数据表拆分到不同的业务库中，实现分而治之的数据管理和读/写操作</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-2 数据库垂直分库</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以关系数据库MySQL为例，由于单一业务的数据信息仍然存储在单表中，当MySQL单表的数据量超过500万行时，读操作就会逐渐成为瓶颈，哪怕构建索引，也无法解决因为数据膨胀而带来的检索效率低下等问题。大家可能会产生疑问，对写操作难道就不会有影响吗？由于写是顺序写，所以基本上数据库的写入操作不会因为数据膨胀而成为瓶颈，但是读操作一定会存在上限。这其实也是RDBMS等类型数据库的特点，相对于非常规的NoSQL数据库而言，由于双方的底层存储架构不同，所以自然无法相提并论。因此到了这个阶段，DBA就需要在垂直分库的基础上实施水平分表改造。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库水平分库与水平分表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>水平分表就是将原本冗余在单库中的单个业务表拆分为n个“逻辑相关”的业务子表（如tab_0000、tab_0001、tab_0002...），不同的业务子表各自负责存储不同区间的数据，对外形成一个整体，这就是大家常说的Sharding操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>水平分表后的业务子表可以包含在单库中，如果Master的TPS过高，则还可以对垂直分库后的单一业务库进行水平化。同水平分表类似，可以将水平分表后的这些业务子表按照某种特定的算法和规则分散到n个“逻辑相关”的业务子库中（如db_0000、db_0001、db_0002……），只是实施相对复杂，而且还需要专门的Sharding中间件负责数据的路由工作</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-3 数据库分库分表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在生产环境中实施分库分表操作，主要是为了解决高并发场景下单库的性能瓶颈，并充分利用分布式的威力提升数据库的读/写性能。假设后续业务表中的数据量又一次达到存储阈值并对性能产生影响时，DBA只需要再次对现有的业务库和业务表水平扩容，并迁移数据即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>MySQL Sharding与MySQL Cluster的区别</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>单纯从技术上来讲，MySQL Cluster只是一个数据库集群，其优势只是扩展了数据库的并行处理能力，但是使用成本、维护成本相当高（目前在生产环境中使用者较少，而且实施相对复杂）。而MySQL Sharding是一个成熟且实惠的方案，不仅可以提升数据库的并行处理能力，还能够解决因为单表数据量过大所产生的检索瓶颈。简而言之，前者是集群模式，后者是分布式模式，因此无论从哪个维度来看，Sharding都是互联网当下最好的选择。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-sharding中间件" tabindex="-1"><a class="header-anchor" href="#◆-5-2-sharding中间件" aria-hidden="true">#</a> ◆ 5.2 Sharding中间件</h3>
<blockquote>
<blockquote>
<p>一旦数据库实施分库分表后，开发人员就必须思考两个问题。首先，必须明确定义SQL语句中的Shard Key（路由条件），这非常重要，因为路由维度直接决定了数据的落盘位置。其次，应该如何根据所定义的Shard Key进行访问路由，这需要定义一套特定的路由算法和规则。当这两个问题成功解决后，就能够让任何一条SQL语句的读/写操作准确定位到具体的业务库和业务表中去执行预期的操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在生产环境中大部分企业大都倾向于使用成熟的Sharding中间件完成数据的路由工作，也会有一些企业自行研发适用于自身业务场景的Sharding中间件，不过当你所处的企业或团队，连最基本的业务进度都没办法保证且缺少实施经验时，笔者更推荐选择前者，毕竟成熟的中间件产品都是经过生产检验的，基本没有必要再花时间去踩坑和填坑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>常见的Sharding中间件对比</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从体系架构上进行划分，Sharding中间件主要基于Proxy架构和应用集成架构两大类组成。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于Proxy架构的Sharding中间件，可以灵活实现任意的关系数据库协议，满足个性化定制，可以做到在一定程度上的通用，不局限于任何数据库。而基于应用集成架构的Sharding中间件，尽管不能够实现通用性需求，但是由于应用直连数据库，读/写性能往往比前者高出10%～20%。总之，两种体系架构截然不同的Sharding中间件都各有优缺点，具体使用哪一种还需要结合自身实际的业务场景而定。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以基于应用集成架构的Sharding中间件为例。早期比较成熟的只有淘宝的TDDL</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>部分功能开源但核心功能闭源</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在想要使用TDDL还有一种间接的方式，那就是淘宝已经将TDDL作为阿里云上的一个收费服务——分布式关系数据库服务（Distribute Relational DatabaseService，DRDS）。开发人员无须关心底层的数据库存储架构，只需要使用阿里云提供的数据服务即可，这种方式有利有弊，最明显的弊端就是，后期如果企业自行构建数据中心时，数据迁移将是一件令人非常头痛的事情。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>市面上常见的一些Sharding中间件产品对比[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Shark是一款采用Apache License 2.0开源协议的分布式MySQL分库分表中间件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具备丰富、灵活的路由算法支持，能够方便DBA实现库和表的水平扩容，以及有效降低数据的迁移成本。Shark站在巨人（SpringJDBC、Druid）的肩膀上，采用应用集成架构，放弃通用性，只为换取更好的执行性能，以及降低分布式环境下外围系统的宕机风险。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以Shard Key为条件，按照特定的路由算法和规则对多数据源进行动态切换，这样即可定位到目标业务库上，再将SQL语句中的全局表名进行解析和重写替换（比如替换前：SELECT<em>FROM tab WHEREuid=1，替换后：SELECT</em>FROM tab_0001 WHERE uid=1），这样即可定位到目标业务表上，这就是Sharding中间件最核心的基础功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓垂直分库就是企业根据自身业务的垂直划分，将原本冗余在单库中的数据表拆分到不同的业务库中，实现分而治之的数据管理和读/写操作。水平分表是将原本冗余在单库中的单个业务表拆分为n个“逻辑相关”的业务子表，不同的业务子表各自负责存储不同区间的数据，对外形成一个整体。假设垂直分库后的订单业务库的内部需要水平拆分出1024张订单表，那么这些订单子表就可以按照order_0000至order_1023的方式分布在订单业务库中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>和单库多表模式不同的是，多库多表模式应用在业务库和业务表都需要进行水平化的场景下，因此可以将其看作对单库多表模式的一种升级，同时这也是互联网场景下，关系数据库应对高并发、单表数据量过大问题的最终解决方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了提升数据库的并行处理能力，以及避免单表数据量过大导致检索效率低下，我们不仅对单库进行了水平分库，还将单表进行了水平分表，最后一共拆分出了1024张业务子表，均匀分布在32个Master库中。也就是说，每个库中都包含32张业务表（1024/32=32），当然Slave库和Master库是保持一致的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当对单库进行水平分库时，建议大家遵循“二叉树分库”策略，即当DBA对数据库进行扩容的时候，都是以2的倍数进行扩容（比如从2台扩容到4台，从4台扩容到8台，从8台扩容到16台，以此类推），采用这种分库方式的最大优点就是扩容和数据迁移会更加方便。当对单表进行水平分表时，为了确保数据能够均匀落盘，建议大家将分表数量设定为分库数量的倍数（比如库的数量为2，片的数量为4；库的数量为4，片的数量为8；库的数量为8，片的数量为16，以此类推）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分库分表后所带来的影响</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一旦数据库实施分库分表后，多多少少都会对现有业务产生一定的影响，而这类影响大多体现在逻辑代码的实现上。假设我们从单库单表的数据库架构演变为“垂直分库、水平分表”或者“水平分库、水平分表”架构时，有4个比较棘手的问题是需要慎重考虑和尽早规划的，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● ACID特性如何保证；● 多表之间的关联查询如何进行；● 无法继续使用外键约束；</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 无法继续使用由Oracle提供的Sequence，或者MySQL提供的AUTO_INCREMENT生成全局唯一和连续性ID。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>关于SequenceID应该如何生成</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任何大型的互联网企业，一旦数据库实施分库分表后，对于SQL语句的编写都有一条铁打不动的“军规”，那就是更倾向于简单化、轻量化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>就是尽可能地避免使用多表联合查询语句，而是将其拆分为多条单表查询语句，多次查询。或许有人会产生疑问，难道多表联合查询性能不如多次单表查询快吗？其实不然，至少从测试结果来看，多次单表查询在执行效率上并不比多表联合查询慢多少，并且在互联网场景下，为了扩展性、易读性和维护性，牺牲一点性能（如多次会话连接、资源消耗），又怎样？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在互联网场景下，利用单表查询语句换来的优势，主要有以下两点：● 查询语句简单，易于理解、维护和扩展；● 缓存利用率高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>全局唯一SequenceID解决方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在面向单点系统的场景下，生成一个全局唯一的ID是非常简单的事情。以数据库为例，Oracle提供的Sequence、MySQL提供的AUTO_INCREMENT都可以生成不重复且连续的ID，甚至开发人员还可以在程序中使用UUID.randomUUID（）方法进行唯一ID的生成。总的来说，这类生成唯一ID的方式都具备一个共同的特点——面向单点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库实施分库分表后，将要面临的场景就不再是单点环境了，而是分布式环境，因此如何有效地生成ID自然也就成了一个令人头痛的问题。首先如何保证所生成的ID具备唯一性是重点，其次，如果需要考虑连续性，那么将更加复杂，因为这里所指的连续性不再是由单点维护，而是整个分布式环境下的连续性。当然，如果只是考虑生成ID的唯一性而忽略掉连续性，开发人员可以利用UUID、物理机器IP地址、随机值、时间戳等不同的维度共同生成唯一的ID。既然要兼顾生成ID的唯一性和连续性，那么依赖一个独立的外围单点系统来负责完成则不失为一个可取的方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Shark内部已经提供了生成SequenceID的API（底层支持数据库和ZooKeeper作为申请SequenceID的存储系统），开发人员只需要调用即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Shark提供生成SequenceID的API只是封装了ID的生成逻辑，真正保证唯一性和连续性的还是单点数据库（想要提升容灾能力和HA，可搭建Master/Slave模式）。上述程序中的getSequenceId（int idcNum，int type，long memData）方法包含3个参数，第1个参数是IDC机房编码，用于区分不同的IDC机房；第2个参数是业务类别，2位数字长度；第3个参数是向数据库申请的ID缓存数。最终这段代码会返回一个数据类型为long、数值长度为19位的SequenceID。数值长度为19位的SequenceID已经能够满足绝大多数企业后续多年的使用了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Shark生成SequenceID的原理。如果每一个应用系统中都依赖Shark，也就意味着每一个应用系统都间接嵌入一个ID生成器，并统一指定一个单点存储系统作为存储介质</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库主要负责存储当前ID序列的最大值，每次每个ID生成器从数据库中申请ID时，都会通过行锁机制来确保并发环境下数据的一致性。或许大家会产生一个疑问，是否存在性能瓶颈？如果每生成一个ID都去数据库申请必然性能低下，但是Shark的ID生成器一次会从数据库中取出一段ID，然后缓存在本地，这样就不用每次都去数据库中申请了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>想要提升Shark生成SequenceID的性能，可以调整getSequenceId（）方法中的第3个参数，该数值越大，ID生成效率越高，但是一旦ID生成器取了一段ID后，系统宕机或者发版时，这一组ID都将废弃，并且后续可向数据库申请的有限ID缓存数将越来越少（SequenceID的最大值不可超过二进制位数64位long类型的最大值9223372036854775807），因此这需要大家仔细权衡，笔者建议将其值设置在“5000～10000”较为合理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了可以使用嵌入式的ID生成器方式，目前业界还有另一种比较常见的做法，那就是将ID生成器从应用中剥离出来，单独部署</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>采用这种方式的优点很明显，当系统发版或宕机时，每个应用所申请的ID段不会轻易作废；但同样也存在2个缺点，首先是ID生成服务需要单独部署，增加了企业的维护成本，其次相对于嵌入式ID生成器而言，多加了一层网络开销。当然最终选择使用哪一种ID生成方式，还需要根据实际的业务场景而定。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-6 独立部署的ID生成器</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于Solr满足多维度的复杂条件查询</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Solr是Apache旗下的一个子项目，它是一种采用Java语言编写、开放源代码，并且扩展自Lucene的搜索引擎。尽管Solr和Lucene同属Apache，但是两者并不存在直接的竞争关系，相反，Solr非常依赖Lucene，因为Solr的核心功能正是通过调用Lucene的API来实现的。Solr能够非常方便地在Web容器中进行部署，并且它提供了一系列的HTTP接口供开发人员调用，使之向服务器提交Document，对索引进行创建、修改和删除等操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Solr还提供了一整套完整的表达式语言，能够实现任意复杂的条件查询。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在互联网场景下使用Solr有两个最主要的场景</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果数据库（MySQL）的查询条件采用like进行模糊查询（比如SELECT*FROM item WHERE item_name like‘%香水%’），数据库是不会进行索引的，而是采用全表扫描机制。因此当表中数据量较大时，查询速度会变得异常缓慢，就像我们在购物网站搜索某一类商品时，由于物品种类成千上万，使用like进行模糊查询就会非常拙劣，因此在这种场景下使用Solr将非常适合。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其次，数据库实施分库分表后，数据最初以什么样的维度进行落盘，最后就只能够通过这种维度进行查询，如果希望同时满足多维度的复杂条件查询需求，利用Solr这类搜索引擎将非常容易。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式事务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓事务，指的是程序中多个操作对上下文的影响是一致的，要么全部成功，要么全部失败，绝对不允许出现停滞在中间某个状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式环境下，本地事务已经无法保证数据的一致性，若引入分布式事务，所带来的问题往往比我们想象的更复杂。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前较常见的三种分布式系统中的一致性协议如下：● 两阶段提交协议（Two Phase Commit Protocol，2PC）；● 三阶段提交协议（Three Phase Commit Protocol，3PC）；● Paxos协议。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以两阶段提交协议为例，首先提交操作会涉及多次节点之间的网络通信；其次由于事务时间、资源锁定时间延长，会导致资源等待时间变长。因此在某些场景下，能够不引入分布式事务的还是尽量不要引入，有些无关紧要的数据丢失就丢失了，可以无须理会，但是一些比较重要的数据，如果一定需要保证一致性，也不要刻意去追求强一致性，可以考虑采用基于消息中间件保证数据最终一致性方案，让之前执行失败的操作继续向前执行下去。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-数据库的ha方案" tabindex="-1"><a class="header-anchor" href="#◆-5-3-数据库的ha方案" aria-hidden="true">#</a> ◆ 5.3 数据库的HA方案</h3>
<blockquote>
<blockquote>
<p>数据库的HA方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>HA在广义上所指的是系统所具备的高可用性。以MySQL数据库为例，DBA实施Master/Slave搭建实际上就是HA的一种体现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我们的应用系统在大部分情况下都是无状态的，由于单台服务器的处理能力有限，因此为了能够更好地提升系统整体的吞吐量及并行处理能力，往往会对这些应用系统采用集群部署，这也是实施HA的另外一种体现。无论是数据库主备模式，还是应用程序集群，往往都不会因为单一节点的故障而影响系统整体服务的不可用，这就是做HA的主要原因。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果WebServer需要部署集群，接入层则需要引入反向代理服务器来分发请求，在互联网领域使用Nginx+Tomcat这种形式的架构非常常见，由Nginx负责请求分发、负载均衡，以及Failover等任务。数据库如果需要搭建HA，也需要一种机制保证主备的正常切换，保证Master宕机后Slave能够开放读/写权限，充当新Master的角色。目前业界有三种成熟的方案可供选择，如下所示：● 基于配置中心实现主备切换；● 基于Keepalived实现主备切换；● 基于MHA实现主备切换。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于配置中心实现主备切换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库实现主备切换通常有两种形式比较常见，一种是当监控告警系统发出告警后，运维人员手动修改数据源信息，另一种则是Master实例发生故障后自动切换到Slave库上。如果采用手动切换主备的方式实现数据库的HA，那么基于配置中心是一个非常不错的选择，但是这往往需要配置中心客户端的支持才能够实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Shark目前已经提供了基于ZooKeeper的配置中心客户端，方便开发人员将数据源信息统一配置在ZooKeeper中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于Keepalived实现主备切换</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当Master实例发生故障，监控系统发出告警通知时，运维人员可以通过修改配置中心配置的数据源信息来达到手动切换数据库主备的目的。当然，除了采用这种方式实现数据库的HA，还可以通过自动主备切换的方式实现数据库的HA。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以Keepalived为例，假设Master机器和Slave机器上都装有Keepalived程序，那么我们需要先修改/etc/keepalive目录下的keepalive.conf配置文件，在主备机器上都配置好VIP（Virtual IP Address，虚拟IP地址）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>成功启动Master机器、Slave机器，以及Keepalived后，程序中数据源的配置和之前相比是存在区别的，Master的IP地址直接指向的是VIP地址。在程序运行的过程中，Master机器和Slave机器上的Keepalived程序会相互发送心跳信号，确认对方状态是否存活，一旦Master实例出现故障，根据所配置属性“delay_loop”的值，Keepalived会在指定的时间范围内定时检查数据库的健康状态，一旦发现异常，Master机器上的Keepalived会选择“自杀”，这时Slave机器上的Keepalived由于检测不到心跳，便会开始接管VIP请求，这样所有的写入请求就会全部落到Slave库上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我们可以在Keepalived的配置文件中通过属性“notify_down”来指定当检测到数据库实例宕机后需要执行的脚本（比如将Slave库的读/写权限打开）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从Master实例宕机到Slave接管成为新Master之前的这段时间，数据库暂时不可用，如果这时有写入请求进来，有可能造成数据丢失，那么怎样才可以避免在数据库主备切换的过程中不出现数据丢失呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在大部分情况下，为了缓解数据库的查询压力，数据都是优先插入到缓存服务器中再插入到数据库的。那么我们可以通过定时程序定时增量检查数据库与缓存数据是否一致，如果不一致，则可以利用缓存数据对数据库实施补偿。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在某些场景下，为了削峰我们采用异步模型将数据插入到数据库，比如先将数据写入到消息队列，待消费后再写入到数据库。因此，当消费消息后插入数据到数据库失败时，可以通过failover机制尝试多次等一系列手段来保证数据库主备切换过程中数据尽可能不丢失。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>保障主备切换过程中的数据一致性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在数据库主备切换的过程中，我们可以利用一系列的辅助手段来避免在数据库不可用时造成数据的丢失，但是在数据库主备切换过程中，还存在一个棘手的问题，那就是Master实例宕机后，Slave变为新的Master时，主备数据肯定不一致了，此时如何保证主备数据的一致性呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在解决这个问题之前，我们首先回到主备同步这个问题上，在Master的TPS较高的情况下，主备同步的延迟肯定是非常大的，因此为了避免数据库读/写分离后应用层无法从Slave拉到实时数据，通常的做法是在写入Master之前也将同一份数据落到缓存中，以避免高并发情况下，从Slave中获取不到指定数据的情况发生。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>MySQL本身提供的机制也能够在最大程度上保证主备数据的一致性，参考微信抢红包的案例，在非高峰期或者非活动日时，由于流量不会特别大，因此数据库主备同步之间可以显式开启半同步复制（Semi-synchronous Replication）功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-7 MySQL的Semi-synchronous Replication机制</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这是MySQL在5.5版本时开始提供的一个功能，半同步复制可以理解为主备之间的强制数据同步，以保证主备数据的准实时性。简单来说，当事务提交到Master后，Master会等待Slave的回应，待Slave回应收到Binlog（二进制日志）后，Master才会响应请求方已经完成了事务。在峰值流量较大的场景下，笔者不建议开启这项功能，这会对TPS产生一定的影响。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>尽管半同步复制机制可以在主备数据库不宕机的情况下保证数据的一致性，但是当Master实例宕机后，Slave摇身一变成为新的Master时，主备数据库之间的数据肯定会出现不一致。在这种情况下，为了避免手动比对Binlog来确保主备数据的一致性，可以使用MySQL在5.6版本开始提供的GTID（全局事务ID）特性。由于新Master是之前的Slave，而宕机后的Master在重启后可以作为Slave存在，可以依靠GTID特性来保证主备之间数据的最终一致性。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-订单业务冗余表需求" tabindex="-1"><a class="header-anchor" href="#◆-5-4-订单业务冗余表需求" aria-hidden="true">#</a> ◆ 5.4 订单业务冗余表需求</h3>
<blockquote>
<blockquote>
<p>5.4 订单业务冗余表需求</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>某些业务除了并发访问度较高，通常还伴随着数据量非常大的特点。一旦数据库实施分库分表后，订单业务的查询需求就会开始变得复杂。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我们的数据最初以什么样的维度进行落盘，最后就只能够通过这样的维度进行查询。订单数据需要对此进行查询的往往同时包含卖家和买家两类用户群体，卖家需要查询哪些买家对自己店铺的商品进行了下单，而买家也需要通过订单信息完成后续的付款等操作，这就产生了矛盾，我们在处理订单数据时，到底是以seller_id为维度进行数据落盘，还是以buyer_id为维度进行数据落盘呢？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果只是以其中一个维度进行数据落盘，那么最终能够查询出订单数据的只是卖家或买家中的一方。因此，为了应对这种特殊的业务需求，目前业界比较常见的做法是对同一份订单数据进行冗余存储，即我们需要维护两张订单表，一张是卖家订单表，另外一张是买家订单表</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>卖家订单表以seller_id为维度进行数据落盘，买家订单表则以buyer_id为维度进行数据落盘，这样既可以满足卖家的查询需求，也能够满足买家的查询需求，这就是数据库实施分库分表后订单业务场景下常见的冗余表需求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>冗余表的实现方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>实现订单数据的冗余存储，就是同时向t_order_seller表和t_order_buyer表中插入同一份订单数据。数据的写入过程，可以分为以下两种形式：● 数据同步写入；● 数据异步写入。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>业务上实现订单数据的落盘，通常的做法是由接入层调用订单服务，然后由订单服务将订单数据写入订单表中，这是非冗余存储时数据落盘的实现方式。但是实现冗余表后，同一份数据需要写入两次，如果采用数据同步写入方案，订单服务会按照先后顺序，写完第一张表后再将数据同步写入到另外一张表中。实施这种方案基本不具备复杂度，就是由之前的单写变为双写。其缺点也非常明显，就是写入时间比之前增加了1倍，因此如果对系统的TPS有严格的时间要求，可以使用数据异步写入方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>采用数据异步写入方案后，订单服务不再采用同步双写落盘数据，而是当服务成功将数据写入到第一张表后，通过异步模型将数据写入到第二张表中（比如启动一个异步线程负责写入，或者写入消息队列后由消费者负责写入）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于第二次数据写入操作是异步的，服务不用等待其结果返回，系统整体性能会得到提升，但是相对于数据同步写入方案来说，系统复杂度却增加了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-8 数据异步写</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于没有可靠的事务机制来保证数据双写过程中的一致性，因此无论是采用同步写入还是异步写入方案，在数据库TPS较高的情况下，冗余表极有可能出现数据不一致。因此这里就涉及一个问题，到底是优先写入到t_order_seller表更好，还是优先写入到t_order_buyer表更合适？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>结合笔者项目中实际的订单业务来分析，优先将数据写入到t_order_buyer表中会更好，因为哪怕后续t_order_seller表写入数据失败，至少用户还可以继续推动订单状态的流转（如对订单完成支付），反之如果用户看不到系统新生成的订单，那么对于商家来说似乎也是没有任何意义的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5.4.2 数据最终一致性方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>数据库实施分库分表后会对现有业务产生一定的影响，数据的一致性难以得到保证，对于那些强调数据一致性的场景，我们能够做的要么是使用强一致性的分布式事务，要么是使用最终一致性方案。介于分布式事务与生俱来的复杂性和低效性，所以笔者建议，对于那些能够接受数据存在短期不一致的业务场景来说，使用最终一致性或许是最优的解决方案。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在冗余表需求中，基于数据同步写入和异步写入两种方案，都可能在数据写入时产生失败，从而导致t_order_seller表与t_order_buyer表之间产生不一致，那么基于消息队列的最终一致性方案应该如何实施呢？简单来说，当订单数据成功写入t_order_buyer表后，立即将消息写入到消息队列中，成功写入t_order_seller表后，再把相同的消息也写入到消息队列中，消费端消费到第1条消息后，如果在单位时间内没有消费到第2条消息，就可以认为数据已经产生了不一致，需要执行数据补偿操作，这种数据最终一致性方案称之为“线上检测补偿”</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>尽管“线上检测补偿”方案会缩短数据不一致的窗口期，但实现难度却比较复杂。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-9 线上检测补偿</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>细化到具体的逻辑实现上，在消费端代码中我们可以申明两个List集合，分别用于存储接收到的buyer和seller的对等消息</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于存储到buyerData和sellerData中的消息是一样的，所以假设制定t_order_seller表和t_order_buyer表之间数据不一致的窗口期被设定为两秒，一旦buyerData或sellerData中任意一个不包含指定的消息，就可以认为数据需要进行补偿。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设消费者消费到第1条消息后，由于网络原因导致第2条消息消费延迟，但数据库之前已经成功写入，因此数据补偿之前，需要优先执行幂等操作。数据一致性检测与补偿的伪代码如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另一种相对更加通用的数据最终一致性方案，那就是基于阿里开源的Canal中间件实现MySQL数据库的Binlog增量同步。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Canal的工作原理非常简单，简单来说，它首先会将自己伪装成MySQL的Slave节点，然后向Master发送dump请求，当Master接收到请求后，便会开始向其推送Binlog，最后再由Canal解析Binlog对象即可完成数据的增量同步。对于开发人员而言，如果采用此方案，则可以从业务代码中去除订单表的双写逻辑，当成功写入t_order_buyer表后，再由Canal来负责根据当前数据库实例的Binlog位点增量同步订单数据到t_order_seller表中</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]图5-10 Binlog增量同步</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在实际的开发过程中，如果需要对订单数据做一些特殊处理，那么可以先将t_order_buyer表中的数据同步到消息队列，待数据消费并处理完成之后再写入到t_order_seller表中即可。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>无论是使用“线上检测补偿”方案还是使用Binlog增量同步方案均能够有效保证数据的最终一致性，当然具体使用哪一种方案则还需要结合实际的业务场景而定。</p>
</blockquote>
</blockquote>
<h2 id="◆-附录" tabindex="-1"><a class="header-anchor" href="#◆-附录" aria-hidden="true">#</a> ◆ 附录</h2>
<blockquote>
<blockquote>
<p>笔者总结了大促备战的9项核心事项供大家参考，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）线上全链路压测：有针对性地对系统进行容量规划，挖掘系统的性能短板，让其坚如磐石。（2）常规配置项检查：服务配置中的连接池、线程池等资源配置项，都需要在系统整体扩容后进行相应的调整。（3）数据库索引检查：DBA团队需要介入，避免出现慢速SQL。（4）黄金链路的限流、降级、熔断检查：根据压测结果及时调整相关阈值，避免交易系统产生雪崩。（5）缓存项检查：热点数据应当优先在缓存命中，以降低下游存储系统的负载压力，至于热点Key应尽早加入本地缓存，避免分布式缓存出现单点瓶颈。（6）故障红蓝军演练：通过人为模拟故障来验证相关应急预案是否充分、有效，以及提升开发人员的应急处理能力。（7）核心存储系统、中间件巡检：容灾性、容错性，以及资源检查。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（8）异步化改造：分析哪些业务可由同步模式改为异步模式来提升其性能。（9）监控检查：验证监控的覆盖范围是否全面，避免系统成为脱了缰的野马。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>定位线上问题的一些手段分享</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分析问题和解决问题的能力就是评判一个程序员能力好坏的标准。首先来看一个非常简单的故障示例，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当成功运行上述代码后，CPU占用率会瞬间异常飙升至100%。针对这一故障，要定位出具体原因，通常需要经历如下4个步骤：（1）通过命令“jps”或者“ps-aux|grep name”获取目标进程的PID；（2）获取PID后，执行命令“top-H-p PID”定位出耗时最高的线程；（3）执行命令“printf“%x\n&quot;TID”将线程ID转换为十六进制数；（4）执行命令“jstack PID|grep TID-a 30”打印出目标线程的堆栈信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果这个CPU占用率过高的例子都需要经历上述如此烦琐的排查步骤，那就更不用说其他复杂的线上问题了。而且，如果你不具备丰富的故障排查经验，甚至很难定位出问题的具体原因。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>笔者再举一个真实的故障案例。某次业务系统升级，当运维同学启动Tomcat后，由于业务上需要执行一些大文件的加载操作，从而导致JVM出现长时间的Full GC。当GC结束后，却发现Tomcat出现了“假死”现象，不再接收任何用户请求。那么如果让你来分析这个故障原因，你的思路是什么？好奇心使然，笔者索性加入了故障排查大军，并记录下了当时的排查步骤，如下所示：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）首先查看Tomcat的server.xml，确认使用的是BIO模型；（2）使用命令“jstack pid”查看线程堆栈，发现Tomcat线程池中的工作线程全部处于Waiting状态；（3）使用Arthas工具的“dashboard”命令查看大盘数据，未发现明显问题；（4）使用命令“curl”访问时，发现Tomcat的访问日志中无任何访问记录；（5）使用命令“strace-p”跟踪程序执行过程中产生的系统调用及接收到的信号，无果；（6）再次执行命令“jstack pid|grep-a http”，未发现Tomcat的Acceptor线程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>既然未发现Tomcat的Acceptor线程，那么就能合理解释为什么Tomcat线程池中的工作线程全部处于Waiting状态了。Acceptor线程的主要任务是负责监听客户端的Socket连接，并将成功建立连接的Socket传递给线程池中的工作线程，但由于Acceptor线程遭遇意外退出，Tomcat无法监听会话连接，所以自然也就不再接收任何请求了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于排查程序异常所导致的CPU占用率过高问题，如果我们使用开源的async-profiler工具则会显得非常简单。async-profiler是一款开源的Java性能分析工具，它具备简单、易用的特点，在实际的开发过程中，开发人员可以通过它来分析诸如CPU占用率、内存占用率等问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>除了async-profiler，在实际的开发过程中，笔者还会经常使用阿里开源的Java故障排查工具Arthas，async-profiler+Arthas的工具组合基本上构成了笔者日常排查线上故障的主要手段。</p>
</blockquote>
</blockquote>
<h2 id="◆-后记" tabindex="-1"><a class="header-anchor" href="#◆-后记" aria-hidden="true">#</a> ◆ 后记</h2>
<blockquote>
<blockquote>
<p>目前云集已经茁壮成长为峰值流量过亿、整站OPS达到75w/s、GMV过百亿的中大型电商企业。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>架构的本质就是有序地对系统进行重构，不断减少系统的“熵”，使之不断进化，创作亦是如此。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一名优秀的架构师，抽象思维能力是必不可缺的，架构师要善于“庖丁解牛”，将实物概念化并归类，比如一个大型网站，你需要能够快速地根据业务功能的不同，将其垂直化。</p>
</blockquote>
</blockquote>
</div></template>


