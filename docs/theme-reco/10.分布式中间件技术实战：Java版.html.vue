<template><div><h1 id="分布式中间件技术实战-java版" tabindex="-1"><a class="header-anchor" href="#分布式中间件技术实战-java版" aria-hidden="true">#</a> 分布式中间件技术实战：Java版</h1>
<p>钟林森</p>
<h2 id="◆-前言-为什么要写这本书" tabindex="-1"><a class="header-anchor" href="#◆-前言-为什么要写这本书" aria-hidden="true">#</a> ◆ 前言 为什么要写这本书</h2>
<blockquote>
<blockquote>
<p>介绍了Java企业级应用构建所涉及的各种常见中间件，包括Redis、RabbitMQ、ZooKeeper和Redisson等，不仅介绍了其理论要点，还介绍了其功能组件底层基础架构的执行过程。</p>
</blockquote>
</blockquote>
<h2 id="◆-第1篇-开发工具准备" tabindex="-1"><a class="header-anchor" href="#◆-第1篇-开发工具准备" aria-hidden="true">#</a> ◆ 第1篇 开发工具准备</h2>
<blockquote>
<blockquote>
<p>分布式系统凭借其具有高吞吐、强扩展、高并发、低延迟及灵活部署等特点，大大促进了互联网的飞速发展，给企业带来了巨大的收益。而作为分布式系统中关键的组件——分布式中间件，也起到了必不可少的作用。它是一种独立的基础系统软件或者服务程序，处于操作系统软件与用户的应用软件中间，可作为独立的软件系统运转。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作为枢纽的中间件也从“集中式”发展为“分布式”，如基于Redis的分布式缓存、基于RabbitMQ的分布式消息中间件、基于Elasticsearch的分布式全文搜索引擎、基于ZooKeeper的分布式锁</p>
</blockquote>
</blockquote>
<h3 id="◆-1-1-分布式系统概述" tabindex="-1"><a class="header-anchor" href="#◆-1-1-分布式系统概述" aria-hidden="true">#</a> ◆ 1.1 分布式系统概述</h3>
<blockquote>
<blockquote>
<p>程序A与程序B分别运行在两台计算机上，它们相互协作完成同一个功能。从理论上讲，这两个程序所组成的系统，就可以称作是“分布式系统”。当然，这两个程序可以是不同的程序，也可以是相同的程序。如果是相同的程序，我们又可以称之为“集群”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式系统出现之前，市面上几乎所有的软件系统都是集中式的，即所谓的单机系统。软件、硬件及各种组件高度耦合组成了单机架构。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以Web应用为例，主要包含以下5个历程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1．单点集中式Web应用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>单点集中式Web应用系统架构总体上来看还是比较简单的，一般以后台管理应用为主，比如 CRM和 OA系统等。这种系统架构有一个很明显的特点就是数据库（比如MySQL）及应用的War包都是共同部署在同一台服务器上，文件的上传存储也是上传到本台机器上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>单点集中式Web应用系统架构的优点是适用于小型项目，发布便捷（只需要打包成War包，并进行解压即可），对于运维的工作量也比较小。其缺点在于若是该台服务器宕机了，整个应用将无法访问。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2．应用与文件服务及数据库单独拆分</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>随着时间的推移，数据库及文件的数据量越来越多，由于服务器的容量是有限的，原有系统架构已经不足以支撑，此时需要将Web应用、数据库、文件存储服务拆分出来作为独立的服务，以此来避免存储瓶颈</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>应用与文件服务及数据库单独拆分这种系统架构，一个明显的特点就是三个服务独立部署，不同服务器宕机了，其他的仍然可以使用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3．引入缓存与集群，改善系统整体性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当请求并发量上去了，而单台Web服务器（比如Tomcat）不足以支撑应用的时候，此时我们会考虑引入缓存及集群，以改善系统的整体性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 引入缓存：把大量用户的读请求引导至缓存（如Redis）中，而写操作仍然直接写到数据库DB中。这点性能上的优化，可以将数据库的一部分数据或者系统经常需要访问的数据（如热点数据）放入缓存中，减少数据库的访问压力，提高用户并发请求性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 引入集群：目的在于减少单台服务器的压力。可以通过部署多台Tomcat来减少单机带来的压力，常见手段是Nginx+Lvs，最终是多台应用服务器构成了负载均衡，减少了单机的负载压力（需要注意的是，对于用户的Session需要调整为使用Redis或者Spring-Session进行管理）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4．数据库读写分离，并提供反向代理及CDN加速访问服务</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在大多数互联网应用系统中，用户的读请求数量往往大于写请求，它们会相互竞争，在这个时候往往写操作会受到影响，导致数据库出现存储瓶颈（可以参考春节抢票高峰期12306的访问情况）。因此会对数据库采取读写分离，从而提高数据库的存储性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了加速网站的访问速度，尤其是加速静态资源的访问，会将系统的大部分静态资源存放到CDN中，并加入反向代理的配置，从而减少访问网站时直接去服务器读取静态数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>DB的读写分离将有效地提高数据库的存储性能，而加入CDN与反向代理将加速系统的访问速度</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>5．分布式文件系统与分布式数据库</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>经过统计与监测，发现系统对于某些表有大量的请求，此时为了减少DB的压力，我们会进行分库分表，即根据业务来拆分数据库</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式系统出现之前，软件系统都是集中式的，俗称单机系统。在很长一段时期，单机系统通过不断升级“程序”或者相关硬件，就能满足不断增长的性能需求，然而，随着互联网的飞速发展，高吞吐、高并发、低延迟逐渐成为“刚需”，单凭“生硬”地不断升级已无能为力，于是分布式系统“应需求而生”。总的来说，分布式系统具有以下5个特性：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 内聚性和透明性：分布式系统是建立在网络之上的软件系统，所以具有高度的内聚性和透明性。● 可扩展性：分布式系统可以随着业务的增长动态扩展自己的系统组件，从而提高系统整体的处理能力。通常有两种方式：其一，优化系统的性能或者升级硬件，即垂直扩展；其二，增加计算单元（如服务器等）以扩展系统的规模，即水平扩展。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 可用与可靠性：说直白点，可靠性量化的指标是给定周期内系统无故障运行的平均时间，而可用性量化的指标是给定周期内系统无故障运行的总时间；一个是“平均”时间，一个是“总”时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 高性能：不管是单机系统还是分布式系统，性能始终是关键指标。不同的系统对性能的衡量指标是不同的，最常见的有“高并发”（即单位时间内处理的任务越多越好和“低延迟”（即每个任务的平均处理时间越少越好）。分布式系统的设计初衷便是利用更多的机器，实现更强大的计算和存储能力，即实现高性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 一致性：分布式系统为了提高可用性和可靠性，一般会引入冗余（副本）。为了保证这些节点上的状态一致，分布式系统必须解决一致性问题，其实就是在多个节点集群部署下，如何保证多个节点在给定的时间内，操作或者存储的数据只有一份。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>分布式系统常见问题</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1．网络并没有那么可靠分布式系统中，节点间本质上是通过网络通信，而网络有些时候并没有那么可靠。常见的网络问题有网络延时、丢包和消息丢失等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2．节点故障无法避免当分布式的节点数目达到一定规模后，整个系统出现故障的概率将变高。而分布式系统需要保证故障发生时，系统仍然是可用的，即在某个或者某些节点发生故障的情况下，需要将该节点所负责的计算和存储任务转移到其他节点。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-2-分布式中间件概述" tabindex="-1"><a class="header-anchor" href="#◆-1-2-分布式中间件概述" aria-hidden="true">#</a> ◆ 1.2 分布式中间件概述</h3>
<blockquote>
<blockquote>
<p>Redis、RabbitMQ、ZooKeeper、Elasticsearch、Nginx中的一种吧，它们都是常用的中间件，可实现缓存、消息队列、分布式锁、全文搜索及负载均衡等功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redisson是“架设在Redis基础上的一个Java驻内存数据网络（In-Memory DataGrid）”，可以简单地理解为Redisson是Redis的一个升级版，它充分利用了Redis键值对数据库提供的一系列优势，为使用者提供了一系列具有分布式特性的常用工具类。Redisson的出现使得原本作为协调单机多线程并发程序的工具包，获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度，同时也简化了分布式环境中程序相互之间的协作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis在分布式系统应用过程中出现的问题，在Redisson这里能够得到很好的解决，比如关于分布式锁的处理，Redisson的处理方式则更为安全、稳定与高效</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ能够起到很好的作用，比如接口限流，从而降低应用服务器的压力；比如消息异步分发，从而降低系统的整体响应时间。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ZooKeeper是一个开源的分布式应用程序协调服务，可以为分布式应用提供一致性服务，简称ZK。其提供的功能服务包括配置维护、域名服务、分布式同步等；提供的接口则包括分布式独享锁、选举、队列等。</p>
</blockquote>
</blockquote>
<h3 id="◆-1-3-本书核心知识要点" tabindex="-1"><a class="header-anchor" href="#◆-1-3-本书核心知识要点" aria-hidden="true">#</a> ◆ 1.3 本书核心知识要点</h3>
<blockquote>
<blockquote>
<p>采用Redis和RabbitMQ的典型应用场景“商城系统高并发抢单”，介绍商城高并发抢单的整体业务流程，以及如何采用Redis和RabbitMQ的相关技术实现高并发抢单的核心业务逻辑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式系统中，“高并发”所产生的诸多问题是很常见的，其中比较典型的问题在于高并发抢占共享资源而导致并发安全的问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以多种实现方式（数据库乐观锁/悲观锁、Redis原子操作、ZooKeeper分布式锁及Redisson分布式锁）配备实际代码实现分布式锁。</p>
</blockquote>
</blockquote>
<h2 id="◆-第2章-搭建微服务项目" tabindex="-1"><a class="header-anchor" href="#◆-第2章-搭建微服务项目" aria-hidden="true">#</a> ◆ 第2章 搭建微服务项目</h2>
<blockquote>
<blockquote>
<p>典型的开发工具包括Intellij IDEA、Navicat Premium及Postman等，开发软件包括JDK、Maven和MySQL</p>
</blockquote>
</blockquote>
<h3 id="◆-2-1-spring-boot概述" tabindex="-1"><a class="header-anchor" href="#◆-2-1-spring-boot概述" aria-hidden="true">#</a> ◆ 2.1 Spring Boot概述</h3>
<blockquote>
<blockquote>
<p>Spring Boot是Spring“全家桶”中的一员，其设计目的是用来简化Spring应用中烦琐的搭建及开发过程，它只需要使用极少的配置，就可以快速得到一个正常运行的应用程序，开发人员从此不再需要定义样板化的配置！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 从搭建的角度看，Spring Boot可以帮助开发者快速搭建企业级应用，借助开发工具如IntelliJ IDEA，几乎只需要几个步骤就能简单地构建一个项目。● 从整合第三方框架的角度看，传统的Spring应用如果需要整合第三方框架，则需要加入大量的XML配置文件，并配置很多晦涩难懂的参数；而对于SpringBoot而言，只需要加入Spring Boot内置的针对第三方框架的“起步依赖”，即内置的jar包即可，不再需要编写大量的样板代码、注释与XML配置。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 从项目运行的角度看，Spring Boot由于内嵌了Servlet容器（如Tomcat），其搭建的项目可以直接打成jar包，并在安装有Java运行环境的机器上采用java -jar xxx.jar的命令直接运行，省去了额外安装及配置Servlet容器的步骤，可以说是非常方便。而且，Spring Boot还能对运行中的应用进行状态监控。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 从开发与部署的角度看，Spring Boot相对于Spring搭建的项目代码和配置文件更少，不再需要对第三方框架的配置而“烦恼”了。项目整体上来看也更加精简，扩展性也变得更强，对于整个团队的开发和维护来说，更大程度地节约了成本。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 由于Spring Boot是Spring家族中的一员，所以对于Spring Boot应用而言，其与Spring生态系统如Spring ORM、Spring JDBC、Spring Data、Spring Security等的集成非常方便、容易；再加上Spring Boot的设计者崇尚“习惯大于配置”的理念，使得Spring Boot应用集成主流框架及Spring生态系统时极为方便、快速，开发者可以更加专注于应用本身的业务逻辑。</p>
</blockquote>
</blockquote>
<h3 id="◆-3-1-redis概述与典型应用场景介绍" tabindex="-1"><a class="header-anchor" href="#◆-3-1-redis概述与典型应用场景介绍" aria-hidden="true">#</a> ◆ 3.1 Redis概述与典型应用场景介绍</h3>
<blockquote>
<blockquote>
<p>各种典型的新型互联网架构应势而生，如面向SOA的系统架构、分库分表的应用架构、微服务/分布式系统架构，以及基于各种分布式中间件的应用架构等层出不穷。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在诸多系统架构实施及对巨大用户流量的分析过程中发现，其实用户的“读”请求远远多于用户的“写”请求，频繁的读请求在高并发的情况下会增加数据库的压力，导致数据库服务器的整体压力上升，这也是早期很多互联网产品在面对高并发时经常出现“响应慢”、“卡住”等用户体验差的原因。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了解决这个问题，许多架构引入了缓存组件，Redis即为其中的一种。它可以很好地将用户频繁需要读取的数据存放至缓存中，减少数据库的I/O（输入/输出）操作，降低了服务器整体的压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>底层采用单线程和多路I/O复用模型，所以Redis的查询速度很快。根据Redis官方提供的数据，它可以实现每秒查询的次数达到10万次，即QPS为100000+，这在某种程度上足以满足大部分的高并发请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis具有以下4种典型的应用场景。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>1．热点数据的存储与展示</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“热点数据”可以理解为大部分用户频繁访问的数据，这些数据对于所有的用户来说，访问将得到同一个结果，比如“微博热搜”（每个用户在同一时刻的热搜是一样的），如果采用传统的“查询数据库”的方法获取热点数据，将大大增加数据库的压力，而降低数据库的读写性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2．最近访问的数据</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户最近访问过的数据记录在数据库中将采用“日期字段”作为标记，频繁查询的实现是采用该日期字段与当前时间做“时间差”的比较查询，这种方式是相当耗时的。而采用Redis的List作为“最近访问的足迹”的数据结构，将大大降低数据库频繁的查询请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3．并发访问对于高并发访问某些数据的情况，Redis可以将这些数据预先装载在缓存中，每次高并发过来的请求则可以直接从缓存中获取，减少高并发访问给数据库带来的压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4．排名“排行榜”在很多互联网产品中也是比较常见的。采用Redis的有序集合（SortedSet）可以很好地实现用户的排名，避免了传统的基于数据库级别的Order By及Group By查询所带来的性能问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis还有诸多应用场景，比如消息队列、分布式锁</p>
</blockquote>
</blockquote>
<h3 id="◆-3-4-redis实战场景之缓存穿透" tabindex="-1"><a class="header-anchor" href="#◆-3-4-redis实战场景之缓存穿透" aria-hidden="true">#</a> ◆ 3.4 Redis实战场景之缓存穿透</h3>
<blockquote>
<blockquote>
<p>“当查询数据库时如果没有查询到数据，则直接返回 Null给前端用户，流程结束”，如果前端频繁发起访问请求时，恶意提供数据库中不存在的Key，则此时数据库中查询到的数据将永远为Null。由于Null的数据是不存入缓存中的，因而每次访问请求时将查询数据库，如果此时有恶意攻击，发起“洪流”式的查询，则很有可能会对数据库造成极大的压力，甚至压垮数据库。这个过程称之为“缓存穿透”</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓存穿透的解决方案</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当查询数据库时如果没有查询到数据，则将 Null返回给前端用户，同时将该Null数据塞入缓存中，并对对应的Key设置一定的过期时间，流程结束</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis缓存的使用在给应用带来整体性能和效率提升的同时，也带来了一定的问题。前面主要介绍了目前比较典型的问题：缓存穿透</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另外两大典型的问题，分别是缓存雪崩和缓存击穿</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）缓存雪崩：指的是在某个时间点，缓存中的Key集体发生过期失效致使大量查询数据库的请求都落在了DB（数据库）上，导致数据库负载过高，压力暴增，甚至有可能“压垮”数据库。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>失效导致的。所以为了更好地避免这种问题的发生，一般的做法是为这些Key设置不同的、随机的TTL（过期失效时间），从而错开缓存中 Key的失效时间点，可以在某种程度上减少数据库的查询压力。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）缓存击穿：指缓存中某个频繁被访问的Key（可以称为“热点Key”），在不停地扛着前端的高并发请求，当这个Key突然在某个瞬间过期失效时，持续的高并发访问请求就“穿破”缓存，直接请求数据库，导致数据库压力在某一瞬间暴增。这种现象就像是“在一张薄膜上凿出了一个洞”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这个问题产生的原因主要是热点的Key过期失效了，而在实际情况中，既然这个Key可以被当作“热点”频繁访问，那么就应该设置这个Key永不过期，这样前端的高并发请求将几乎永远不会落在数据库上。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不管是缓存穿透、缓存雪崩还是缓存击穿，其实它们最终导致的后果几乎都是一样的，即给DB（数据库）造成压力，甚至压垮数据库。而它们的解决方案也都有一个共性，那就是“加强防线”，尽量让高并发的读请求落在缓存中，从而避免直接跟数据库打交道。</p>
</blockquote>
</blockquote>
<h2 id="◆-第4章-redis典型应用场景实战之抢红包系统" tabindex="-1"><a class="header-anchor" href="#◆-第4章-redis典型应用场景实战之抢红包系统" aria-hidden="true">#</a> ◆ 第4章 Redis典型应用场景实战之抢红包系统</h2>
<blockquote>
<blockquote>
<p>设计一款能“扛住”用户高并发请求的抢红包系统。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-1-整体业务流程介绍" tabindex="-1"><a class="header-anchor" href="#◆-4-1-整体业务流程介绍" aria-hidden="true">#</a> ◆ 4.1 整体业务流程介绍</h3>
<blockquote>
<blockquote>
<p>借鉴微信红包的部分业务流及红包随机金额生成算法的思想，设计一款能扛住秒级高并发用户流量的抢红包系统。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个红包系统主要由以下三大部分组成：● 信息流：包括用户操作背后的请求通信和红包信息在不同用户与用户群中的流转等。● 业务流：主要包括发红包、点红包和抢红包等业务逻辑。● 资金流：主要包括红包背后的资金转账和入账等流程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统整体业务模块的划分依据主要来源于对系统整体业务流程的分析和拆分，抢红包系统整体业务流程主要包括发和抢</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>系统包括两大核心业务模块，即发红包模块和抢红包模块，分别对应发红包业务流程和点红包及拆红包业务流程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在系统整体业务操作过程中，将产生各种各样的核心业务数据，这部分数据将由数据操作DB模块存储至数据库中。最后是缓存中间件Redis操作模块，主要用于发红包时缓存红包个数和由随机数算法产生的红包随机金额列表，同时将借助Redis单线程特性与操作的原子性实现抢红包时的锁操作。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-2-数据库表设计与环境搭建" tabindex="-1"><a class="header-anchor" href="#◆-4-2-数据库表设计与环境搭建" aria-hidden="true">#</a> ◆ 4.2 数据库表设计与环境搭建</h3>
<blockquote>
<blockquote>
<p>主要包括3张数据表，即发红包时记录红包相关信息表、发红包时生成的对应随机金额信息表，以及抢红包时用户抢到的红包金额记录表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其他的如日志记录、请求数据记录等也可以根据实际情况添加。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于发红包请求的处理，在本系统中的后端主要是根据用户输入的金额和个数预生成相应的红包随机金额列表，并将红包的总个数及对应的随机金额列表缓存至Redis中，同时将红包的总金额、随机金额列表和红包全局唯一标识串等信息异步记录到相应的数据库表中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于抢红包请求的处理，后端接口首先接收前端用户账号及红包全局唯一标识串等请求信息，并假设用户账号合法性等信息全部校验通过，然后开始处理用户“点红包”的逻辑，主要是从缓存系统中获取当前剩余红包的个数，根据红包个数是否大于0判断是否仍然还有红包。假设剩余红包个数大于0，则开始处理用户“拆红包”的逻辑，这个逻辑主要是从缓存系统的随机金额队列中弹出一个红包金额，并根据金额是否为 Null判断是否成功抢到红包。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-3-红包金额-随机生成算法实战" tabindex="-1"><a class="header-anchor" href="#◆-4-3-红包金额-随机生成算法实战" aria-hidden="true">#</a> ◆ 4.3 “红包金额”随机生成算法实战</h3>
<blockquote>
<blockquote>
<p>在本系统中，红包随机金额列表主要是采用“预生成”的方式产生的（这种方式跟微信红包的实时生成方式不一样），即通过给定红包的总金额 M和人员总数 N，采用某种随机数算法生成红包随机金额列表，并将其存至缓存中，用于“拆红包”逻辑的处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>介绍一种在数学与计算机领域比较典型的随机数生成算法，即蒙特卡罗方法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>蒙特卡罗方法是由著名科学家、“计算机科学之父”和“博弈论之父”冯·诺依曼提出的，此种方法又可称为统计模拟法、随机抽样技术，是一种以概率和统计理论方法为基础的计算方法。主要是通过将待求解的问题采用相同的概率模型进行求解，并用电子计算机实现统计模拟或抽样，以获得问题的近似解。蒙特卡罗方法生成随机数的主要步骤如下：（1）针对实际问题建立一个简单且便于实现的概率统计模型，使所求的量恰好是该模型的概率分布或数字特征。（2）基于模型的随机变量建立抽样方法，在计算机上进行模拟测试，抽取足够多的随机数。（3）对模拟实验结果进行统计分析，给出所求解的估计值，这就是最终产生的随机数。（4）必要时，可以通过改进模型以提高估计精度和减少实验费用，最终提高模拟效率。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>直白点讲，这种算法主要是通过建立一个模型，并对模型中的随机变量建立抽样方法，在计算机中反复多次进行模拟测试，最终得到一个或多个估计值，即随机数列表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>二倍均值法简介</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>目前市面上关于红包随机金额的生成算法有许多种，二倍均值法属于其中比较典型的一种。顾名思义，二倍均值算法的核心思想是根据每次剩余的总金额 M和剩余人数 N，执行M/N再乘以2的操作得到一个边界值E，然后制定一个从0到E的随机区间，在这个随机区间内将产生一个随机金额R，此时总金额M将更新为M-R，剩余人数N更新为N-1。再继续重复上述执行流程，以此类推，直至最终剩余人数N-1为0，即代表随机数已经产生完毕。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-4-发红包-模块实战" tabindex="-1"><a class="header-anchor" href="#◆-4-4-发红包-模块实战" aria-hidden="true">#</a> ◆ 4.4 “发红包”模块实战</h3>
<blockquote>
<blockquote>
<p>后端接口在接收到前端用户发红包的请求时，将采用当前的时间戳（纳秒级别）作为红包全局唯一标识串，并将这一标识串返回给前端，后续用户发起“抢红包”的请求时，将会带上这一参数，目的是为了给发出的红包打标记，并根据这一标记去缓存中查询红包个数和随机金额列表等数据。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>采用MVCM的模式开发相应的代码模块。其中，MVC指的是M-Model（模型层，即数据库表相对应的实体类和业务逻辑处理服务类）、V-View（视图层，在本系统中暂不需要用到）、C.Controller （控制层，即接受前端请求参数并执行相应的判断处理逻辑），而最后的M指的是Middleware（中间件层，即采用中间件辅助处理业务逻辑的服务类）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>redis:red:packet:10010:177565921763957，这个字符串数值代表的是存储至缓存系统中随机金额列表List和红包总数Total对应的Key前缀，后续前端发起“抢红包”请求时需要带上这个字符串数值，表示当前用户所抢的红包。值得一提的是，该前缀包含了采用当前时间戳生成的红包全局唯一标识串177565921763957。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-5-抢红包-模块实战" tabindex="-1"><a class="header-anchor" href="#◆-4-5-抢红包-模块实战" aria-hidden="true">#</a> ◆ 4.5 “抢红包”模块实战</h3>
<blockquote>
<blockquote>
<p>“抢红包”业务模块是整个抢红包系统的核心模块，可以说是最关键的环节。当群里的成员看到有人发红包时，正常情况下都会点该红包图样，并由此开启后端处理抢红包请求逻辑的节奏。首先后端接口将会接收红包全局唯一标识串和用户账号id，从缓存系统中取出红包的个数，判断个数是否大于0。如果大于0则表示缓存中仍然有红包，然后从缓存系统的随机金额列表中弹出一个随机金额，判断是否为Null。如果不为Null，则表示当前用户抢到红包了，此时需要更新缓存系统的红包个数并异步记录相关信息到数据库中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）从业务角度分析，抢红包业务模块需要实现两大业务逻辑，包括点红包业务逻辑和拆红包业务逻辑，简单地讲，包含两个“动作”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）从系统架构角度分析，“抢红包”业务模块对应的后端处理逻辑需要保证接口的稳定性、可扩展性和扛高并发性，对于相应接口的设计需要尽可能做到低耦合和服务的高内聚，因而在代码实战过程中，采用的是面向接口和服务进行编程。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）从技术角度分析，抢红包业务模块对应的后端接口需要频繁地访问缓存系统Redis，用于获取红包剩余个数和随机金额列表，进而判断用户点红包、拆红包是否成功。除此之外，在用户每次成功抢到红包之后，后端接口需要及时更新缓存系统中红包的剩余个数，将相应的信息记入数据库中等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>高并发请求其实本质上是高并发多线程，多线程的高并发如果出现抢占共享资源而不加以控制的话，将会带来各种各样的并发安全问题，数据不一致便是其中典型的一种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>借助高并发压力测试工具 Jmeter模拟大数据量的并发请求，并观察由此产生的问题，以及针对出现的问题进行优化与代码实战。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-6-jmeter压力测试高并发抢红包" tabindex="-1"><a class="header-anchor" href="#◆-4-6-jmeter压力测试高并发抢红包" aria-hidden="true">#</a> ◆ 4.6 Jmeter压力测试高并发抢红包</h3>
<blockquote>
<blockquote>
<p>Apache Jmeter是Apache组织开发的基于Java的压力测试工具。它可以通过产生来自不同类别的压力，模拟实际生产环境中高并发产生的巨大负载，从而对应用服务器、网络或对象整体性能进行测试，并对产生的测试结果进行分析和反馈。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>借助Jmeter工具对高并发抢红包请求进行压力测试</p>
</blockquote>
</blockquote>
<h3 id="◆-4-7-问题分析与优化方案" tabindex="-1"><a class="header-anchor" href="#◆-4-7-问题分析与优化方案" aria-hidden="true">#</a> ◆ 4.7 问题分析与优化方案</h3>
<blockquote>
<blockquote>
<p>对于抢红包系统的抢业务模块来说也是如此。我们确实已经进行了业务模块分析、开发流程梳理、代码实战和自测等操作，也对产生的数据进行了分析和对比，但是却在模拟实际生产环境的过程中暴露出了问题。因为我们并没有考虑“秒级同时并发多线程”的情况，从而导致最终出现的数据不一致或并非自己所预料的结果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当某一时刻的同一用户在“疯狂”地点红包图样时，如果前端不加以控制的话，同一时间的同一个用户将发起多个抢红包请求。当后端接收到这些请求时，将很有可能同时进行“缓存系统中是否有红包”的判断并成功通过，然后执行后面弹出红包随机金额的业务逻辑，导致同一个用户抢到多个红包的情况发生。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其实是后端接口并没有考虑到高并发请求的情况。更深入地讲，其原因在于当前请求还没有处理完核心业务逻辑时，其他同样的请求已经到来，导致后端接口几乎来不及做重复判断的逻辑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>得知问题产生的原因在于：同一时刻多个并发的线程对共享资源进行了访问操作，导致最终出现数据不一致或者结果并非自己所预料的现象，而这其实就是多线程高并发时出现的并发安全问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在传统的单体 Java应用中，为了解决多线程高并发的安全问题，最常见的做法是在核心的业务逻辑代码中加锁操作（同步控制操作），即加Synchronized关键字。然而在微服务、分布式系统架构时代，这种做法是行不通的。因为Synchronized关键字是跟单一服务节点所在的JVM相关联，而分布式系统架构下的服务一般是部署在不同的节点（服务器）下，从而当出现高并发请求时，Synchronized同步操作将显得“力不从心”！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>因而我们需要寻找一种更为高效的解决方案。这种方案既要保证单一节点核心业务代码的同步控制，也要保证当扩展到多个节点部署时同样能实现核心业务逻辑代码的同步控制，这就是“分布式锁”出现的初衷。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>它的出现主要是为了解决分布式系统中高并发请求时并发访问共享资源导致并发安全的问题。目前关于分布式锁的实现有许多种，典型的包括基于数据库级别的乐观锁和悲观锁，以及基于Redis的原子操作实现分布式锁和基于ZooKeeper实现分布式锁等</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis作为一款具有高性能存储的缓存中间件</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis底层架构是采用单线程进行设计的，因而它提供的这些操作也是单线程的，即其操作具备原子性。而所谓的原子性，指的是同一时刻只能有一个线程处理核心业务逻辑，当有其他线程对应的请求过来时，如果前面的线程没有处理完毕，那么当前线程将进入等待状态（堵塞），直到前面的线程处理完毕。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以通过 Redis的原子操作setIfAbsent()方法对该业务逻辑加分布式锁，表示“如果当前的Key不存在于缓存中，则设置其对应的Value，该方法的操作结果返回True；如果当前的Key已经存在于缓存中，则设置其对应的Value失败，即该方法的操作结果将返回False。由于该方法具备原子性（单线程）操作的特性，因而当多个并发的线程同一时刻调用setIfAbsent()时，Redis的底层是会将线程加入“队列”排队处理的。</p>
</blockquote>
</blockquote>
<h3 id="◆-4-8-总结" tabindex="-1"><a class="header-anchor" href="#◆-4-8-总结" aria-hidden="true">#</a> ◆ 4.8 总结</h3>
<blockquote>
<blockquote>
<p>当我们用Jmeter模拟高并发请求对系统的接口进行压力测试时，会出现超出预料的现象，即“同一个用户会抢到多个红包金额”，这在实际情况下显然是不允许出现的。经分析发现，这是一种多线程高并发时产生的并发安全问题，需要对核心业务处理逻辑加同步控制操作，即加分布式锁，最后我们基于Redis的分布式锁解决了上述问题。</p>
</blockquote>
</blockquote>
<h2 id="◆-第5章-消息中间件rabbitmq" tabindex="-1"><a class="header-anchor" href="#◆-第5章-消息中间件rabbitmq" aria-hidden="true">#</a> ◆ 第5章 消息中间件RabbitMQ</h2>
<blockquote>
<blockquote>
<p>缓存中间件 Redis，其主要作用在于提升高并发读请求情况下查询的性能，减少频繁查询数据库的频率，从而降低DB（数据库）服务器的压力。随着用户流量的快速增长，由于传统应用在系统接口和服务处理模块层面仍然沿用“高耦合”和“同步”的处理方式，导致接口由于线程堵塞而延长了整体响应时间，即所谓的“高延迟”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为此，消息中间件 RabbitMQ得到了“重用”</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>它可以通过异步通信等方式降低应用系统接口层面的整体响应时间</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>比如业务服务模块解耦、异步通信、高并发限流、超时业务和数据延迟处理等</p>
</blockquote>
</blockquote>
<h3 id="◆-5-1-rabbitmq简介" tabindex="-1"><a class="header-anchor" href="#◆-5-1-rabbitmq简介" aria-hidden="true">#</a> ◆ 5.1 RabbitMQ简介</h3>
<blockquote>
<blockquote>
<p>RabbitMQ还是一款开源并实现了高级消息队列协议（即AMQP）的消息中间件，既支持单一节点的部署，同时也支持多个节点的集群部署，在某种程度上完全可以满足目前互联网应用或产品高并发、大规模和高可用性的要求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ作为一款能实现高性能存储分发消息的分布式中间件，具有异步通信、服务解耦、接口限流、消息分发和业务延迟处理等功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>接口限流和消息分发以“商城用户抢购商品”为例，商城为了吸引用户流量，会不定期地举办线上商城热门商品的抢购活动，当抢购活动开始之前，用户犹如“守株待兔”一般会盯在屏幕前等待活动的开始，当活动开始之时，由于商品数量有限，所有的用户几乎会在同一时刻单击“抢购”按钮开始进行商品的抢购</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>毫无疑问，在抢购活动开始的那一刻，将会产生巨大的用户抢购流量，这些请求几乎在同一时间到达后端系统接口。而在正常的情况下，后端系统接口在接收到前端发送过来的请求时，会执行如下流程：首先会校验用户和商品等信息的合法性，当校验通过之后，会判断当前商品的库存是否充足，如果充足，则代表当前用户将能成功抢购到商品，最后将用户抢购成功的相关数据记入数据库，并异步通知用户抢购成功，尽快进行付款等。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>后端系统接口在处理用户抢购的整体业务流程“太长”，而在这整块业务逻辑的处理过程中，存在着先取出库存再进行判断，最后再进行减1的更新操作，在高并发的情况下，这些业务操作会给系统带来诸多的问题。比如，商品超卖、数据不一致、用户等待时间长、系统接口挂掉等现象。因而这种单一的处理流程只适用于同一时刻前端请求量很少的情况，而对于类似商城抢购、商品秒杀等某一时刻产生高并发请求的情况则显得力不从心。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>消息中间件 RabbitMQ的引入可以大大地改善系统的整体业务流程和性能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ的引入主要是从以下两个方面来优化系统的整体处理流程：（1）接口限流：当前端产生高并发请求时，并不会像“无头苍蝇”一样立即到达后端系统接口，而是像每天上班时的地铁限流一样，将这些请求按照先来后到的规则加入RabbitMQ的队列，即在某种程度上实现“接口限流”。（2）消息异步分发：当商品库存充足时，当前抢购的用户将可以抢到该商品，之后会异步地通过发送短信、发送邮件等方式通知用户抢购成功，并告知用户尽快付款，即在某种程度上实现了“消息异步分发”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3．业务延迟处理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ除了可以实现消息实时异步分发之外，在某些业务场景下，还能实现消息的延时和延迟处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>比如用户抢到火车票后，由于各种原因而迟迟没有付款，过了30分钟后仍然没有支付车票的价格，导致系统自动取消该笔订单。类似这种“需要延迟一定的时间后再进行处理”的业务在实际生产环境中并不少见，传统企业级应用对于这种业务的处理，是采用一个定时器定时去获取没有付款的订单，并判断用户的下单时间距离当前的时间是否已经超过30分钟，如果是，则表示用户在30分钟内仍然没有付款，系统将自动使该笔订单失效并回收该张车票</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果定时器频繁地从数据库中获取“未付款”状态的订单，其数据量之大将难以想象，而且如果大批量的用户在30分钟内迟迟不付款，那从数据库中获取的数据量将一直在增长，当达到一定程度时，将给数据库服务器和应用服务器带来巨大的压力，更有甚者将直接压垮服务器，导致抢票等业务全线崩溃，带来的直接后果将不堪设想！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>而消息中间件RabbitMQ的引入，不管是从业务层面还是应用的性能层面，都大大得到了改善</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>从优化流程中可以看出，RabbitMQ的引入主要是替代了传统处理流程的“定时器处理逻辑”，取而代之的是采用RabbitMQ的延迟队列进行处理。延迟队列，顾名思义指的是可以延迟一定的时间再处理相应的业务逻辑。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ的这一特性在某些场景下确实能起到很好的作用，比如上面讲的“成功抢到票后30分钟内未付款的处理流程”就是比较典型的一种。除此之外，商城购物时“单击去付款而迟迟没有在规定的时间内支付”的流程的处理、点外卖时“下单成功后迟迟没有在规定的时间内付款”的流程的处理等都是实际生产环境中比较典型的场景。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Spring内置的基于ApplicationEvent和ApplicationListener的事件驱动模型。Spring的事件驱动模型，顾名思义是通过“事件驱动”的方式实现业务模块之间的交互，交互的方式有同步和异步两种，某种程度上，“事件”也可以看作是“消息”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在传统企业级Spring应用系统中，正是通过事件驱动模型实现信息的异步通信和业务模块的解耦</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Spring的事件驱动模型主要由3部分组成，包括发送消息的生产者、消息（或事件）和监听接收消息的消费者</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ的消息模型时，会发现“生产者+消息+交换机+路由对应队列+消费者”跟Spring的事件驱动模型出奇地相似。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-2-spring-boot项目整合rabbitmq" tabindex="-1"><a class="header-anchor" href="#◆-5-2-spring-boot项目整合rabbitmq" aria-hidden="true">#</a> ◆ 5.2 Spring Boot项目整合RabbitMQ</h3>
<blockquote>
<blockquote>
<p>RabbitMQ的核心要点其实在于消息、消息模型、生产者和消费者，而RabbitMQ的“消息模型”有许多种，包括基于FanoutExchange的消息模型、基于DirectExchange的消息模型和基于TopicExchange的消息模型等，这些消息模型都有一个共性，那就是它们几乎都包含交换机、路由和队列等基础组件。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 生产者：用于产生、发送消息的程序。● 消费者：用于监听、接收、消费和处理消息的程序。● 消息：可以看作是实际的数据，如一串文字、一张图片和一篇文章等。在RabbitMQ底层系统架构中，消息是通过二进制的数据流进行传输的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 队列：消息的暂存区或者存储区，可以看作是一个“中转站”。消息经过这个“中转站”后，便将消息传输到消费者手中。● 交换机：同样也可以看作是消息的中转站点，用于首次接收和分发消息，其中包括Headers、 Fanout、Direct和Topic这4种。● 路由：相当于密钥、地址或者“第三者”，一般不单独使用，而是与交换机绑定在一起，将消息路由到指定的队列。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ的消息模型主要是由队列、交换机和路由三大基础组件组成</p>
</blockquote>
</blockquote>
<h3 id="◆-5-3-rabbitmq多种消息模型实战" tabindex="-1"><a class="header-anchor" href="#◆-5-3-rabbitmq多种消息模型实战" aria-hidden="true">#</a> ◆ 5.3 RabbitMQ多种消息模型实战</h3>
<blockquote>
<blockquote>
<p>基于FanoutExchange的消息模型实战FanoutExchange，顾名思义，是交换机的一种，具有“广播消息”的作用，即当消息进入交换机这个“中转站”时，交换机会检查哪个队列跟自己是绑定在一起的，找到相应的队列后，将消息传输到相应的绑定队列中，并最终由队列对应的消费者进行监听消费。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>生产者生产的消息将首先进入交换机，并由交换机中转至绑定的N条队列中，其中 N≥1，并最终由队列所绑定的消费者进行监听接收消费处理。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于FanoutExchange消息模型的介绍和代码部分已经讲解完毕。此种消息模型适用于“业务数据需要广播式传输”的场景，比如“用户操作写日志”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当用户在系统中做了某种操作之后，需要在本身业务系统中将用户的操作内容记入数据库，同时也需要单独将用户的操作内容传输到专门的日志系统进行存储（以便后续系统进行日志分析等），这个时候，可以将用户操作的日志封装成实体对象，并将其序列化后的JSON数据充当消息，最终采用基于广播式的交换机，即FanoutExchange消息模型进行发送、接收和处理，从而实现相应的业务功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于DirectExchange的消息模型实战</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>具有“直连传输消息”的作用，即当消息进入交换机这个“中转站”时，交换机会检查哪个路由跟自己绑定在一起，并根据生产者发送消息指定的路由进行匹配，如果能找到对应的绑定模型，则将消息直接路由传输到指定的队列，最终由队列对应的消费者进行监听消费。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>它需要严格意义上的绑定，即需要且必须要指定特定的交换机和路由，并绑定到指定的队列中。或许是由于这种严格意义上的要求，基于DirectExchange消息模型在实际生产环境中具有很广泛的应用</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>几乎90%的业务场景中，凡是需要RabbitMQ实现消息通信的，都可以采用DirectExchange消息模型实现</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>TopicExchange也是 RabbitMQ交换机的一种，是一种“发布-主题-订阅”式的交换机</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>TopicExchange消息模型同样是由交换机、路由和队列严格绑定构成，与前面介绍的另外两种消息模型相比，最大的不同之处在于其支持“通配式”的路由，即可以通过为路由的名称指定特定的通配符“<em>”和“#”，从而绑定到不同的队列中。其中，通配符“</em>”表示一个特定的“单词”，而通配符“#”则可以表示任意的单词（可以是一个，也可以是多个，也可以没有）。某种程度上讲“#”通配符表示的路由范围大于等于“*”通配符表示的路由范围，即前者可以包含后者。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当这种消息模型的路由名称包含“<em>”时，由于“</em>”相当于一个单词，因而此时此种消息模型将降级为“基于DirectExchange的消息模型”；当路由名称包含“#”时，由于#相当于0个或者多个单词，因而此时此种消息模型将相当于“基于FanoutExchange的消息模型”，即此时绑定的路由将不起作用了，哪怕进行了绑定，也不再起作用！</p>
</blockquote>
</blockquote>
<h3 id="◆-5-4-rabbitmq确认消费机制" tabindex="-1"><a class="header-anchor" href="#◆-5-4-rabbitmq确认消费机制" aria-hidden="true">#</a> ◆ 5.4 RabbitMQ确认消费机制</h3>
<blockquote>
<blockquote>
<p>RabbitMQ之所以被称为高性能、高可用的分布式消息中间件，不仅是因为它拥有消息异步通信、业务服务模块解耦、接口限流、消息延迟处理等多种功能特性，更多的是因为RabbitMQ在消息的发送、传输和接收的过程中，可以保证消息成功发送、不会丢失，以及被确认消费。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于“消息成功发送”，主要是针对生产者的生产确认机制而言的（即Publisher的Confirm机制），而对于“消息不丢失”和“被确认消费”，则主要是面向消费者的确认消费而言的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）发送出去的消息不知道到底有没有发送成功？即采用RabbitTemplate操作组件发送消息时，开发者自认为消息已经发送出去了，然而在某些情况下（比如交换机、路由和队列绑定构成的消息模型不存在时）却很有可能是发送失败的。（2）由于某些特殊的原因，RabbitMQ服务出现了宕机和崩溃等问题，导致其需要执行重启操作。如果此时队列中仍然有大量的消息还未被消费，则很有可能在重启RabbitMQ服务的过程中发生消息丢失的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（3）消费者在监听消费处理消息的时候，可能会出现监听失败或者直接崩溃等问题，导致消息所在的队列找不到对应的消费者而不断地重新入队列，最终出现消息被重复消费的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>针对这些常见的问题，RabbitMQ给开发者提供了相应的策略，而这些策略在某种程度上就是为了保证消息的高可用和能被准确消费。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（1）针对第一种情况，RabbitMQ会要求生产者在发送完消息之后进行“发送确认”，当确认成功时即代表消息已经成功发送出去了</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）针对第二种情况，即如何保证 RabbitMQ队列中的消息“不丢失”;RabbitMQ则是强烈建议开发者在创建队列、交换机时设置其持久化参数为true，即durable参数取值为true。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ的消息“确认消费”模式有3种，它们定义在AcknowledgeMode枚举类中，分别是NONE、AUTO和MANUAL，这3种模式的含义、作用和应用场景是不同的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先介绍 NONE消费模式。顾名思义，NONE指的是“无须确认”机制，即生产者将消息发送至队列，消费者监听到该消息时，无须发送任何反馈信息给RabbitMQ服务器。这就好比“用户禁止某个App应用的通知提醒”是一个道理，当App有重大更新信息时，虽然App后端会给用户异步推送消息，但是由于用户进行了相关设置，因而虽然消息已经发送出去了，但却迟迟得不到用户的“查看”或者“确认”等反馈信息，好像消息“石沉大海了一般”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>AUTO消费模式。顾名思义，AUTO指的是“自动确认”机制，即生产者将消息发送至队列，消费者监听到该消息时，需要发送一个 AUTO ACK的反馈信息给RabbitMQ服务器，之后该消息将在 RabbitMQ的队列中被移除。其中，这种发送反馈信息的行为是 RabbitMQ“自动触发”的，即其底层的实现逻辑是由RabbitMQ内置的相关组件实现自动发送确认反馈信息。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>MANUAL消费模式。它是一种“人为手动确认消费”机制，即生产者将消息发送至队列，消费者监听到该消息时需要手动地“以代码的形式”发送一个ACK的反馈信息给RabbitMQ服务器，之后该消息将在RabbitMQ的队列中被移除，同时告知生产者，消息已经成功发送并且已经成功被消费者监听消费了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>而对于一些在消息、业务数据传输方面要求比较严格的场景，如手机话费充值业务中的话费数据、电商平台支付过程中的支付金额、游戏应用冲金币过程中的金币等，NONE消费模式显得力不从心。毫无疑问，此时应当使用基于AUTO或者基于MANUAL机制的消费模式辅助实现，从而保证数据不丢失、核心业务处理逻辑只做一次等。</p>
</blockquote>
</blockquote>
<h3 id="◆-5-6-总结" tabindex="-1"><a class="header-anchor" href="#◆-5-6-总结" aria-hidden="true">#</a> ◆ 5.6 总结</h3>
<blockquote>
<blockquote>
<p>总的来说，RabbitMQ目前在企业级应用、微服务系统中充当着重要的角色，它可以通过异步通信等方式降低应用系统接口层面整体的响应时间，对传统应用高内聚的多服务模块进行服务模块的解耦等。</p>
</blockquote>
</blockquote>
<h2 id="◆-第6章-死信队列-延迟队列实战" tabindex="-1"><a class="header-anchor" href="#◆-第6章-死信队列-延迟队列实战" aria-hidden="true">#</a> ◆ 第6章 死信队列/延迟队列实战</h2>
<blockquote>
<blockquote>
<p>延时、延迟处理指定的业务逻辑，在实际生产环境中还是很常见的。比如，商城平台订单超过30分钟未支付将自动关闭；商城订单完成后，如果用户一直未评价，5天后将自动好评；会员到期前15天和到期前3天分别发送短信提醒；延迟1小时发送邮件；延迟30分钟提交报表等。针对这些业务场景，分布式消息中间件 RabbitMQ提供了“死信队列/延迟队列”，用以实现相应的业务逻辑。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-1-死信队列概述" tabindex="-1"><a class="header-anchor" href="#◆-6-1-死信队列概述" aria-hidden="true">#</a> ◆ 6.1 死信队列概述</h3>
<blockquote>
<blockquote>
<p>在某些业务场景中，有些业务数据对应的消息在进入队列后不希望立即被处理，而是要求该消息可以“延迟”一定的时间，再被消费者监听消费处理，这便是“死信队列/延迟队列”出现的初衷。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在传统企业级应用系统中，实现消息、业务数据的延迟处理一般是通过开启定时器的方式，轮询扫描并获取数据库表中满足条件的业务数据记录，然后比较数据记录的业务时间和当前时间。如果当前时间大于记录中的业务时间，则说明该数据记录已经超过了指定的时间而未被处理，此时需要执行相应的业务逻辑，比如失效该数据记录、发送通知信息给指定的用户等。对于这种处理方式，定时器是每隔一定的时间频率不间断地去扫描数据库表，并不断地获取满足业务条件的数据，直到手动关闭该定时器（如果不关闭的话，定时器开启的线程将一直运行下去）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ提供的“死信队列”这一功能特性在实际生产环境中确实能起到很好的作用，比如上面讲的“成功抢到票后30分钟内未付款的处理流程”就是比较典型的一种。除此之外，商城购物时“单击去付款而迟迟没有在规定的时间内支付”流程的处理；App点外卖时“下单成功后迟迟没有在规定的时间内付款”流程的处理；用户提交会员注册信息后“30分钟内没有进行邮箱或短信验证时发送提醒”等，这些都是实际生产环境中比较典型的场景。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>下面以“商城用户选购商品后去支付时订单超时未付款”的场景为案例，介绍RabbitMQ死信队列在实际生产环境中的应用。当用户在商城平台看到满意的商品时，单击“加入购物车”按钮，即可将商品加入自己的购物车内。选购完毕，单击去付款按钮后，将会跳转到支付页面，此时系统会为用户生成一笔对应购物车中商品的订单，并将该订单的状态设置为0，即代表“未付款”，同时将该订单的id或者订单编号塞入 RabbitMQ的延迟队列中，并设置延迟时间为30分钟。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果用户在30分钟内选择了某种付款方式并进行了付款，则系统将更新该订单id对应的订单支付状态为1，即已付款，同时更新订单中所包含的商品对应的库存；如果用户在30分钟内迟迟未付款，则RabbitMQ的延迟队列对应的消费者将会在30分钟后监听到该订单的id，根据该订单的id查询数据库的订单数据表，如果该订单的付款状态仍然为0 （即未付款），则表示用户已经超过30分钟而仍然未付款，此时则需要使该笔订单失效，同时更新回退商品库存。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-2-rabbitmq死信队列实战" tabindex="-1"><a class="header-anchor" href="#◆-6-2-rabbitmq死信队列实战" aria-hidden="true">#</a> ◆ 6.2 RabbitMQ死信队列实战</h3>
<blockquote>
<blockquote>
<p>相对于传统定时器的轮询处理方式，死信队列具有占用系统资源少（比如不需要再轮询数据库获取数据，减少DB层面资源的消耗）、人为干预很少（只需要搭建好死信队列消息模型，就可以不需要再去干预了），以及自动消费处理（当指定的延迟时间一到，消息将自动被路由到实际的队列进行处理）等优势。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>与普通的队列相比，死信队列同样也具有消息、交换机、路由和队列等专有名词，只不过在死信队列里增加了另外3个成员，即DLX、DLK和TTL。其中DLX跟DLK是必需的成员，而TTL则是可选、非必需的。下面着重介绍一下这3个成员：● DLX，即Dead Letter Exchange，中文为死信交换机，是交换机的一种类型，只是属于特殊的类型。● DLK，即Dead Letter Routing-Key，中文为死信路由，同样也是一种特殊的路由，主要是跟DLX组合在一起构成死信队列。● TTL，即Time To Live，指进入死信队列中的消息可以存活的时间。当TTL一到，将意味着该消息“死了”，从而进入下一个“中转站”，等待被真正的消息队列监听消费。</p>
</blockquote>
</blockquote>
<h3 id="◆-6-3-典型应用场景实战之商城平台订单支付超时" tabindex="-1"><a class="header-anchor" href="#◆-6-3-典型应用场景实战之商城平台订单支付超时" aria-hidden="true">#</a> ◆ 6.3 典型应用场景实战之商城平台订单支付超时</h3>
<blockquote>
<blockquote>
<p>由于“用户下单”这种业务场景具有时效性，因而可以在处理用户下单的业务逻辑中，将“超时时间”即 TTL设置为死信队列的组成成分，将“下单记录id”充当消息发送至死信队列中。然后只需要在“真正队列”对应的消费者中监听消费该消息，当消费者能监听到消息时，即代表着该下单记录已经超过了30分钟。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>此时可以根据获取到的消息，即“下单记录id”，作为查询条件前往数据库表中查询相应的记录。如果该下单记录的支付状态为“未付款”或者“已保存”，则代表该用户下单记录已经支付超时了，此时需要将该记录更新为失效状态；如果该下单记录的支付状态为“已付款”，则代表该用户已经在30分钟内成功支付了该笔订单。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 用户下单：顾名思义，该业务流程主要用于实现用户单击“去结算”或者“去支付”按钮时，在数据库相关数据表中插入一笔用户下单记录，并设置支付状态为“已保存”。● 死信队列发送和延迟监听下单记录：这一业务流程指的是用户下单成功之后，将下单记录id充当消息异步发送至死信队列中，最终在真正的队列对应的消费者中实现自动监听消费超时支付的消息，即“下单记录id”。● 更新用户下单记录状态：该业务流程主要的职责在于消费者监听到“下单记录id”消息之后，前往数据库查询相应的记录，并判断该下单记录的支付状态是否仍为“已保存”。如果该支付状态仍然为“已保存”状态，则表示该用户经过了指定的时间依旧没有付款，此时系统需要在数据库中将该笔订单的状态更新为“已失效”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>RabbitMQ建议开发者在创建队列、交换机和路由及其绑定等相关组件时，相应属性的设置需要再三斟酌。如果真的是调整相应组件的特性，可以通过以下两种方式进行调整：● 在不影响线上生产环境数据传输的情况下，直接在RabbitMQ后端控制台调整相应的组件属性，比如交换机和路由的绑定等；● 在不影响线上生产环境数据传输的情况下，可以通过代码层面调整相应组件的属性，只不过需要先将RabbitMQ后端控制台要修改的组件删除，然后在代码层面调整完毕之后立即运行项目，即可重新在RabbitMQ后端控制台创建新的队列。</p>
</blockquote>
</blockquote>
<h2 id="◆-第7章-分布式锁实战" tabindex="-1"><a class="header-anchor" href="#◆-第7章-分布式锁实战" aria-hidden="true">#</a> ◆ 第7章 分布式锁实战</h2>
<blockquote>
<blockquote>
<p>为了应对某些业务场景下产生的高并发请求，通常一个子系统会部署多份实例，并采用某种均衡机制“分摊”处理前端用户的请求，此种方式俗称“集群”。事实证明，此种分布式、集群部署的方式确实能给企业级应用系统带来性能和效率上的提升，从而给企业业务规模带来可扩展的收益。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>也带来了一些棘手的问题，其中比较典型的问题是高并发场景下多个线程并发访问、操作共享资源时，出现数据不一致的现象。针对这类问题，业界普遍采取的方式是采用“分布式锁”加以解决</p>
</blockquote>
</blockquote>
<h3 id="◆-7-1-分布式锁概述" tabindex="-1"><a class="header-anchor" href="#◆-7-1-分布式锁概述" aria-hidden="true">#</a> ◆ 7.1 分布式锁概述</h3>
<blockquote>
<blockquote>
<p>在传统单体应用时代，“并发访问、操作共享资源”的场景并不少见。由于那时还没有“分布式”的概念，因而当多个线程并发访问、操作共享资源时，往往是通过加同步互斥锁的机制进行控制，这种方式在很长一段时间内确实能起到一定的作用。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>随着用户、数据量的增长，企业应用为了适应各种变化，不得不对传统单一的应用系统进行拆分并作分布式部署，而此种分布式系统架构部署方案的落地在带来性能和效率上提升的同时也带来了一些问题，即传统采取加锁的方式将不再起作用。这是因为集群、分布式部署的服务实例一般是部署在不同机器上的，在分布式系统架构下，此种资源共享将不再是传统的线程共享，而是跨JVM进程之间资源的共享了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“共享资源”的含义。顾名思义，它指的是可以被多个线程、进程同时访问并进行操作的数据或者代码块</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>主要是通过对共享资源“账户余额”直接加锁，其原理是这样的：每次并发产生的线程需要对共享资源执行操作之前，比如“存钱”或者“取钱”操作，会要求当前线程获取该共享资源的同步锁，如果能获取成功，则执行相应的操作，如果获取失败，该线程将进入堵塞、等待的状态，直到其他线程释放了对该共享资源的同步锁，才能执行相应的操作，否则将一直进入等待状态。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不管是采用Synchronized关键字还是并发操作类Lock等工具的方式，控制并发线程对“共享资源”的访问，它终归只适用于单体应用或者是单一部署的服务实例，而对于分布式部署的系统或者集群部署的服务实例，此种方式将显得力不从心。这是因为这种方式的“锁”很大程度上需要依赖应用系统所在的JDK，像Synchronized、并发操作工具类Lock等都是Java提供给开发者的关键字或者工具。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>而在分布式系统时代，许多服务实例或者系统是分开部署的，它们将拥有自己独立的Host（主机），独立的JDK，导致应用系统在分布式部署的情况下，这种控制“并发线程访问共享资源”的机制将不再起作用。此时的“并发访问共享资源”将演变为“跨 JVM进程之间的访问共享资源”，因而为了解决这种问题，“分布式锁”诞生了！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于分布式锁的设计与使用，业界普遍有几点要求</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 排他性：这一点跟单体应用时代加的“锁”是一个道理，即需要保证分布式部署、服务集群部署的环境下，被共享的资源如数据或者代码块在同一时间内只能被一台机器上的一个线程执行。● 避免死锁：指的是当前线程获取到锁之后，经过一段有限的时间（该时间一般用于执行实际的业务逻辑），一定要被释放（正常情况或者异常情况下释放）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 高可用：指的是获取或释放锁的机制必须高可用而且性能极佳。● 可重入：指的是该分布式锁最好是一把可重入锁，即当前机器的当前线程在彼时如果没有获取到锁，那么在等待一定的时间后一定要保证可以再被获取到。● 公平锁（可选）：这并非硬性的要求，指的是不同机器的不同线程在获取锁时最好保证几率是一样的，即应当保证来自不同机器的并发线程可以公平获取到锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>鉴于这几点要求，目前业界也提供了多种可靠的方式实现分布式锁，其中就包括基于数据库级别的乐观锁、悲观锁、基于Redis的原子操作、基于ZooKeeper的互斥排他锁，以及基于开源框架Redisson的分布式锁</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 基于数据库级别的乐观锁：主要是通过在查询、操作共享数据记录时带上一个标识字段version，通过version来控制每次对数据记录执行的更新操作。● 基于数据库级别的悲观锁：在这里以MySQL的InnoDB引擎为例，它主要是通过在查询共享的数据记录时加上For Update字眼，表示该共享的数据记录已经被当前线程锁住了（行级别锁、表级别锁），只有当该线程操作完成并提交事务之后，才会释放该锁，从而其他线程才能获取到该数据记录。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 基于Redis的原子操作：主要是通过Redis提供的原子操作SETNX与EXPIRE来实现。SETNX表示只有当Key在Redis不存在时才能设置成功，通常这个Key需要设计为与共享的资源有联系，用于间接地当作“锁”，并采用EXPIRE操作释放获取的锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 基于ZooKeeper的互斥排它锁：这种机制主要是通过ZooKeeper在指定的标识字符串（通常这个标识字符串需要设计为跟共享资源有联系，即可以间接地当作“锁”）下维护一个临时有序的节点列表Node List，并保证同一时刻并发线程访问共享资源时只能有一个最小序号的节点（即代表获取到锁的线程），该节点对应的线程即可执行访问共享资源的操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>介绍分布式锁在实际生产环境中两种典型的应用场景，即“重复提交”和“商城高并发抢单”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用户在前端界面输入相关信息（比如用户名、密码等）之后，“疯狂”地单击注册按钮，此时前端虽然做了一些控制操作（比如“置灰”），却仍然不可避免地存在一些不可控制的因素，导致前端提交了多次重复的、相同的用户信息到系统后端，系统后端相关接口在执行“查询用户名是否存在”和“插入用户信息进数据库”等操作时，由于“来不及”处理线程并发的情况，导致最终出现“用户数据表”中存在两条甚至多条相同的用户信息记录。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>问题出现的根本原因在于“查询用户名是否存在”的操作，当多个线程比如A、B、C同时到达后端接口时，很有可能同时执行“查询用户名是否存在”的操作，而由于用户是首次注册，用户数据表此时还没有该数据记录，因而A、B、C 3个线程很有可能同时得到“用户名不存在”的结果，导致3个线程同时执行了“插入用户信息进数据库”的操作，最终出现数据重复的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“查询用户名是否存在”与“插入用户信息进数据库”这两个操作应当是一个“完整性”的综合操作，对于并发的多线程而言，这个综合操作就是被共享的资源，因而为了控制线程的并发访问，我们需要在综合操作之前加入“分布式锁”，确保高并发下同一时刻只能有一个线程获取到分布式锁。获取成功之后，即可执行综合操作，并在执行完成之后释放该锁！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>2．商城高并发抢单</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当抢购活动开始时，正常情况下，在某一时刻前端会产生巨大的用户流量，当蜂拥而来的用户抢购请求同一时刻到达系统后端时（在这里我们暂且假设接口不会瞬间被压垮），后端接口首先会“查询商品当前的库存”，如果充足，则代表用户可以抢购该商品，同时“商品的库存需要减1”，并最终更新数据库的商品库存表。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在高并发产生多个线程如A、B、C的情况下，假设此时商品库存还有1个，但是由于并发的原因，导致查询商品库存时，3个线程同时获取到的库存为1，都认为库存是充足的，导致3个线程都执行了减1更新的操作，最终库存变为“负数”，即传说中“库存超卖”的情况！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“查库存”“判断库存是否充足”及“库存减1更新”这3个操作应该合在一起，是整个“高并发抢单”的核心业务逻辑，也是多个并发线程访问的“共享资源”。因而为了控制线程的并发访问，避免最终出现库存超卖的现象，我们需要在该组合操作之前加入“分布式锁”，确保高并发下同一时刻只能有一个线程获取到分布式锁，并执行核心的业务逻辑。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-2-基于数据库实现分布式锁" tabindex="-1"><a class="header-anchor" href="#◆-7-2-基于数据库实现分布式锁" aria-hidden="true">#</a> ◆ 7.2 基于数据库实现分布式锁</h3>
<blockquote>
<blockquote>
<p>乐观锁简介</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每次从数据库中获取数据时总认为不会有其他线程对该数据进行修改，因此不会上锁，但是在更新时其会判断其他线程在这之前有没有对该数据进行修改，通常是采用“版本号version”机制进行实现。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“版本号version”机制的执行流程是这样的：当前线程取出数据记录时，会顺带把版本号字段version的值取出来，最后在更新该数据记录时，将该version的取值作为更新的条件。当更新成功之后，同时将版本号version的值加1，而其他同时获取到该数据记录的线程在更新时由于version已经不是当初获取的那个数据记录，因而将更新失败，从而避免并发多线程访问共享数据时出现数据不一致的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>典型的应用场景“用户提现金额”为案例</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当用户在前端多次单击“提现”按钮（可能是恶意的行为，亦或是黑客恶意进行攻击）时，将很有可能出现典型的并发现象，即同一时刻可能会产生多个“提现余额”的并发请求线程。当这些请求到达后端相关接口时，正常情况下，接口会查询账户的余额，并判断当前剩余的金额是否足够被提取，如果足够，则更新当前账户的余额，最终账户余额的值为“账户剩下的金额”减去“申请提现的金额”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>悲观锁简介</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>悲观锁是一种“消极、悲观”的处理方式，它总是假设事情的发生是在最坏的情况，即每次并发线程在获取数据的时候认为其他线程会对数据进行修改，因而每次在获取数据时都会上锁，而其他线程访问该数据的时候就会发生阻塞的现象，最终只有当前线程释放了该共享资源的锁，其他线程才能获取到锁，并对共享资源进行操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在传统的关系型数据库中就用到了很多类似悲观锁的机制，比如行锁、表锁、读锁和写锁等，都是在进行操作之前先上锁。除此之外，Java中的Synchronized关键字和ReentrantLock工具类等底层的实现也是参照了“悲观锁”的思想。对于数据库级别悲观锁的实现，目前Oracle、MySQL数据库是采用如下的伪SQL来实现的：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当高并发产生多个线程如A、B、C时，3个线程同时前往数据库中采用上述的SQL查询共享的数据记录时，由于数据库引擎的作用，同一时刻将只有一个线程如A线程获取到该数据记录的锁（在 MySQL InnoDB引擎中属于“行”记录级别的锁），其他两个线程B和C将处于一直等待的状态，直到A线程对该数据库记录操作完毕，并提交事务之后才会释放锁，之后 B和 C的其中一个线程才能成功获取到锁，并执行相应的操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>当并发请求量比较大的时候，由于产生的每个线程在查询数据的时候都需要上锁，而同一时刻只会有一个线程上锁成功，因此只有当该线程对该共享资源操作完毕并释放锁之后，其他正在等待中的线程才能获取到锁。这种方式将会造成大量的线程发生堵塞的现象，在某种程度上会对DB（数据库）服务器造成一定的压力，从这一角度看，基于数据库级别的悲观锁适用于并发量不大的情况，特别是“读”请求数据量不大的情况。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>总体来说，在高并发产生多线程请求时：（1）对于乐观锁而言，由于采用version版本号的机制实现，因而在高并发产生多线程时，同一时刻将只有一个线程能获取到“锁”并成功操作共享资源，而其他的线程将获取失败，而且是永久性地失败下去，即fail over！从这种角度看，这种方式虽然可以控制并发线程对共享资源的访问，但是却牺牲了系统的吞吐性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>由于乐观锁主要是通过version字段对共享数据进行跟踪和控制，其最终的一个实现步骤是带上version进行匹配、同时执行version+1的更新操作，因而当并发的多线程需要频繁“写”数据库时，是会严重影响数据库性能的。从这种角度看，“乐观锁”其实比较适合于“写少读多”的业务场景。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>（2）对于悲观锁而言，由于是建立在数据库底层搜索引擎的基础之上，并采用select …for update的方式对共享资源加“锁”，因而当产生高并发多线程请求，特别是“读”请求时，将对数据库的性能带来严重的影响，因为在同一时刻产生的多线程中将只有一个线程能获取到锁，而其他的线程将处于堵塞的状态，直到该线程释放了锁。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“悲观锁”的方式如果使用不当，将会产生“死锁”的现象（即两个或者多个线程同时处于等待获取对方的资源锁的状态），因而“悲观锁”其实更适用于“读少写多”的业务场景。</p>
</blockquote>
</blockquote>
<h3 id="◆-7-3-基于redis实现分布式锁" tabindex="-1"><a class="header-anchor" href="#◆-7-3-基于redis实现分布式锁" aria-hidden="true">#</a> ◆ 7.3 基于Redis实现分布式锁</h3>
<blockquote>
<blockquote>
<p>在Redis的知识体系与底层基础架构中，其实并没有直接提供所谓的“分布式锁”组件，而是间接地借助其原子操作加以实现。之所以其原子操作可以实现分布式锁的功能，主要是得益于Redis的单线程机制，即不管外层应用系统并发了N多个线程，当每个线程都需要使用Redis的某个原子操作时，是需要进行“排队等待”的，即在其底层系统架构中，同一时刻、同一个部署节点中只有一个线程执行某种原子操作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可以实现“分布式锁”功能的原子操作主要是SET和EXPIRE操作，从Redis的2.6.x版本开始，其提供的SET命令已经变成了如下格式：[插图]</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在SET命令中，对于Key跟Value，相信读者并不陌生，即所谓的键与值，EX指的是 Key的存活时间，而 NX表示只有当 Key不存在时才会设置其值，XX则表示当Key存在时才会设置Key的值。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>NX机制其实就是用于实现分布式锁的核心，即所谓的SETNX操作。值得一提的是，在使用SETNX操作实现分布式锁功能时，需要注意以下几点事项：</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 使用SETNX命令获取“锁”时，如果操作结果返回0（表示Key及对应的“锁”已经存在，即已经被其他线程所获取了），则获取“锁”失败，反之则获取成功。● 为了防止并发线程在获取“锁”之后，程序出现异常情况，从而导致其他线程在调用SETNX命令时总是返回0而进入死锁状态时，需要为Key设置一个“合理”的过期时间。● 当成功获取到“锁”并执行完成相应的操作之后，需要释放该“锁”。可以通过执行 DEL命令将“锁”删除，而在删除的时候还需要保证所删除的“锁”是当时线程所获取的，从而避免出现误删除的情况！</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis实现分布式锁的核心主要是基于SETNX跟 EXPIRE操作实现的</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>基于Redis的原子操作实现分布式锁的流程主要由3个核心操作构成，第一个核心操作是需要精心设计构造一个跟共享资源或核心业务相关的Key，用于充当调用SETNX操作时的Key；第二个核心操作是采用Redis的操作组件调用SETNX跟EXPIRE操作，用于获取对共享资源的“锁”；最后一个核心操作是在执行完成相应的业务逻辑之后释放该“锁”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redis提供的所有操作和命令均是“原子性”的，所谓的“原子性”指的是一个操作要么全部完成，要么全部不完成，类似于一个整体而不可进行“分割”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于“用户重复提交注册信息”这一业务场景而言，如果不对高并发产生的多线程加以控制的话，将很有可能出现数据库表重复注册相同的用户信息</p>
</blockquote>
</blockquote>
<h3 id="◆-7-4-基于zookeeper实现分布式锁" tabindex="-1"><a class="header-anchor" href="#◆-7-4-基于zookeeper实现分布式锁" aria-hidden="true">#</a> ◆ 7.4 基于ZooKeeper实现分布式锁</h3>
<blockquote>
<blockquote>
<p>ZooKeeper是一款开源的分布式服务协调中间件，是由雅虎研究院相关的研发人员组织开发的。其设计的初衷是开发一个通用的无单点问题的分布式协调框架，采用统一的协调管理方式更好地管理各个子系统，从而让开发者将更多的精力集中在业务逻辑处理上，最终使整个分布式系统看上去就像是一个大型的动物园，而ZooKeeper则正好用来协调分布式环境中的各个子系统。ZooKeeper也因此而得名。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ZooKeeper还是一种典型的分布式数据一致性的解决方案，应用程序可以基于ZooKeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、分布式锁和分布式队列等功能</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 统一配置管理：指的是ZooKeeper可以把每个子系统都需要的配置文件抽取出来，并将其统一放置到ZooKeeper的ZNode节点中进行共享。● 统一命名服务：指的是给存放在每个节点上的资源进行命名，各个子系统便可以通过名字获取到节点上相应的资源。● 集群状态：通过动态地感知ZooKeeper上节点的增加、删除，从而保证集群下的相关节点主、副本数据的一致性。● 分布式锁：是ZooKeeper提供给外部应用的一个重大功能，主要是通过创建与共享资源相关的“临时顺序节点”和动态Watcher监听机制，从而控制多线程对共享资源的并发访问，而这也可以看作是ZooKeeper拥有诸多特性的根本原因。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>比较典型的业务场景当属ZooKeeper用于担任服务生产者和服务消费者的“注册中心”，即服务生产者将自己提供的服务注册到ZooKeeper中心，服务的消费者在进行服务调用时先在ZooKeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者提供的相关接口。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在分布式服务调度框架Dubbo的基础架构中，ZooKeeper就担任了注册中心这一角色。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>ZooKeeper将所有数据存储在内存中，最终构成的数据模型可以看作是一棵树（ZNode Tree），由斜杠“/”进行分割，分割之后的每个分支即为路径，每个路径对应的即为一个ZNode，例如/ZNode1/Node1，每个节点都会保存自己的数据内容及一系列的属性信息。在ZooKeeper中，ZNode可以分为“持久节点”和“临时节点”两种类型。</p>
</blockquote>
</blockquote>
<h2 id="◆-第8章-综合中间件redisson" tabindex="-1"><a class="header-anchor" href="#◆-第8章-综合中间件redisson" aria-hidden="true">#</a> ◆ 第8章 综合中间件Redisson</h2>
<blockquote>
<blockquote>
<p>高性能分布式中间件Redisson，它是架设在Redis基础上实现 Java驻内存数据网格的综合中间件。之所以称为“综合中间件”，是因为Redisson所提供的功能特性及其在实际项目中所起的作用远远大于原生Redis所提供的各种功能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redisson是一款具有诸多高性能功能特性的开源中间件，其设计的初衷是促进实施者对Redis的关注进行分离（Separation of Concern），让使用者可以将更多的精力集中地放在处理业务逻辑上，从而更好地拆分应用的整体系统架构。</p>
</blockquote>
</blockquote>
<h3 id="◆-8-1-redisson概述" tabindex="-1"><a class="header-anchor" href="#◆-8-1-redisson概述" aria-hidden="true">#</a> ◆ 8.1 Redisson概述</h3>
<blockquote>
<blockquote>
<p>Redisson是一款免费、开源的中间件。其内置了一系列的分布式对象、分布式集合、分布式锁及分布式服务等诸多功能特性，是一款基于Redis实现、拥有一系列分布式系统功能特性的工具包，可以说是实现分布式系统架构中缓存中间件的最佳选择。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redisson是建立在缓存中间件Redis的基础上实现的一款具有高性能且操作更为便捷的“综合中间件”。它充分利用 Redis的Key-Value（键值对）数据结构及基于内存数据库所提供的一系列优势，使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统架构的难度。与此同时，Redisson还结合了各种具有丰富特色的分布式服务、分布式对象、分布式集合及分布式锁等数据组件，更进一步地简化了分布式环境中程序之间的相互协作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>典型业务场景是Redisson在“去重业务”场景中的应用。对于去重，相信读者并不陌生。去重指的是判断一个元素是否在一个集合中存在。如果存在，则输出“已存在”的结果；如果不存在，则存储该元素并输出“该元素不存在”的结果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>传统Java应用系统一般采用JDK自身提供的HashSet进行去重，即主要是通过调用contains()方法，判断当前元素是否存在于集合Set中。如果方法调用返回的结果为true，则代表元素已存在于该集合中；如果返回结果为false，则代表元素不存在，并将该元素添加进集合中。此种方式要求在调用contains()方法之前，将数据列表加载至内存中，即HashSet的contains()方法是基于内存存储实现判断功能的。故在高并发产生大数据量的场景下，此种方式则显得“捉襟见肘”。为此Redisson分布式对象提供了一种高性能的数据组件“布隆过滤器”（Bloom Filter）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>用来过滤已经存在的元素，最终保证集合中的元素是唯一的，即所谓的“去重”。它的作用和JDK自身提供的HashSet作用有异曲同工之妙，只不过它不需要在“判重”之前将数据列表加载至内存中。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redisson的“布隆过滤器”需要将当前的元素经过事先设计构建好的K个哈希函数计算出K个哈希值，并将预先已经构建好的“位数组”的相关下标取值置为1。当某个元素需要判断是否已经存在时，则同样是先经过 K个哈希函数求取 K个哈希值，并判断“位数组”相应的K个下标的取值是否都为1。如果是，则代表元素是“大概率”存在的；否则，表示该元素一定不存在。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>布隆过滤器在实际项目中主要是用于判断一个元素是否存在于“大数量”的集合中，其底层判重的算法主要有两个核心步骤：首先是“初始化”的逻辑，即需要设计并构造K个哈希函数及容量大小为N、每个元素初始取值为0的位数组</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>第二个典型业务场景是“消息通信”，即Redisson也可以实现类似于“消息中间件RabbitMQ”所提供的消息队列功能，从而实现业务服务模块的异步通信与解耦。这一功能主要是通过Redisson分布式对象中的一个组件“基于发布订阅模式的主题”功能实现的，该数据组件底层在执行发布、订阅逻辑时与RabbitMQ消息队列的生产者发送消息、消费者监听消费消息很类似。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Ressison开源组件里并没有提供“死信队列”这一核心组件，取而代之的是 Redisson的阻塞式队列。阻塞式队列指的是进入到 Redisson队列中的消息将会发生阻塞的现象，如果消息设置了过期时间TTL（也叫存活时间），那么消息将会在该阻塞队列“暂时停留”一定的时间，直到过期时间 TTL一到，即代表消息该“离开”了，将前往下一个中转站，消息将进入真正的队列，等待着被消费者监听消费。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所以Redisson提供了“分布式锁”这一功能组件，其最大的原因在于基于Redis的原子操作实现的分布式锁是有一定缺陷的，而Redisson的分布式锁可以很好地弥补这一缺陷。这些缺陷包括以下几点：● 执行Redis的原子操作EXPIRE时，需要设置Key的过期时间TTL，不同的业务场景设置的过期时间是不同的，但是如果设置不当，将很有可能影响应用系统与Redis服务的性能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 采用Redis的原子操作SETNX获取分布式锁时，不具备“可重入”的特性。即当高并发产生多线程时，同一时刻只有一个线程可以获取到锁，从而操作共享资源，而其他的线程将获取锁失败，而且是“永远”失败下去。而有一些业务场景需要要求线程具有“可重入”，则需要在应用程序里添加while(true){}的代码块，即不断地循环等待获取分布式锁，这种方式既不优雅，又很有可能造成应用系统性能“卡顿”的现象。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>● 在执行Redis的原子操作SETNX之后EXPIRE操作之前，此时如果Redis的服务节点发生宕机，由于Key没有及时被释放而导致最终很有可能出现“死锁”的现象，即永远不会有其他的线程能够获取到锁（因为Key没有被删除，导致其永久存在）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在Redis 3.x等高版本中虽然已经出现了RedLock等分布式锁组件，但是其性能却仍然有待考究，而Redisson分布式锁的出现可以很好地解决以上列举的几点缺陷。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Redisson提供了多种“分布式锁”供开发者使用，包括“可重入锁”“一次性锁”“联锁”“红锁RedLock”及“读写锁”等，每一种分布式锁实现的方式和适用的应用场景各不相同。而应用比较多的当属Redisson的“可重入锁”及“一次性锁”了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>可重入锁，顾名思义，指的是当前线程如果没有获取到对共享资源的锁，将会等待一定的时间重新获取。在过个过程中Redisson会提供一个重新获取锁的时间阈值，并在调用tryLock()方法时进行指定。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一次性锁指的是当前线程获取分布式锁时，如果成功则执行后续对共享资源的操作，否则将永远地失败下去（有点“成者为王，败者为寇”的韵味！），其主要是通过调用lock()方法获取锁。</p>
</blockquote>
</blockquote>
<h3 id="◆-9-1-整体业务流程介绍与分析" tabindex="-1"><a class="header-anchor" href="#◆-9-1-整体业务流程介绍与分析" aria-hidden="true">#</a> ◆ 9.1 整体业务流程介绍与分析</h3>
<blockquote>
<blockquote>
<p>对于一些热点新闻、文章或者博客（比如“微博App”的热搜，特别是一些具有爆炸性的娱乐八卦新闻），每次出现时都会有巨大的用户量发起点赞、评论、转发及收藏等操作，这对于系统后端而言，可以说是一种高并发的用户请求。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>先查询后插入的操作需要将其看作是一个不可分割的、整体的操作，即所谓的“共享资源”，否则在高并发产生多线程请求时，系统后端接口将很有可能由于“来不及处理”，而导致出现并发安全的问题，即数据不一致的现象，这种现象在点赞业务场景里将体现为“同一个用户出现多条对相同文章的点赞记录”。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“排行榜”的产生在实际项目中可以有多种方式，有的是直接借助缓存中间件的相关组件进行实现，有的是直接借助数据库如MySQL的Group By和Order By关键字实现，不同的实现方式性能不一样，适用的业务场景也不尽相同。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于高并发的“点赞”业务场景，笔者采用的是综合中间件Redisson中的相关组件，并结合数据库如MySQL的Group By和Order By关键字综合进行实现，此种方式只需要保证以下两点：● 需要保证排行榜对应SQL的正确性，因为该SQL将直接用于产生“排行榜”，即已经排好序的实体对象列表，其中每个实体对象主要包含“博客id”“点赞总数”等字段。如果SQL的执行结果不正确，那其他执行的操作将是在做无用功。● 提供一种触发机制，即用户在前端执行某些操作时，将实时触发缓存中排行榜的更新，而这主要是通过触发这样的一段代码逻辑：重新获取排好序的实体对象列表，并更新缓存中的排行榜，这个操作可以通过异步的方式进行触发。而在一些对实时性要求不高的业务模块中，也可以只通过定时的方式主动触发缓存中的排行榜。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>对于一些预算充足且具备雄厚实力的企业，一般会对数据库服务器采取Master/Slave，即主/从备份的部署模式，并对于“读实例”的数据库服务器采取“集群”部署的模式（即所谓的多台主机部署模式），最终提高前端用户高并发、频繁访问排行榜的性能。</p>
</blockquote>
</blockquote>
<h2 id="◆-第3篇-总结" tabindex="-1"><a class="header-anchor" href="#◆-第3篇-总结" aria-hidden="true">#</a> ◆ 第3篇 总结</h2>
<blockquote>
<blockquote>
<p>这个时代的Java企业级应用逐渐接近于微服务和分布式系统架构。</p>
</blockquote>
</blockquote>
</div></template>


